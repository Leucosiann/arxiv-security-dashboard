[
  {
    "id": "2601.04034v1",
    "title": "HoneyTrap: Deceiving Large Language Model Attackers to Honeypot Traps with Resilient Multi-Agent Defense",
    "authors": [
      "Siyuan Li",
      "Xi Lin",
      "Jun Wu",
      "Zehao Liu",
      "Haoyu Li"
    ],
    "published_date": "2026-01-07",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.04034v1",
    "pdf_link": "https://arxiv.org/pdf/2601.04034v1",
    "content": {
      "en": "Jailbreak attacks pose significant threats to large language models (LLMs), enabling attackers to bypass safeguards. However, existing reactive defense approaches struggle to keep up with the rapidly evolving multi-turn jailbreaks, where attackers continuously deepen their attacks to exploit vulnerabilities. To address this critical challenge, we propose HoneyTrap, a novel deceptive LLM defense framework leveraging collaborative defenders to counter jailbreak attacks. It integrates four defensive agents, Threat Interceptor, Misdirection Controller, Forensic Tracker, and System Harmonizer, each performing a specialized security role and collaborating to complete a deceptive defense. To ensure a comprehensive evaluation, we introduce MTJ-Pro, a challenging multi-turn progressive jailbreak dataset that combines seven advanced jailbreak strategies designed to gradually deepen attack strategies across multi-turn attacks. Besides, we present two novel metrics: Mislead Success Rate (MSR) and Attack Resource Consumption (ARC), which provide more nuanced assessments of deceptive defense beyond conventional measures. Experimental results on GPT-4, GPT-3.5-turbo, Gemini-1.5-pro, and LLaMa-3.1 demonstrate that HoneyTrap achieves an average reduction of 68.77% in attack success rates compared to state-of-the-art baselines. Notably, even in a dedicated adaptive attacker setting with intensified conditions, HoneyTrap remains resilient, leveraging deceptive engagement to prolong interactions, significantly increasing the time and computational costs required for successful exploitation. Unlike simple rejection, HoneyTrap strategically wastes attacker resources without impacting benign queries, improving MSR and ARC by 118.11% and 149.16%, respectively.",
      "tr": "**Makale Başlığı:** HoneyTrap: Büyük Dil Modeli Saldırganlarını, Dayanıklı Çoklu-Ajan Savunmasıyla Honeypot Tuzaklarına Aldatma\n\n**Özet:**\n\nJailbreak saldırıları, büyük dil modelleri (LLM) için önemli tehditler oluşturmakta ve saldırganların koruma mekanizmalarını atlatmalarına olanak tanımaktadır. Ancak, mevcut reaktif savunma yaklaşımları, saldırganların güvenlik açıklarından yararlanmak için saldırılarını sürekli olarak derinleştirdiği, hızla gelişen çok turlu jailbreak'lerle başa çıkmakta zorlanmaktadır. Bu kritik zorluğun üstesinden gelmek için, jailbreak saldırılarına karşı koymak üzere işbirlikçi savunmacılardan yararlanan yeni bir aldatıcı LLM savunma çerçevesi olan HoneyTrap'i öneriyoruz. HoneyTrap, her biri özel bir güvenlik rolü üstlenen ve aldatıcı bir savunmayı tamamlamak üzere işbirliği yapan dört savunma ajanını entegre eder: Threat Interceptor, Misdirection Controller, Forensic Tracker ve System Harmonizer. Kapsamlı bir değerlendirme sağlamak amacıyla, çok turlu saldırılar boyunca saldırı stratejilerini giderek derinleştirmek üzere tasarlanmış yedi gelişmiş jailbreak stratejisini birleştiren zorlu bir çok turlu aşamalı jailbreak veri kümesi olan MTJ-Pro'yu sunuyoruz. Ayrıca, aldatıcı savunmanın geleneksel ölçümlerin ötesinde daha incelikli değerlendirmeler sunan iki yeni metrik sunuyoruz: Mislead Success Rate (MSR) ve Attack Resource Consumption (ARC). GPT-4, GPT-3.5-turbo, Gemini-1.5-pro ve LLaMa-3.1 üzerindeki deneysel sonuçlar, HoneyTrap'in en son temel yöntemlere kıyasla saldırı başarı oranlarında ortalama %68.77'lik bir azalma sağladığını göstermektedir. Özellikle, yoğunlaştırılmış koşullara sahip özel bir adaptif saldırgan ortamında bile HoneyTrap, etkileşimleri uzatmak için aldatıcı etkileşimden yararlanarak dayanıklı kalır ve başarılı bir şekilde sömürü için gereken süreyi ve hesaplama maliyetlerini önemli ölçüde artırır. Basit reddetmenin aksine, HoneyTrap zararsız sorguları etkilemeden saldırgan kaynaklarını stratejik olarak boşa harcar, MSR ve ARC'yi sırasıyla %118.11 ve %149.16 oranında iyileştirir."
    }
  },
  {
    "id": "2601.03868v1",
    "title": "What Matters For Safety Alignment?",
    "authors": [
      "Xing Li",
      "Hui-Ling Zhen",
      "Lihao Yin",
      "Xianzhi Yu",
      "Zhenhua Dong"
    ],
    "published_date": "2026-01-07",
    "tags": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2601.03868v1",
    "pdf_link": "https://arxiv.org/pdf/2601.03868v1",
    "content": {
      "en": "This paper presents a comprehensive empirical study on the safety alignment capabilities. We evaluate what matters for safety alignment in LLMs and LRMs to provide essential insights for developing more secure and reliable AI systems. We systematically investigate and compare the influence of six critical intrinsic model characteristics and three external attack techniques. Our large-scale evaluation is conducted using 32 recent, popular LLMs and LRMs across thirteen distinct model families, spanning a parameter scale from 3B to 235B. The assessment leverages five established safety datasets and probes model vulnerabilities with 56 jailbreak techniques and four CoT attack strategies, resulting in 4.6M API calls. Our key empirical findings are fourfold. First, we identify the LRMs GPT-OSS-20B, Qwen3-Next-80B-A3B-Thinking, and GPT-OSS-120B as the top-three safest models, which substantiates the significant advantage of integrated reasoning and self-reflection mechanisms for robust safety alignment. Second, post-training and knowledge distillation may lead to a systematic degradation of safety alignment. We thus argue that safety must be treated as an explicit constraint or a core optimization objective during these stages, not merely subordinated to the pursuit of general capability. Third, we reveal a pronounced vulnerability: employing a CoT attack via a response prefix can elevate the attack success rate by 3.34x on average and from 0.6% to 96.3% for Seed-OSS-36B-Instruct. This critical finding underscores the safety risks inherent in text-completion interfaces and features that allow user-defined response prefixes in LLM services, highlighting an urgent need for architectural and deployment safeguards. Fourth, roleplay, prompt injection, and gradient-based search for adversarial prompts are the predominant methodologies for eliciting unaligned behaviors in modern models.",
      "tr": "**Makale Başlığı:** Güvenlik Uyumu İçin Ne Önemlidir?\n\n**Özet:**\n\nBu makale, güvenlik uyumu yetenekleri üzerine kapsamlı bir ampirik çalışma sunmaktadır. Daha güvenli ve güvenilir yapay zeka sistemleri geliştirme konusunda temel içgörüler sağlamak amacıyla, LLM'ler ve LRM'ler için güvenlik uyumunda nelerin önemli olduğunu değerlendiriyoruz. Altı kritik içsel model özelliği ve üç harici saldırı tekniğinin etkisini sistematik olarak araştırıyor ve karşılaştırıyoruz. Büyük ölçekli değerlendirmemiz, 3B ila 235B arasındaki parametre ölçeğini kapsayan on üç farklı model ailesi boyunca 32 adet güncel, popüler LLM ve LRM kullanılarak gerçekleştirilmiştir. Değerlendirme, beş yerleşik güvenlik veri kümesinden yararlanmakta ve 56 jailbreak tekniği ve dört CoT attack stratejisi ile model zafiyetlerini incelemekte, bu da 4.6M API call sonucunu doğurmaktadır. Temel ampirik bulgularımız dört ana başlık altında toplanmaktadır. Birincisi, LRMs GPT-OSS-20B, Qwen3-Next-80B-A3B-Thinking ve GPT-OSS-120B modellerini en güvenli ilk üç model olarak tespit ettik; bu, sağlam güvenlik uyumu için entegre **reasoning** ve self-reflection mekanizmalarının önemli avantajını desteklemektedir. İkincisi, post-training ve knowledge distillation, güvenlik uyumunda sistematik bir bozulmaya yol açabilir. Bu nedenle, bu aşamalarda güvenliğin, genel yetenek peşinde koşmanın basitçe alt sıralarına yerleştirilmek yerine, açık bir kısıtlama veya çekirdek bir optimizasyon hedefi olarak ele alınması gerektiğini savunuyoruz. Üçüncüsü, bariz bir zafiyet ortaya koymaktayız: bir response prefix aracılığıyla bir CoT attack kullanmak, Seed-OSS-36B-Instruct için ortalama 3.34 kat ve %0.6'dan %96.3'e kadar saldırı başarı oranını yükseltebilir. Bu kritik bulgu, text-completion arayüzlerinde ve LLM hizmetlerinde kullanıcı tanımlı response prefix'lere izin veren özelliklerde yerleşik güvenlik risklerini vurgulamakta, mimari ve dağıtım güvenceleri için acil bir ihtiyaç doğurmaktadır. Dördüncüsü, roleplay, prompt injection ve adversarial prompts için gradient-based search, modern modellerde uyumsuz davranışları ortaya çıkarmak için baskın metodolojilerdir."
    }
  },
  {
    "id": "2601.03587v1",
    "title": "Deontic Knowledge Graphs for Privacy Compliance in Multimodal Disaster Data Sharing",
    "authors": [
      "Kelvin Uzoma Echenim",
      "Karuna Pande Joshi"
    ],
    "published_date": "2026-01-07",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.DB"
    ],
    "link": "http://arxiv.org/abs/2601.03587v1",
    "pdf_link": "https://arxiv.org/pdf/2601.03587v1",
    "content": {
      "en": "Disaster response requires sharing heterogeneous artifacts, from tabular assistance records to UAS imagery, under overlapping privacy mandates. Operational systems often reduce compliance to binary access control, which is brittle in time-critical workflows. We present a novel deontic knowledge graph-based framework that integrates a Disaster Management Knowledge Graph (DKG) with a Policy Knowledge Graph (PKG) derived from IoT-Reg and FEMA/DHS privacy drivers. Our release decision function supports three outcomes: Allow, Block, and Allow-with-Transform. The latter binds obligations to transforms and verifies post-transform compliance via provenance-linked derived artifacts; blocked requests are logged as semantic privacy incidents. Evaluation on a 5.1M-triple DKG with 316K images shows exact-match decision correctness, sub-second per-decision latency, and interactive query performance across both single-graph and federated workloads.",
      "tr": "**Makale Başlığı:** Multimodal Afet Veri Paylaşımında Gizlilik Uyumluluğu İçin Deontic Knowledge Graphs\n\n**Özet:**\n\nAfet müdahalesi, çakışan gizlilik zorunlulukları altında, tablosal yardım kayıtlarından UAS görüntülerine kadar heterojen eserlerin paylaşılmasını gerektirir. Operasyonel sistemler genellikle uyumluluğu ikili erişim kontrolüne indirger ki bu, zaman açısından kritik iş akışlarında kırılgan bir yaklaşımdır. Afet Yönetimi Knowledge Graph (DKG) ile IoT-Reg ve FEMA/DHS gizlilik etkenlerinden türetilen bir Policy Knowledge Graph (PKG)'ı entegre eden, yeni bir deontic knowledge graph tabanlı çerçeve sunuyoruz. Yayın karar fonksiyonumuz üç sonuç desteklemektedir: İzin Ver, Engelle ve Dönüşümle İzin Ver. Sonuncusu, dönüşümlere yükümlülükler bağlar ve provenance-linked derived artifacts aracılığıyla dönüşüm sonrası uyumluluğu doğrular; engellenen istekler semantik gizlilik olayları olarak kaydedilir. 5.1M-triple DKG üzerinde 316K görüntü ile yapılan değerlendirme, hem tekli-graph hem de federated iş yüklerinde exact-match karar doğruluğu, karar başına saniyenin altında gecikme süresi ve interaktif sorgu performansı göstermiştir."
    }
  },
  {
    "id": "2601.03429v1",
    "title": "DeepLeak: Privacy Enhancing Hardening of Model Explanations Against Membership Leakage",
    "authors": [
      "Firas Ben Hmida",
      "Zain Sbeih",
      "Philemon Hailemariam",
      "Birhanu Eshete"
    ],
    "published_date": "2026-01-06",
    "tags": [
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.03429v1",
    "pdf_link": "https://arxiv.org/pdf/2601.03429v1",
    "content": {
      "en": "Machine learning (ML) explainability is central to algorithmic transparency in high-stakes settings such as predictive diagnostics and loan approval. However, these same domains require rigorous privacy guaranties, creating tension between interpretability and privacy. Although prior work has shown that explanation methods can leak membership information, practitioners still lack systematic guidance on selecting or deploying explanation techniques that balance transparency with privacy.   We present DeepLeak, a system to audit and mitigate privacy risks in post-hoc explanation methods. DeepLeak advances the state-of-the-art in three ways: (1) comprehensive leakage profiling: we develop a stronger explanation-aware membership inference attack (MIA) to quantify how much representative explanation methods leak membership information under default configurations; (2) lightweight hardening strategies: we introduce practical, model-agnostic mitigations, including sensitivity-calibrated noise, attribution clipping, and masking, that substantially reduce membership leakage while preserving explanation utility; and (3) root-cause analysis: through controlled experiments, we pinpoint algorithmic properties (e.g., attribution sparsity and sensitivity) that drive leakage.   Evaluating 15 explanation techniques across four families on image benchmarks, DeepLeak shows that default settings can leak up to 74.9% more membership information than previously reported. Our mitigations cut leakage by up to 95% (minimum 46.5%) with only <=3.3% utility loss on average. DeepLeak offers a systematic, reproducible path to safer explainability in privacy-sensitive ML.",
      "tr": "**Makale Başlığı:** DeepLeak: Üyelik Sızıntısına Karşı Model Açıklamalarının Gizliliği Artıran Güçlendirilmesi\n\n**Özet:**\n\nMakine öğrenmesi (ML) açıklanabilirliği, tahminci teşhis ve kredi onayı gibi yüksek riskli ortamlarda algoritmik şeffaflık için merkezi bir unsurdur. Ancak, aynı alanlar titiz gizlilik garantileri gerektirmekte, bu da yorumlanabilirlik ve gizlilik arasında bir gerilim yaratmaktadır. Önceki çalışmalar, açıklama yöntemlerinin üyelik bilgisini sızdırabileceğini gösterse de, uygulayıcılar hala şeffaflığı gizlilikle dengeleyen açıklama teknikleri seçme veya dağıtma konusunda sistematik bir rehberlikten yoksundur. Biz, post-hoc açıklama yöntemlerindeki gizlilik risklerini denetlemek ve azaltmak için bir sistem olan DeepLeak'i sunuyoruz. DeepLeak, mevcut durumu üç şekilde ilerletmektedir: (1) kapsamlı sızıntı profillemesi: Varsayılan yapılandırmalar altında temsili açıklama yöntemlerinin üyelik bilgisini ne kadar sızdırdığını ölçmek için daha güçlü bir explanation-aware membership inference attack (MIA) geliştiriyoruz; (2) hafif güçlendirme stratejileri: Açıklama faydasını korurken üyelik sızıntısını önemli ölçüde azaltan, duyarlılığa göre kalibre edilmiş gürültü, atama kırpma ve maskeleme gibi pratik, modelden bağımsız azaltmalar sunuyoruz; ve (3) kök neden analizi: Kontrollü deneyler aracılığıyla, sızıntıya neden olan algoritmik özellikleri (örneğin, attribution sparsity ve sensitivity) tespit ediyoruz. Görüntü kıyaslamalarında dört aileden 15 açıklama tekniğini değerlendiren DeepLeak, varsayılan ayarların daha önce bildirilenlere kıyasla %74,9'a kadar daha fazla üyelik bilgisini sızdırabileceğini göstermektedir. Azaltmalarımız, ortalama sadece <=%3,3'lük bir fayda kaybıyla sızıntıyı %95'e kadar (minimum %46,5) azaltmaktadır. DeepLeak, gizliliğe duyarlı ML'de daha güvenli açıklanabilirlik için sistematik, tekrarlanabilir bir yol sunmaktadır."
    }
  },
  {
    "id": "2601.03420v1",
    "title": "Jailbreaking LLMs Without Gradients or Priors: Effective and Transferable Attacks",
    "authors": [
      "Zhakshylyk Nurlanov",
      "Frank R. Schmidt",
      "Florian Bernard"
    ],
    "published_date": "2026-01-06",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2601.03420v1",
    "pdf_link": "https://arxiv.org/pdf/2601.03420v1",
    "content": {
      "en": "As Large Language Models (LLMs) are increasingly deployed in safety-critical domains, rigorously evaluating their robustness against adversarial jailbreaks is essential. However, current safety evaluations often overestimate robustness because existing automated attacks are limited by restrictive assumptions. They typically rely on handcrafted priors or require white-box access for gradient propagation. We challenge these constraints by demonstrating that token-level iterative optimization can succeed without gradients or priors. We introduce RAILS (RAndom Iterative Local Search), a framework that operates solely on model logits. RAILS matches the effectiveness of gradient-based methods through two key innovations: a novel auto-regressive loss that enforces exact prefix matching, and a history-based selection strategy that bridges the gap between the proxy optimization objective and the true attack success rate. Crucially, by eliminating gradient dependency, RAILS enables cross-tokenizer ensemble attacks. This allows for the discovery of shared adversarial patterns that generalize across disjoint vocabularies, significantly enhancing transferability to closed-source systems. Empirically, RAILS achieves near 100% success rates on multiple open-source models and high black-box attack transferability to closed-source systems like GPT and Gemini.",
      "tr": "İşte makale başlığı ve özetinin istenen akademik ve resmi dilde Türkçe çevirisi:\n\n**Makale Başlığı:** Jailbreaking LLMs Without Gradients or Priors: Effective and Transferable Attacks\n\n**Özet:**\n\nBüyük dil modellerinin (LLMs) giderek daha fazla güvenlik-kritik alanlarda konuşlandırılmasıyla, düşmanca jailbreak'lere karşı sağlamlıklarının titizlikle değerlendirilmesi elzemdir. Bununla birlikte, mevcut güvenlik değerlendirmeleri genellikle sağlamlığı abartmaktadır, çünkü mevcut otomatik saldırılar kısıtlayıcı varsayımlarla sınırlıdır. Bunlar tipik olarak handcrafted priors'a dayanır veya gradient propagation için white-box erişimi gerektirir. Bu kısıtlamalara, token-level iterative optimization'ın gradients veya priors olmadan başarılı olabileceğini göstererek meydan okuyoruz. RAILS (RAndom Iterative Local Search) çerçevesini tanıtıyoruz; bu çerçeve yalnızca model logits üzerinde çalışır. RAILS, iki temel yenilik sayesinde gradient-based yöntemlerin etkinliğine ulaşır: exact prefix matching'i zorunlu kılan yeni bir auto-regressive loss ve proxy optimization objective ile gerçek attack success rate arasındaki boşluğu dolduran bir history-based selection strategy. Kritik olarak, gradient bağımlılığını ortadan kaldırarak RAILS, cross-tokenizer ensemble attacks'ı mümkün kılar. Bu, disjoint vocabularies boyunca genelleşen paylaşılan düşmanca örüntülerin keşfedilmesine olanak tanır, bu da closed-source sistemlere transfer edilebilirliği önemli ölçüde artırır. Ampirik olarak RAILS, birden fazla open-source modelde %100'e yakın başarı oranları ve GPT ve Gemini gibi closed-source sistemlere yüksek black-box attack transferability elde eder."
    }
  },
  {
    "id": "2601.03323v1",
    "title": "Listen to Rhythm, Choose Movements: Autoregressive Multimodal Dance Generation via Diffusion and Mamba with Decoupled Dance Dataset",
    "authors": [
      "Oran Duan",
      "Yinghua Shen",
      "Yingzhu Lv",
      "Luyang Jie",
      "Yaxin Liu"
    ],
    "published_date": "2026-01-06",
    "tags": [
      "cs.CR",
      "cs.CV",
      "cs.LG",
      "cs.SD"
    ],
    "link": "http://arxiv.org/abs/2601.03323v1",
    "pdf_link": "https://arxiv.org/pdf/2601.03323v1",
    "content": {
      "en": "Advances in generative models and sequence learning have greatly promoted research in dance motion generation, yet current methods still suffer from coarse semantic control and poor coherence in long sequences. In this work, we present Listen to Rhythm, Choose Movements (LRCM), a multimodal-guided diffusion framework supporting both diverse input modalities and autoregressive dance motion generation. We explore a feature decoupling paradigm for dance datasets and generalize it to the Motorica Dance dataset, separating motion capture data, audio rhythm, and professionally annotated global and local text descriptions. Our diffusion architecture integrates an audio-latent Conformer and a text-latent Cross-Conformer, and incorporates a Motion Temporal Mamba Module (MTMM) to enable smooth, long-duration autoregressive synthesis. Experimental results indicate that LRCM delivers strong performance in both functional capability and quantitative metrics, demonstrating notable potential in multimodal input scenarios and extended sequence generation. We will release the full codebase, dataset, and pretrained models publicly upon acceptance.",
      "tr": "Elbette, akademik makale başlığını ve özetini istenen şekilde Türkçeye çevirdim:\n\n**Makale Başlığı:** Listen to Rhythm, Choose Movements: Autoregressive Multimodal Dance Generation via Diffusion and Mamba with Decoupled Dance Dataset\n\n**Özet:**\nÜretken modeller ve dizi öğrenimindeki gelişmeler, dans hareketi üretimi araştırmalarını büyük ölçüde ilerletmiş olmasına rağmen, mevcut yöntemler hala kaba semantik kontrol ve uzun dizilerde zayıf tutarlılık sorunlarından muzdariptir. Bu çalışmada, hem çeşitli girdi modalitelerini hem de otoregresif dans hareketi üretimini destekleyen, çok modlu kılavuzlu bir diffusion çerçevesi olan Listen to Rhythm, Choose Movements (LRCM)'i sunmaktayız. Dans veri setleri için bir özellik ayrıştırma (feature decoupling) paradigması keşfediyor ve bunu Motorica Dance veri setine genelleştirerek hareket yakalama verilerini, ses ritmini ve profesyonelce notlandırılmış küresel ve yerel metin açıklamalarını ayırıyoruz. Diffusion mimarimiz, bir audio-latent Conformer ve bir text-latent Cross-Conformer'ı entegre eder ve yumuşak, uzun süreli otoregresif sentezlemeyi etkinleştirmek için bir Motion Temporal Mamba Module (MTMM) içerir. Deneysel sonuçlar, LRCM'in hem fonksiyonel yetenek hem de nicel metriklerde güçlü performans sunduğunu göstermektedir; bu da çok modlu girdi senaryolarında ve genişletilmiş dizi üretiminde dikkate değer bir potansiyel sergilemektedir. Kabul edilmesi üzerine tam codebase, veri seti ve önceden eğitilmiş modelleri kamuya açık olarak yayımlayacağız."
    }
  },
  {
    "id": "2601.03005v1",
    "title": "JPU: Bridging Jailbreak Defense and Unlearning via On-Policy Path Rectification",
    "authors": [
      "Xi Wang",
      "Songlei Jian",
      "Shasha Li",
      "Xiaopeng Li",
      "Zhaoye Li"
    ],
    "published_date": "2026-01-06",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.03005v1",
    "pdf_link": "https://arxiv.org/pdf/2601.03005v1",
    "content": {
      "en": "Despite extensive safety alignment, Large Language Models (LLMs) often fail against jailbreak attacks. While machine unlearning has emerged as a promising defense by erasing specific harmful parameters, current methods remain vulnerable to diverse jailbreaks. We first conduct an empirical study and discover that this failure mechanism is caused by jailbreaks primarily activating non-erased parameters in the intermediate layers. Further, by probing the underlying mechanism through which these circumvented parameters reassemble into the prohibited output, we verify the persistent existence of dynamic $\\textbf{jailbreak paths}$ and show that the inability to rectify them constitutes the fundamental gap in existing unlearning defenses. To bridge this gap, we propose $\\textbf{J}$ailbreak $\\textbf{P}$ath $\\textbf{U}$nlearning (JPU), which is the first to rectify dynamic jailbreak paths towards safety anchors by dynamically mining on-policy adversarial samples to expose vulnerabilities and identify jailbreak paths. Extensive experiments demonstrate that JPU significantly enhances jailbreak resistance against dynamic attacks while preserving the model's utility.",
      "tr": "Kesinlikle, istediğiniz şekilde akademik makale başlığı ve özetini çevirdim:\n\n**Makale Başlığı:** JPU: On-Policy Path Rectification ile Jailbreak Savunması ve Unlearning Arasında Köprü Kurmak\n\n**Özet:**\nKapsamlı güvenlik uyum çalışmalarına rağmen, Büyük Dil Modelleri (LLM'ler) sıklıkla jailbreak saldırılarına karşı başarısız olmaktadır. Makine unlearning'i, belirli zararlı parametreleri silerek umut vadeden bir savunma yöntemi olarak ortaya çıkarken, mevcut yöntemler çeşitli jailbreak'lere karşı hala savunmasızdır. Öncelikle ampirik bir çalışma yürüterek, bu başarısızlık mekanizmasının, jailbreak'lerin öncelikle ara katmanlardaki silinmemiş parametreleri aktive etmesinden kaynaklandığını keşfediyoruz. Dahası, bu engellenen parametrelerin yasaklanmış çıktıya nasıl yeniden birleştiği altta yatan mekanizmayı probing yoluyla, dinamik **jailbreak paths**'in kalıcı varlığını doğruluyor ve bunları düzeltme konusundaki yetersizliğin, mevcut unlearning savunmalarındaki temel boşluğu oluşturduğunu gösteriyoruz. Bu boşluğu kapatmak için, güvenliğe yönelik jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangın jangDaha fazla..."
    }
  },
  {
    "id": "2601.02941v1",
    "title": "SastBench: A Benchmark for Testing Agentic SAST Triage",
    "authors": [
      "Jake Feiglin",
      "Guy Dar"
    ],
    "published_date": "2026-01-06",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "link": "http://arxiv.org/abs/2601.02941v1",
    "pdf_link": "https://arxiv.org/pdf/2601.02941v1",
    "content": {
      "en": "SAST (Static Application Security Testing) tools are among the most widely used techniques in defensive cybersecurity, employed by commercial and non-commercial organizations to identify potential vulnerabilities in software. Despite their great utility, they generate numerous false positives, requiring costly manual filtering (aka triage). While LLM-powered agents show promise for automating cybersecurity tasks, existing benchmarks fail to emulate real-world SAST finding distributions. We introduce SastBench, a benchmark for evaluating SAST triage agents that combines real CVEs as true positives with filtered SAST tool findings as approximate false positives. SastBench features an agent-agnostic design. We evaluate different agents on the benchmark and present a comparative analysis of their performance, provide a detailed analysis of the dataset, and discuss the implications for future development.",
      "tr": "Aşağıda, verdiğiniz akademik makale başlığı ve özetinin Türkçe çevirisi bulunmaktadır. Teknik terimler belirtildiği gibi İngilizce olarak korunmuştur:\n\n**Makale Başlığı:** SastBench: SastBench: A Benchmark for Testing Agentic SAST Triage\n\n**Özet:**\n\nSAST (Static Application Security Testing) araçları, savunma siber güvenliğinde en yaygın kullanılan teknikler arasında yer almaktadır ve ticari ile ticari olmayan kuruluşlar tarafından yazılımdaki potansiyel güvenlik açıklarını belirlemek amacıyla kullanılmaktadır. Bu araçların büyük faydalarına rağmen, çok sayıda yanlış pozitif (false positive) üretmeleri, maliyetli manuel filtreleme (triage olarak da bilinir) gerektirmektedir. LLM destekli ajanlar siber güvenlik görevlerini otomatikleştirmede umut vaat etse de, mevcut benchmarklar gerçek dünya SAST bulgu dağılımlarını taklit etmekte yetersiz kalmaktadır. Biz, SastBench'i tanıtıyoruz; bu benchmark, gerçek CVE'leri doğru pozitifler (true positives) olarak ve filtrelenmiş SAST araç bulgularını yaklaşık yanlış pozitifler (approximate false positives) olarak birleştirerek SAST triage ajanlarını değerlendirmek için tasarlanmıştır. SastBench, ajan-bağımsız (agent-agnostic) bir tasarıma sahiptir. Benchmark üzerinde farklı ajanları değerlendiriyor, performanslarının karşılaştırmalı bir analizini sunuyor, veri kümesinin ayrıntılı bir analizini sağlıyor ve gelecekteki geliştirme çalışmaları için çıkarımları tartışıyoruz."
    }
  },
  {
    "id": "2601.02751v1",
    "title": "Window-based Membership Inference Attacks Against Fine-tuned Large Language Models",
    "authors": [
      "Yuetian Chen",
      "Yuntao Du",
      "Kaiyuan Zhang",
      "Ashish Kundu",
      "Charles Fleming"
    ],
    "published_date": "2026-01-06",
    "tags": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2601.02751v1",
    "pdf_link": "https://arxiv.org/pdf/2601.02751v1",
    "content": {
      "en": "Most membership inference attacks (MIAs) against Large Language Models (LLMs) rely on global signals, like average loss, to identify training data. This approach, however, dilutes the subtle, localized signals of memorization, reducing attack effectiveness. We challenge this global-averaging paradigm, positing that membership signals are more pronounced within localized contexts. We introduce WBC (Window-Based Comparison), which exploits this insight through a sliding window approach with sign-based aggregation. Our method slides windows of varying sizes across text sequences, with each window casting a binary vote on membership based on loss comparisons between target and reference models. By ensembling votes across geometrically spaced window sizes, we capture memorization patterns from token-level artifacts to phrase-level structures. Extensive experiments across eleven datasets demonstrate that WBC substantially outperforms established baselines, achieving higher AUC scores and 2-3 times improvements in detection rates at low false positive thresholds. Our findings reveal that aggregating localized evidence is fundamentally more effective than global averaging, exposing critical privacy vulnerabilities in fine-tuned LLMs.",
      "tr": "Makale Başlığı: İnce Ayarlanmış Büyük Dil Modellerine Karşı Pencere Tabanlı Üyelik Çıkarım Saldırıları\n\nÖzet:\nBüyük Dil Modellerine (LLM'ler) yönelik üyelik çıkarım saldırılarının (MIA'lar) çoğu, eğitim verilerini tanımlamak için ortalama kayıp gibi küresel sinyallere dayanmaktadır. Ancak bu yaklaşım, ezberleme (memorization) ile ilgili ince, yerelleştirilmiş sinyalleri seyreltir ve saldırı etkinliğini azaltır. Biz bu küresel ortalama alma paradigmasına meydan okuyoruz ve üyelik sinyallerinin yerelleştirilmiş bağlamlarda daha belirgin olduğu hipotezini öne sürüyoruz. WBC'yi (Window-Based Comparison) tanıtıyoruz; bu yöntem, işaret tabanlı toplama (sign-based aggregation) ile kayan pencere yaklaşımını kullanarak bu anlayıştan yararlanır. Yöntemimiz, metin dizileri boyunca farklı boyutlarda pencereleri kaydırır; her pencere, hedef ve referans modeller arasındaki kayıp karşılaştırmalarına dayanarak üyelik konusunda ikili bir oy kullanır. Geometrik olarak aralıklı pencere boyutları boyunca oyların birleştirilmesiyle, token düzeyindeki artefaktlardan ifade düzeyindeki yapılara kadar ezberleme (memorization) modellerini yakalarız. On bir veri kümesi üzerinde yapılan kapsamlı deneyler, WBC'nin yerleşik taban çizgilerini önemli ölçüde aştığını, daha yüksek AUC puanları ve düşük yanlış pozitif eşiklerinde tespit oranlarında 2-3 kat iyileşme sağladığını göstermektedir. Bulgularımız, yerelleştirilmiş kanıtların toplamasının küresel ortalama almaktan temelde daha etkili olduğunu ortaya koymakta ve ince ayarlanmış LLM'lerde kritik gizlilik güvenlik açıklarını açığa çıkarmaktadır."
    }
  },
  {
    "id": "2601.02720v1",
    "title": "Privacy-Preserving AI-Enabled Decentralized Learning and Employment Records System",
    "authors": [
      "Yuqiao Xu",
      "Mina Namazi",
      "Sahith Reddy Jalapally",
      "Osama Zafar",
      "Youngjin Yoo"
    ],
    "published_date": "2026-01-06",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.02720v1",
    "pdf_link": "https://arxiv.org/pdf/2601.02720v1",
    "content": {
      "en": "Learning and Employment Record (LER) systems are emerging as critical infrastructure for securely compiling and sharing educational and work achievements. Existing blockchain-based platforms leverage verifiable credentials but typically lack automated skill-credential generation and the ability to incorporate unstructured evidence of learning. In this paper,a privacy-preserving, AI-enabled decentralized LER system is proposed to address these gaps. Digitally signed transcripts from educational institutions are accepted, and verifiable self-issued skill credentials are derived inside a trusted execution environment (TEE) by a natural language processing pipeline that analyzes formal records (e.g., transcripts, syllabi) and informal artifacts. All verification and job-skill matching are performed inside the enclave with selective disclosure, so raw credentials and private keys remain enclave-confined. Job matching relies solely on attested skill vectors and is invariant to non-skill resume fields, thereby reducing opportunities for screening bias.The NLP component was evaluated on sample learner data; the mapping follows the validated Syllabus-to-O*NET methodology,and a stability test across repeated runs observed <5% variance in top-ranked skills. Formal security statements and proof sketches are provided showing that derived credentials are unforgeable and that sensitive information remains confidential. The proposed system thus supports secure education and employment credentialing, robust transcript verification,and automated, privacy-preserving skill extraction within a decentralized framework.",
      "tr": "Kesinlikle, akademik makalenin başlığını ve özetini istenen şekilde çevirdim:\n\n**Makale Başlığı:** Gizliliği Koruyan Yapay Zeka Destekli Merkeziyetsiz Öğrenme ve İstihdam Kayıtları Sistemi\n\n**Özet:**\nLearning and Employment Record (LER) sistemleri, eğitim ve iş başarılarını güvenli bir şekilde derleme ve paylaşma için kritik altyapılar olarak ortaya çıkmaktadır. Mevcut blockchain tabanlı platformlar, verifiable credentials'dan yararlanır ancak tipik olarak otomatik skill-credential üretimi ve yapılandırılmamış öğrenme kanıtlarını dahil etme yeteneğinden yoksundur. Bu makalede, bu boşlukları gidermek için gizliliği koruyan, AI-enabled decentralized bir LER sistemi önerilmektedir. Eğitim kurumlarından dijital olarak imzalanmış transkriptler kabul edilir ve güvenilir bir yürütme ortamında (TEE) formal kayıtları (örn. transkriptler, müfredatlar) ve informal artefaktları analiz eden bir natural language processing pipeline'ı tarafından verifiable self-issued skill credentials elde edilir. Tüm verification ve job-skill matching, selective disclosure ile enclave içinde gerçekleştirilir, böylece raw credentials ve private keys enclave-confined kalır. Job matching, yalnızca attested skill vectors'a dayanır ve non-skill resume alanlarına karşı invariant'tır, bu da screening bias'ı için fırsatları azaltır. NLP bileşeni, örnek öğrenci verileri üzerinde değerlendirilmiştir; eşleme, doğrulanmış Syllabus-to-O*NET metodolojisini takip eder ve tekrarlanan çalıştırmalarda elde edilen bir stability test, top-ranked skills'de <%5 varyans gözlemlemiştir. Formal security statements ve proof sketches, elde edilen credentials'ın unforgeable olduğunu ve hassas bilgilerin confidential kaldığını gösterir. Önerilen sistem, merkeziyetsiz bir çerçevede güvenli eğitim ve istihdam credentialing'ini, robust transcript verification'ı ve otomatik, gizliliği koruyan skill extraction'ı desteklemektedir."
    }
  }
]