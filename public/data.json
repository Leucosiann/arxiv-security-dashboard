[
  {
    "id": "2601.16795v1",
    "title": "Building a Robust Risk-Based Access Control System to Combat Ransomware's Capability to Encrypt: A Machine Learning Approach",
    "authors": [
      "Kenan Begovic",
      "Abdulaziz Al-Ali",
      "Qutaibah Malluhi"
    ],
    "published_date": "2026-01-23",
    "tags": [
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.16795v1",
    "pdf_link": "https://arxiv.org/pdf/2601.16795v1",
    "content": {
      "en": "Ransomware core capability, unauthorized encryption, demands controls that identify and block malicious cryptographic activity without disrupting legitimate use. We present a probabilistic, risk-based access control architecture that couples machine learning inference with mandatory access control to regulate encryption on Linux in real time. The system builds a specialized dataset from the native ftrace framework using the function_graph tracer, yielding high-resolution kernel-function execution traces augmented with resource and I/O counters. These traces support both a supervised classifier and interpretable rules that drive an SELinux policy via lightweight booleans, enabling context-sensitive permit/deny decisions at the moment encryption begins. Compared to approaches centered on sandboxing, hypervisor introspection, or coarse system-call telemetry, the function-level tracing we adopt provides finer behavioral granularity than syscall-only telemetry while avoiding the virtualization/VMI overhead of sandbox-based approaches. Our current user-space prototype has a non-trivial footprint under burst I/O; we quantify it and recognize that a production kernel-space solution should aim to address this. We detail dataset construction, model training and rule extraction, and the run-time integration that gates file writes for suspect encryption while preserving benign cryptographic workflows. During evaluation, the two-layer composition retains model-level detection quality while delivering rule-like responsiveness; we also quantify operational footprint and outline engineering steps to reduce CPU and memory overhead for enterprise deployment. The result is a practical path from behavioral tracing and learning to enforceable, explainable, and risk-proportionate encryption control on production Linux systems.",
      "tr": "**Makale Başlığı: Şifreleme Kabiliyetine Karşı Güçlü Bir Risk Tabanlı Erişim Kontrol Sistemi Oluşturmak: Bir Makine Öğrenmesi Yaklaşımı**\n\n**Özet:**\n\nFidye yazılımlarının temel kabiliyeti olan yetkisiz şifreleme, meşru kullanımı aksatmadan kötü amaçlı kriptografik etkinliği tanımlayıp engelleyen kontrolleri gerektirir. Makine öğrenmesi inference'ını zorunlu erişim kontrolü ile birleştiren, Linux üzerinde şifrelemeyi gerçek zamanlı olarak düzenleyen olasılıksal, risk tabanlı bir erişim kontrol mimarisi sunuyoruz. Sistem, yüksek çözünürlüklü çekirdek fonksiyonu yürütme izlerini kaynak ve G/Ç sayaçlarıyla zenginleştirerek yerel ftrace framework'ünden function_graph tracer'ı kullanarak özel bir veri kümesi oluşturur. Bu izler, hem denetimli bir sınıflandırıcıyı hem de hafif booleans aracılığıyla bir SELinux politikasını yönlendiren ve şifreleme başladığı anda bağlam duyarlı izin/red kararlarına olanak tanıyan yorumlanabilir kuralları destekler. Sanal alan (sandboxing), hipervizör incelemesi (hypervisor introspection) veya kaba sistem çağrısı telemetrisi (coarse system-call telemetry) merkezli yaklaşımlarla karşılaştırıldığında, benimsediğimiz fonksiyon seviyesi izleme, yalnızca sistem çağrısı telemetrisinden daha ince davranışsal ayrıntı sağlar ve sanal alan tabanlı yaklaşımların sanallaştırma/VMI yükünü (virtualization/VMI overhead) önler. Mevcut kullanıcı alanı prototipimiz, ani G/Ç (burst I/O) altında önemsiz olmayan bir ayak izine sahiptir; bunu ölçümlendiriyoruz ve üretim ortamı çekirdek alanı (kernel-space) çözümünün bunu ele almayı hedeflemesi gerektiğini kabul ediyoruz. Veri kümesi oluşturma, model eğitimi ve kural çıkarma işlemleri ile şüpheli şifreleme için dosya yazma işlemlerini denetleyen ve aynı zamanda iyi niyetli kriptografik iş akışlarını koruyan çalışma zamanı entegrasyonunu detaylandırıyoruz. Değerlendirme sırasında, iki katmanlı bileşim, kural benzeri duyarlılık sağlarken model düzeyinde tespit kalitesini korur; ayrıca operasyonel ayak izini ölçümlendirir ve kurumsal dağıtım için CPU ve bellek yükünü azaltmaya yönelik mühendislik adımlarını ana hatlarıyla belirtiriz. Sonuç, üretim ortamı Linux sistemlerinde davranışsal izleme ve öğrenmeden zorunlu, açıklanabilir ve risk orantılı şifreleme kontrolüne pratik bir yol sunmaktadır."
    }
  },
  {
    "id": "2601.16589v1",
    "title": "Emerging Threats and Countermeasures in Neuromorphic Systems: A Survey",
    "authors": [
      "Pablo Sorrentino",
      "Stjepan Picek",
      "Ihsen Alouani",
      "Nikolaos Athanasios Anagnostopoulos",
      "Francesco Regazzoni"
    ],
    "published_date": "2026-01-23",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.ET"
    ],
    "link": "http://arxiv.org/abs/2601.16589v1",
    "pdf_link": "https://arxiv.org/pdf/2601.16589v1",
    "content": {
      "en": "Neuromorphic computing mimics brain-inspired mechanisms through spiking neurons and energy-efficient processing, offering a pathway to efficient in-memory computing (IMC). However, these advancements raise critical security and privacy concerns. As the adoption of bio-inspired architectures and memristive devices increases, so does the urgency to assess the vulnerability of these emerging technologies to hardware and software attacks. Emerging architectures introduce new attack surfaces, particularly due to asynchronous, event-driven processing and stochastic device behavior. The integration of memristors into neuromorphic hardware and software implementations in spiking neural networks offers diverse possibilities for advanced computing architectures, including their role in security-aware applications. This survey systematically analyzes the security landscape of neuromorphic systems, covering attack methodologies, side-channel vulnerabilities, and countermeasures. We focus on both hardware and software concerns relevant to spiking neural networks (SNNs) and hardware primitives, such as Physical Unclonable Functions (PUFs) and True Random Number Generators (TRNGs) for cryptographic and secure computation applications. We approach this analysis from diverse perspectives, from attack methodologies to countermeasure strategies that integrate efficiency and protection in brain-inspired hardware. This review not only maps the current landscape of security threats but provides a foundation for developing secure and trustworthy neuromorphic architectures.",
      "tr": "**Makale Başlığı:** Nöromorfik Sistemlerde Ortaya Çıkan Tehditler ve Karşı Önlemler: Bir Derleme\n\n**Özet:**\n\nNöromorfik bilişim, sivri uçlu nöronlar ve enerji verimli işlem yoluyla beyin-esinlenilmiş mekanizmaları taklit ederek, verimli bellekte bilişim (IMC) için bir yol sunmaktadır. Bununla birlikte, bu gelişmeler kritik güvenlik ve gizlilik endişelerini de beraberinde getirmektedir. Biyo-esinlenilmiş mimarilerin ve memristör cihazlarının benimsenmesi arttıkça, bu gelişmekte olan teknolojilerin donanım ve yazılım saldırılarına karşı savunmasızlığının değerlendirilmesi aciliyeti de artmaktadır. Gelişmekte olan mimariler, özellikle asenkron, olay güdümlü işlem ve stokastik cihaz davranışları nedeniyle yeni saldırı yüzeyleri sunmaktadır. Memristörlerin nöromorfik donanıma entegrasyonu ve sivri uçlu sinir ağlarındaki (SNNs) yazılım uygulamaları, güvenlik-farkındalıklı uygulamalardaki rolleri de dahil olmak üzere, gelişmiş bilişim mimarileri için çeşitli olanaklar sunmaktadır. Bu derleme, saldırı metodolojilerini, yan kanal savunmasızlıklarını ve karşı önlemleri kapsayan nöromorfik sistemlerin güvenlik ortamını sistematik olarak analiz etmektedir. Kriptografik ve güvenli bilişim uygulamaları için Fiziksel Klonlanamaz Fonksiyonlar (PUFs) ve Gerçek Rastgele Sayı Üreteçleri (TRNGs) gibi donanım ilkel öğeleri ve sivri uçlu sinir ağları (SNNs) ile ilgili hem donanım hem de yazılım endişelerine odaklanmaktayız. Bu analizi, saldırı metodolojilerinden beyin-esinlenilmiş donanımda verimlilik ve korumayı entegre eden karşı önlem stratejilerine kadar çeşitli bakış açılarından ele alıyoruz. Bu inceleme, mevcut güvenlik tehditleri ortamını haritalamakla kalmayıp, aynı zamanda güvenli ve güvenilir nöromorfik mimariler geliştirmek için bir temel oluşturmaktadır."
    }
  },
  {
    "id": "2601.16506v1",
    "title": "SafeThinker: Reasoning about Risk to Deepen Safety Beyond Shallow Alignment",
    "authors": [
      "Xianya Fang",
      "Xianying Luo",
      "Yadong Wang",
      "Xiang Chen",
      "Yu Tian"
    ],
    "published_date": "2026-01-23",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.16506v1",
    "pdf_link": "https://arxiv.org/pdf/2601.16506v1",
    "content": {
      "en": "Despite the intrinsic risk-awareness of Large Language Models (LLMs), current defenses often result in shallow safety alignment, rendering models vulnerable to disguised attacks (e.g., prefilling) while degrading utility. To bridge this gap, we propose SafeThinker, an adaptive framework that dynamically allocates defensive resources via a lightweight gateway classifier. Based on the gateway's risk assessment, inputs are routed through three distinct mechanisms: (i) a Standardized Refusal Mechanism for explicit threats to maximize efficiency; (ii) a Safety-Aware Twin Expert (SATE) module to intercept deceptive attacks masquerading as benign queries; and (iii) a Distribution-Guided Think (DDGT) component that adaptively intervenes during uncertain generation. Experiments show that SafeThinker significantly lowers attack success rates across diverse jailbreak strategies without compromising utility, demonstrating that coordinating intrinsic judgment throughout the generation process effectively balances robustness and practicality.",
      "tr": "Makale Başlığı: SafeThinker: Sığ Hizalamanın Ötesinde Güvenliği Derinleştirmek İçin Risk Hakkında Reasoning\n\nÖzet:\nBüyük Dil Modellerinin (LLM'ler) doğasında bulunan risk farkındalığına rağmen, mevcut savunmalar genellikle sığ güvenlik hizalaması ile sonuçlanmakta, bu da modelleri gizlenmiş saldırılara (örneğin, önceden doldurma) karşı savunmasız hale getirirken kullanışlılığı düşürmektedir. Bu boşluğu kapatmak için, hafif bir gateway classifier aracılığıyla savunma kaynaklarını dinamik olarak tahsis eden adaptif bir çerçeve olan SafeThinker'ı öneriyoruz. Gateway'in risk değerlendirmesine dayanarak, girdiler üç farklı mekanizma aracılığıyla yönlendirilir: (i) verimliliği en üst düzeye çıkarmak için açık tehditlere yönelik bir Standardized Refusal Mechanism; (ii) zararsız sorgular gibi görünen aldatıcı saldırıları engellemek için bir Safety-Aware Twin Expert (SATE) modülü; ve (iii) belirsiz üretim sırasında adaptif olarak müdahale eden bir Distribution-Guided Think (DDGT) bileşeni. Deneyler, SafeThinker'ın kullanışlılıktan ödün vermeden çeşitli jailbreak stratejilerinde saldırı başarı oranlarını önemli ölçüde düşürdüğünü göstermektedir. Bu, üretim süreci boyunca içsel yargıyı koordine etmenin dayanıklılık ve pratikliği etkili bir şekilde dengelediğini ortaya koymaktadır."
    }
  },
  {
    "id": "2601.16473v1",
    "title": "DeMark: A Query-Free Black-Box Attack on Deepfake Watermarking Defenses",
    "authors": [
      "Wei Song",
      "Zhenchang Xing",
      "Liming Zhu",
      "Yulei Sui",
      "Jingling Xue"
    ],
    "published_date": "2026-01-23",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "link": "http://arxiv.org/abs/2601.16473v1",
    "pdf_link": "https://arxiv.org/pdf/2601.16473v1",
    "content": {
      "en": "The rapid proliferation of realistic deepfakes has raised urgent concerns over their misuse, motivating the use of defensive watermarks in synthetic images for reliable detection and provenance tracking. However, this defense paradigm assumes such watermarks are inherently resistant to removal. We challenge this assumption with DeMark, a query-free black-box attack framework that targets defensive image watermarking schemes for deepfakes. DeMark exploits latent-space vulnerabilities in encoder-decoder watermarking models through a compressive sensing based sparsification process, suppressing watermark signals while preserving perceptual and structural realism appropriate for deepfakes. Across eight state-of-the-art watermarking schemes, DeMark reduces watermark detection accuracy from 100% to 32.9% on average while maintaining natural visual quality, outperforming existing attacks. We further evaluate three defense strategies, including image super resolution, sparse watermarking, and adversarial training, and find them largely ineffective. These results demonstrate that current encoder decoder watermarking schemes remain vulnerable to latent-space manipulations, underscoring the need for more robust watermarking methods to safeguard against deepfakes.",
      "tr": "Makale Başlığı: DeMark: Derin Sahte Filigran Savunmalarına Karşı Sorgusuz Bir Kara Kutu Saldırısı\n\nÖzet:\nGerçekçi derin sahtelerin hızla yayılması, kötüye kullanımlarına ilişkin acil endişeleri artırmış ve güvenilir tespit ve köken takibi için sentetik görüntülerdeki savunma amaçlı filigranların kullanımını teşvik etmiştir. Ancak, bu savunma paradigması, bu tür filigranların doğası gereği kaldırılmaya karşı dirençli olduğunu varsaymaktadır. DeMark ile bu varsayımı sorguluyoruz. DeMark, derin sahteler için savunma amaçlı görüntü filigranlama şemalarını hedefleyen sorgusuz bir kara kutu saldırı çerçevesidir. DeMark, şifreleyici-çözücü (encoder-decoder) filigranlama modellerindeki gizli alan (latent-space) güvenlik açıklarından, sıkıştırılmış algılama (compressive sensing) tabanlı bir seyrekleştirme (sparsification) süreci aracılığıyla yararlanır; bu süreç, derin sahteler için uygun algısal ve yapısal gerçekçiliği korurken filigran sinyallerini bastırır. Sekiz adet en gelişmiş (state-of-the-art) filigranlama şeması üzerinde yapılan incelemelerde, DeMark ortalama olarak filigran tespit doğruluğunu %100'den %32.9'a düşürmekte ve doğal görsel kaliteyi korumaktadır; bu da mevcut saldırılardan daha iyi performans göstermektedir. Ayrıca, görüntü süper çözünürlüğü (image super resolution), seyrek filigranlama (sparse watermarking) ve düşman eğitimi (adversarial training) dahil olmak üzere üç savunma stratejisini değerlendirdik ve bunların büyük ölçüde etkisiz olduğunu bulduk. Bu sonuçlar, mevcut şifreleyici-çözücü (encoder-decoder) filigranlama şemalarının hala gizli alan (latent-space) manipülasyonlarına karşı savunmasız olduğunu göstermekte ve derin sahtelere karşı korunmak için daha sağlam filigranlama yöntemlerine olan ihtiyacı vurgulamaktadır."
    }
  },
  {
    "id": "2601.16354v1",
    "title": "NOIR: Privacy-Preserving Generation of Code with Open-Source LLMs",
    "authors": [
      "Khoa Nguyen",
      "Khiem Ton",
      "NhatHai Phan",
      "Issa Khalil",
      "Khang Tran"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.16354v1",
    "pdf_link": "https://arxiv.org/pdf/2601.16354v1",
    "content": {
      "en": "Although boosting software development performance, large language model (LLM)-powered code generation introduces intellectual property and data security risks rooted in the fact that a service provider (cloud) observes a client's prompts and generated code, which can be proprietary in commercial systems. To mitigate this problem, we propose NOIR, the first framework to protect the client's prompts and generated code from the cloud. NOIR uses an encoder and a decoder at the client to encode and send the prompts' embeddings to the cloud to get enriched embeddings from the LLM, which are then decoded to generate the code locally at the client. Since the cloud can use the embeddings to infer the prompt and the generated code, NOIR introduces a new mechanism to achieve indistinguishability, a local differential privacy protection at the token embedding level, in the vocabulary used in the prompts and code, and a data-independent and randomized tokenizer on the client side. These components effectively defend against reconstruction and frequency analysis attacks by an honest-but-curious cloud. Extensive analysis and results using open-source LLMs show that NOIR significantly outperforms existing baselines on benchmarks, including the Evalplus (MBPP and HumanEval, Pass@1 of 76.7 and 77.4), and BigCodeBench (Pass@1 of 38.7, only a 1.77% drop from the original LLM) under strong privacy against attacks.",
      "tr": "**Makale Başlığı:** NOIR: Açık Kaynaklı LLM'ler ile Gizliliği Koruyan Kod Üretimi\n\n**Özet:**\n\nYazılım geliştirme performansını artırmasına rağmen, büyük dil modeli (LLM) destekli kod üretimi, ticari sistemlerde potansiyel olarak telif hakkı alınmış kodları içeren istemlerin (prompts) ve üretilen kodun bir hizmet sağlayıcı (bulut) tarafından gözlemlenmesi gerçeğinden kaynaklanan fikri mülkiyet ve veri güvenliği riskleri barındırmaktadır. Bu sorunu hafifletmek amacıyla, istemleri ve üretilen kodu buluttan koruyan ilk framework olan NOIR'ı öneriyoruz. NOIR, istemlerin embedding'lerini kodlamak ve buluta göndermek için istemcide bir encoder ve decoder kullanır; böylece LLM'den zenginleştirilmiş embedding'ler elde edilir ve bunlar daha sonra istemcide kodu yerel olarak üretmek üzere decode edilir. Bulut, embedding'leri istemi ve üretilen kodu tahmin etmek için kullanabileceğinden, NOIR indistinguishability'yi sağlamak için yeni bir mekanizma sunar; bu mekanizma, istemlerde ve kodda kullanılan vocabulary'de yerel bir differential privacy koruması ve istemci tarafında veri bağımsız ve rastgeleleştirilmiş bir tokenizer içerir. Bu bileşenler, dürüst ama meraklı bir bulut tarafından yapılan yeniden yapılandırma ve frekans analizi saldırılarına karşı etkili bir şekilde savunma sağlar. Açık kaynaklı LLM'ler kullanılarak yapılan kapsamlı analizler ve sonuçlar, NOIR'ın Evalplus (MBPP ve HumanEval, Pass@1 %76,7 ve %77,4) ve BigCodeBench (Pass@1 %38,7, orijinal LLM'den yalnızca %1,77'lik bir düşüş) dahil olmak üzere güçlü gizlilik saldırılarına karşı koruma sağlayan benchmarklarda mevcut temel sistemlere kıyasla önemli ölçüde daha iyi performans gösterdiğini ortaya koymaktadır."
    }
  },
  {
    "id": "2601.16140v1",
    "title": "Learning to Watermark in the Latent Space of Generative Models",
    "authors": [
      "Sylvestre-Alvise Rebuffi",
      "Tuan Tran",
      "Valeriu Lacatusu",
      "Pierre Fernandez",
      "Tomáš Souček"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2601.16140v1",
    "pdf_link": "https://arxiv.org/pdf/2601.16140v1",
    "content": {
      "en": "Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.",
      "tr": "**Akademik Makale Başlığı:** Learning to Watermark in the Latent Space of Generative Models\n\n**Özet:**\n\nÜretken modeller tarafından üretilen yapay zeka görüntülerine yönelik mevcut watermarking yaklaşımları, genellikle piksel uzayında uygulanan ve hesaplama yükü ile potansiyel görsel artefaktlar getiren post-hoc yöntemlere dayanmaktadır. Bu çalışmada, latent uzay watermarking'ini araştırmaktayız ve latent watermarking için hem diffusion hem de autoregressive modellerde çalışan birleşik bir yaklaşım olan DistSeal'ı sunmaktayız. Yaklaşımımız, üretken modellerin latent uzayında post-hoc watermarking modellerini eğiterek çalışır. Bu latent watermarker'ların, ya üretken modelin kendisine ya da latent decoder'a etkili bir şekilde distilled edilebildiğini ve bu sayede model içi watermarking'i mümkün kıldığını göstermekteyiz. Elde edilen latent watermarker'lar, piksel uzayı tabanlı yöntemlere kıyasla benzer algılanamazlık ve 20 kata kadar hızlanma sunarken rekabetçi bir sağlamlık elde etmektedir. Deneylerimiz ayrıca, latent watermarker'ların distilled edilmesinin piksel uzayı olanlara göre daha üstün olduğunu ortaya koymaktadır, bu da hem daha verimli hem de daha sağlam bir çözüm sunmaktadır."
    }
  },
  {
    "id": "2601.15824v2",
    "title": "Introducing the Generative Application Firewall (GAF)",
    "authors": [
      "Joan Vendrell Farreny",
      "Martí Jordà Roca",
      "Miquel Cornudella Gaya",
      "Rodrigo Fernández Baón",
      "Víctor García Martínez"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.15824v2",
    "pdf_link": "https://arxiv.org/pdf/2601.15824v2",
    "content": {
      "en": "This paper introduces the Generative Application Firewall (GAF), a new architectural layer for securing LLM applications. Existing defenses -- prompt filters, guardrails, and data-masking -- remain fragmented; GAF unifies them into a single enforcement point, much like a WAF coordinates defenses for web traffic, while also covering autonomous agents and their tool interactions.",
      "tr": "Makale Başlığı: Üretken Uygulama Güvenlik Duvarının (GAF) Tanıtılması\n\nÖzet:\nBu makale, LLM uygulamalarını güvence altına almak için yeni bir mimari katman olan Üretken Uygulama Güvenlik Duvarını (GAF) tanıtmaktadır. Mevcut savunmalar – prompt filters, guardrails ve data-masking – parçalı kalmaktadır; GAF, bir WAF'ın web trafiği için savunmaları koordine etmesine benzer şekilde, bunları tek bir uygulama noktasına birleştirirken aynı zamanda autonomous agents ve onların tool interactions'larını da kapsamaktadır."
    }
  },
  {
    "id": "2601.15754v1",
    "title": "CAFE-GB: Scalable and Stable Feature Selection for Malware Detection via Chunk-wise Aggregated Gradient Boosting",
    "authors": [
      "Ajvad Haneef K",
      "Karan Kuwar Singh",
      "Madhu Kumar S D"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15754v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15754v1",
    "content": {
      "en": "High-dimensional malware datasets often exhibit feature redundancy, instability, and scalability limitations, which hinder the effectiveness and interpretability of machine learning-based malware detection systems. Although feature selection is commonly employed to mitigate these issues, many existing approaches lack robustness when applied to large-scale and heterogeneous malware data. To address this gap, this paper proposes CAFE-GB (Chunk-wise Aggregated Feature Estimation using Gradient Boosting), a scalable feature selection framework designed to produce stable and globally consistent feature rankings for high-dimensional malware detection. CAFE-GB partitions training data into overlapping chunks, estimates local feature importance using gradient boosting models, and aggregates these estimates to derive a robust global ranking. Feature budget selection is performed separately through a systematic k-selection and stability analysis to balance detection performance and robustness. The proposed framework is evaluated on two large-scale malware datasets: BODMAS and CIC-AndMal2020, representing large and diverse malware feature spaces. Experimental results show that classifiers trained on CAFE-GB -selected features achieve performance parity with full-feature baselines across multiple metrics, including Accuracy, F1-score, MCC, ROC-AUC, and PR-AUC, while reducing feature dimensionality by more than 95\\%. Paired Wilcoxon signed-rank tests confirm that this reduction does not introduce statistically significant performance degradation. Additional analyses demonstrate low inter-feature redundancy and improved interpretability through SHAP-based explanations. Runtime and memory profiling further indicate reduced downstream classification overhead. Overall, CAFE-GB provides a stable, interpretable, and scalable feature selection strategy for large-scale malware detection.",
      "tr": "Makale Başlığı: CAFE-GB: Kötü Amaçlı Yazılım Tespiti İçin Yığın-Bazlı Toplanmış Gradyan Artırma Yöntemi ile Ölçeklenebilir ve Kararlı Özellik Seçimi\n\nÖzet:\nYüksek boyutlu kötü amaçlı yazılım veri kümeleri sıklıkla özellik fazlalığı, kararsızlık ve ölçeklenebilirlik sınırlamaları sergiler. Bu durum, makine öğrenmesi tabanlı kötü amaçlı yazılım tespit sistemlerinin etkinliğini ve yorumlanabilirliğini engellemektedir. Özellik seçimi bu sorunları azaltmak için yaygın olarak kullanılsa da, mevcut yaklaşımların çoğu, büyük ölçekli ve heterojen kötü amaçlı yazılım verilerine uygulandığında dayanıklılık eksikliği göstermektedir. Bu boşluğu gidermek için, bu makale yüksek boyutlu kötü amaçlı yazılım tespiti için kararlı ve küresel olarak tutarlı özellik sıralamaları üretecek şekilde tasarlanmış ölçeklenebilir bir özellik seçimi çerçevesi olan CAFE-GB'yi (Chunk-wise Aggregated Feature Estimation using Gradient Boosting) önermektedir. CAFE-GB, eğitim verilerini üst üste binen parçalara ayırır, gradient boosting modelleri kullanarak yerel özellik önemini tahmin eder ve dayanıklı bir küresel sıralama elde etmek için bu tahminleri toplar. Özellik bütçesi seçimi, tespit performansı ve dayanıklılığı dengelemek için sistematik bir k-selection ve stability analysis yoluyla ayrı olarak gerçekleştirilir. Önerilen çerçeve, geniş ve çeşitli kötü amaçlı yazılım özellik alanlarını temsil eden iki büyük ölçekli kötü amaçlı yazılım veri kümesi üzerinde değerlendirilmiştir: BODMAS ve CIC-AndMal2020. Deneysel sonuçlar, CAFE-GB ile seçilen özellikler üzerinde eğitilen sınıflandırıcıların, Özelliklerin boyutunu %95'in üzerinde azaltırken, Accuracy, F1-score, MCC, ROC-AUC ve PR-AUC dahil olmak üzere birden çok metrikte tam özellikli taban çizgilerine eşit performans elde ettiğini göstermektedir. Eşleştirilmiş Wilcoxon signed-rank testleri, bu azalmanın istatistiksel olarak anlamlı bir performans düşüşü yaratmadığını doğrulamaktadır. Ek analizler, düşük özellikler arası fazlalığı ve SHAP-based explanations aracılığıyla iyileştirilmiş yorumlanabilirliği ortaya koymaktadır. Çalıştırma süresi ve bellek profillemesi, ayrıca aşağı akış sınıflandırma yükünün azaldığını göstermektedir. Genel olarak, CAFE-GB, büyük ölçekli kötü amaçlı yazılım tespiti için kararlı, yorumlanabilir ve ölçeklenebilir bir özellik seçimi stratejisi sunmaktadır."
    }
  },
  {
    "id": "2601.16241v1",
    "title": "A New Paradigm for Trusted Respiratory Monitoring Via Consumer Electronics-grade Radar Signals",
    "authors": [
      "Xinyu Li",
      "Jinyang Huang",
      "Feng-Qi Cui",
      "Meng Wang",
      "Peng Zhao"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.16241v1",
    "pdf_link": "https://arxiv.org/pdf/2601.16241v1",
    "content": {
      "en": "Respiratory monitoring is an extremely important task in modern medical services. Due to its significant advantages, e.g., non-contact, radar-based respiratory monitoring has attracted widespread attention from both academia and industry. Unfortunately, though it can achieve high monitoring accuracy, consumer electronics-grade radar data inevitably contains User-sensitive Identity Information (USI), which may be maliciously used and further lead to privacy leakage. To track these challenges, by variational mode decomposition (VMD) and adversarial loss-based encryption, we propose a novel Trusted Respiratory Monitoring paradigm, Tru-RM, to perform automated respiratory monitoring through radio signals while effectively anonymizing USI. The key enablers of Tru-RM are Attribute Feature Decoupling (AFD), Flexible Perturbation Encryptor (FPE), and robust Perturbation Tolerable Network (PTN) used for attribute decomposition, identity encryption, and perturbed respiratory monitoring, respectively. Specifically, AFD is designed to decompose the raw radar signals into the universal respiratory component, the personal difference component, and other unrelated components. Then, by using large noise to drown out the other unrelated components, and the phase noise algorithm with a learning intensity parameter to eliminate USI in the personal difference component, FPE is designed to achieve complete user identity information encryption without affecting respiratory features. Finally, by designing the transferred generalized domain-independent network, PTN is employed to accurately detect respiration when waveforms change significantly. Extensive experiments based on various detection distances, respiratory patterns, and durations demonstrate the superior performance of Tru-RM on strong anonymity of USI, and high detection accuracy of perturbed respiratory waveforms.",
      "tr": "Makale Başlığı: Tüketici Elektroniği Sınıfı Radar Sinyalleri Aracılığıyla Güvenilir Solunum İzleme İçin Yeni Bir Paradigm\n\nÖzet:\nSolunum izleme, modern tıbbi hizmetlerde son derece önemli bir görevdir. Önemli avantajları, örneğin temassız olması, nedeniyle radar tabanlı solunum izleme hem akademi hem de endüstri tarafından geniş ilgi görmektedir. Ne yazık ki, yüksek izleme doğruluğu elde edebilse de, tüketici elektroniği sınıfı radar verileri kaçınılmaz olarak Kullanıcı Hassas Kimlik Bilgisi (USI) içermektedir; bu da kötü amaçlı olarak kullanılabilir ve daha fazla gizlilik sızıntısına yol açabilir. Bu zorlukların üstesinden gelmek için, variational mode decomposition (VMD) ve adversarial loss-based encryption yoluyla, radyo sinyalleri aracılığıyla otomatik solunum izleme gerçekleştiren ve USI'yi etkili bir şekilde anonimleştiren yeni bir Güvenilir Solunum İzleme paradigması olan Tru-RM'yi öneriyoruz. Tru-RM'nin temel bileşenleri, sırasıyla nitelik ayrıştırma, kimlik şifreleme ve pertürbe edilmiş solunum izleme için kullanılan Attribute Feature Decoupling (AFD), Flexible Perturbation Encryptor (FPE) ve sağlam Perturbation Tolerable Network (PTN)'dir. Spesifik olarak AFD, ham radar sinyallerini evrensel solunum bileşeni, kişisel fark bileşeni ve diğer ilgisiz bileşenlere ayırmak için tasarlanmıştır. Ardından, diğer ilgisiz bileşenleri bastırmak için büyük gürültü kullanarak ve kişisel fark bileşenindeki USI'yi ortadan kaldırmak için bir öğrenme yoğunluğu parametresine sahip faz gürültüsü algoritması ile FPE, solunum özelliklerini etkilemeden tam kullanıcı kimlik bilgileri şifrelemesi elde etmek için tasarlanmıştır. Son olarak, aktarılmış genelleştirilmiş alan bağımsız ağı tasarlayarak, PTN dalga formlarının önemli ölçüde değiştiği durumlarda solunumu doğru bir şekilde tespit etmek için kullanılır. Çeşitli tespit mesafeleri, solunum desenleri ve sürelerine dayanan kapsamlı deneyler, Tru-RM'nin USI'nin güçlü anonimliği ve pertürbe edilmiş solunum dalga formlarının yüksek tespit doğruluğu üzerindeki üstün performansını göstermektedir."
    }
  },
  {
    "id": "2601.15697v1",
    "title": "Balancing Security and Privacy: The Pivotal Role of AI in Modern Healthcare Systems",
    "authors": [
      "Binu V P",
      "Deepthy K Bhaskar",
      "Minimol B"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15697v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15697v1",
    "content": {
      "en": "As digital threats continue to grow, organizations must find ways to enhance security while protecting user privacy. This paper explores how artificial intelligence (AI) plays a crucial role in achieving this balance. AI technologies can improve security by detecting threats, monitoring systems, and automating responses. However, using AI also raises privacy concerns that need careful consideration.We examine real-world examples from the healthcare sector to illustrate how organizations can implement AI solutions that strengthen security without compromising patient privacy. Additionally, we discuss the importance of creating transparent AI systems and adhering to privacy regulations.Ultimately, this paper provides insights and recommendations for integrating AI into healthcare security practices, helping organizations navigate the challenges of modern management while keeping patient data safe.",
      "tr": "**Makale Başlığı:** Siber Güvenlik ve Gizliliği Dengelemek: Modern Sağlık Sistemlerinde Yapay Zekanın Kilit Rolü\n\n**Özet:**\nDijital tehditler sürekli artarken, kuruluşlar güvenliği artırmanın yollarını bulmalı ve aynı zamanda kullanıcı gizliliğini korumalıdır. Bu makale, yapay zekanın (AI) bu dengeyi sağlamada ne kadar kritik bir rol oynadığını incelemektedir. AI teknolojileri, tehditleri tespit ederek, sistemleri izleyerek ve yanıtları otomatikleştirerek güvenliği artırabilir. Bununla birlikte, AI'ın kullanımı aynı zamanda dikkatli bir şekilde ele alınması gereken gizlilik endişelerini de beraberinde getirmektedir. Kuruluşların hasta gizliliğini tehlikeye atmadan güvenliği güçlendiren AI çözümlerini nasıl uygulayabileceğini göstermek için sağlık sektöründen gerçek dünya örneklerini inceliyoruz. Ek olarak, şeffaf AI sistemleri oluşturmanın ve gizlilik düzenlemelerine uymanın önemini tartışıyoruz. Nihayetinde, bu makale, kuruluşların modern yönetimin zorluklarında yol almasına yardımcı olurken hasta verilerini güvende tutmak için AI'ın sağlık güvenliği uygulamalarına entegrasyonuna ilişkin içgörüler ve öneriler sunmaktadır."
    }
  }
]