[
  {
    "id": "2601.16140v1",
    "title": "Learning to Watermark in the Latent Space of Generative Models",
    "authors": [
      "Sylvestre-Alvise Rebuffi",
      "Tuan Tran",
      "Valeriu Lacatusu",
      "Pierre Fernandez",
      "Tomáš Souček"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2601.16140v1",
    "pdf_link": "https://arxiv.org/pdf/2601.16140v1",
    "content": {
      "en": "Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.",
      "tr": "**Makale Başlığı: Üretici Modellerin Latent Uzayında Filigranlamayı Öğrenmek**\n\n**Özet:**\n\nYapay zeka tarafından üretilen görseller için mevcut filigranlama yaklaşımları genellikle piksel uzayında uygulanan post-hoc yöntemlere dayanmakta olup, bu da ek hesaplama yükü ve potansiyel görsel artefaktlar getirmektedir. Bu çalışmada, latent uzay filigranlamasını incelemekte ve hem difüzyon hem de otoregresif modellerde çalışan, birleştirilmiş bir latent filigranlama yaklaşımı olan DistSeal'i sunmaktayız. Yaklaşımımız, üretici modellerin latent uzayında post-hoc filigranlama modellerini eğiterek çalışır. Bu latent watermarkers'ların ya üretici modelin kendisine ya da latent decoder'a etkili bir şekilde distilled edilebileceğini, böylece in-model watermarking'i mümkün kıldığını göstermekteyiz. Elde edilen latent watermarks, benzer algılanamazlık sunarken ve piksel-uzaylı temel yöntemlere kıyasla 20 kata kadar hızlanma sağlarken rekabetçi bir robustless elde eder. Deneylerimiz, latent watermarkers'ları distilling etmenin piksel-uzaylı olanları distilling etmekten daha iyi performans gösterdiğini ve hem daha verimli hem de daha robust bir çözüm sunduğunu ortaya koymaktadır."
    }
  },
  {
    "id": "2601.15824v1",
    "title": "Introducing the Generative Application Firewall (GAF)",
    "authors": [
      "Joan Vendrell Farreny",
      "Martí Jordà Roca",
      "Miquel Cornudella Gaya",
      "Rodrigo Fernández Baón",
      "Víctor García Martínez"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.15824v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15824v1",
    "content": {
      "en": "This paper introduces the Generative Application Firewall (GAF), a new architectural layer for securing LLM applications. Existing defenses -- prompt filters, guardrails, and data-masking -- remain fragmented; GAF unifies them into a single enforcement point, much like a WAF coordinates defenses for web traffic, while also covering autonomous agents and their tool interactions.",
      "tr": "**Makale Başlığı:** Generative Application Firewall (GAF) Tanıtımı\n\n**Özet:**\n\nBu makale, LLM uygulamalarını güvence altına almak için yeni bir mimari katman olan Generative Application Firewall'ı (GAF) tanıtmaktadır. Mevcut savunmalar – prompt filters, guardrails ve data-masking – parçalı kalmaktadır; GAF, bir WAF'ın web trafiği için savunmaları koordine etmesine benzer şekilde, bunları tek bir uygulama noktasına entegre ederken, aynı zamanda otonom ajanları ve araç etkileşimlerini de kapsamaktadır."
    }
  },
  {
    "id": "2601.15754v1",
    "title": "CAFE-GB: Scalable and Stable Feature Selection for Malware Detection via Chunk-wise Aggregated Gradient Boosting",
    "authors": [
      "Ajvad Haneef K",
      "Karan Kuwar Singh",
      "Madhu Kumar S D"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15754v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15754v1",
    "content": {
      "en": "High-dimensional malware datasets often exhibit feature redundancy, instability, and scalability limitations, which hinder the effectiveness and interpretability of machine learning-based malware detection systems. Although feature selection is commonly employed to mitigate these issues, many existing approaches lack robustness when applied to large-scale and heterogeneous malware data. To address this gap, this paper proposes CAFE-GB (Chunk-wise Aggregated Feature Estimation using Gradient Boosting), a scalable feature selection framework designed to produce stable and globally consistent feature rankings for high-dimensional malware detection. CAFE-GB partitions training data into overlapping chunks, estimates local feature importance using gradient boosting models, and aggregates these estimates to derive a robust global ranking. Feature budget selection is performed separately through a systematic k-selection and stability analysis to balance detection performance and robustness. The proposed framework is evaluated on two large-scale malware datasets: BODMAS and CIC-AndMal2020, representing large and diverse malware feature spaces. Experimental results show that classifiers trained on CAFE-GB -selected features achieve performance parity with full-feature baselines across multiple metrics, including Accuracy, F1-score, MCC, ROC-AUC, and PR-AUC, while reducing feature dimensionality by more than 95\\%. Paired Wilcoxon signed-rank tests confirm that this reduction does not introduce statistically significant performance degradation. Additional analyses demonstrate low inter-feature redundancy and improved interpretability through SHAP-based explanations. Runtime and memory profiling further indicate reduced downstream classification overhead. Overall, CAFE-GB provides a stable, interpretable, and scalable feature selection strategy for large-scale malware detection.",
      "tr": "Makale Başlığı: CAFE-GB: Kötü Amaçlı Yazılım Tespiti İçin Parça Tabanlı Toplanmış Gradyan Artırma ile Ölçeklenebilir ve Kararlı Özellik Seçimi\n\nÖzet:\nYüksek boyutlu kötü amaçlı yazılım veri kümeleri sıklıkla özellik fazlalığı, istikrarsızlık ve ölçeklenebilirlik sınırlılıkları sergiler; bu durum, makine öğrenmesi tabanlı kötü amaçlı yazılım tespit sistemlerinin etkinliğini ve yorumlanabilirliğini engeller. Özellik seçimi bu sorunları azaltmak için yaygın olarak kullanılsa da, mevcut yaklaşımların çoğu büyük ölçekli ve heterojen kötü amaçlı yazılım verilerine uygulandığında sağlamlık eksikliği çekmektedir. Bu boşluğu gidermek için bu çalışma, yüksek boyutlu kötü amaçlı yazılım tespiti için kararlı ve küresel olarak tutarlı özellik sıralamaları üretmek üzere tasarlanmış ölçeklenebilir bir özellik seçimi çerçevesi olan CAFE-GB'yi (Chunk-wise Aggregated Feature Estimation using Gradient Boosting) önermektedir. CAFE-GB, eğitim verilerini örtüşen parçalara ayırır, gradient boosting modellerini kullanarak yerel özellik önemini tahmin eder ve sağlam bir küresel sıralama türetmek için bu tahminleri toplar. Özellik bütçesi seçimi, tespit performansı ve sağlamlığı dengelemek için sistematik bir k-selection ve stability analysis aracılığıyla ayrı olarak gerçekleştirilir. Önerilen çerçeve, büyük ve çeşitli kötü amaçlı yazılım özellik alanlarını temsil eden iki büyük ölçekli kötü amaçlı yazılım veri kümesi üzerinde değerlendirilmiştir: BODMAS ve CIC-AndMal2020. Deneysel sonuçlar, CAFE-GB -seçilmiş özelliklerle eğitilen sınıflandırıcıların, özellik boyutluluğunu %95'ten fazla azaltırken, Accuracy, F1-score, MCC, ROC-AUC ve PR-AUC dahil olmak üzere birden çok metrikte tam özellikli temellerle performans denkliği elde ettiğini göstermektedir. Eşleştirilmiş Wilcoxon signed-rank testleri, bu azaltmanın istatistiksel olarak anlamlı bir performans düşüşüne neden olmadığını doğrulamaktadır. Ek analizler, düşük özellikler arası fazlalığı ve SHAP-based explanations aracılığıyla iyileştirilmiş yorumlanabilirliği göstermektedir. Runtime ve memory profiling ayrıca azalan downstream classification maliyetini de göstermektedir. Genel olarak, CAFE-GB, büyük ölçekli kötü amaçlı yazılım tespiti için kararlı, yorumlanabilir ve ölçeklenebilir bir özellik seçimi stratejisi sunmaktadır."
    }
  },
  {
    "id": "2601.15697v1",
    "title": "Balancing Security and Privacy: The Pivotal Role of AI in Modern Healthcare Systems",
    "authors": [
      "Binu V P",
      "Deepthy K Bhaskar",
      "Minimol B"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15697v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15697v1",
    "content": {
      "en": "As digital threats continue to grow, organizations must find ways to enhance security while protecting user privacy. This paper explores how artificial intelligence (AI) plays a crucial role in achieving this balance. AI technologies can improve security by detecting threats, monitoring systems, and automating responses. However, using AI also raises privacy concerns that need careful consideration.We examine real-world examples from the healthcare sector to illustrate how organizations can implement AI solutions that strengthen security without compromising patient privacy. Additionally, we discuss the importance of creating transparent AI systems and adhering to privacy regulations.Ultimately, this paper provides insights and recommendations for integrating AI into healthcare security practices, helping organizations navigate the challenges of modern management while keeping patient data safe.",
      "tr": "**Makale Başlığı:** Dijital Güvenlik ve Kullanıcı Mahremiyetinin Dengelenmesi: Modern Sağlık Sistemlerinde Yapay Zekanın Kilit Rolü\n\n**Özet:**\n\nDijital tehditlerin artışıyla birlikte, kuruluşların güvenliklerini güçlendirirken aynı zamanda kullanıcı mahremiyetini koruma yolları bulmaları zorunlu hale gelmiştir. Bu makale, yapay zekanın (AI) bu dengeyi sağlamada nasıl kritik bir rol oynadığını incelemektedir. AI teknolojileri, tehditleri tespit ederek, sistemleri izleyerek ve yanıtları otomatikleştirerek güvenliği iyileştirebilir. Bununla birlikte, AI kullanımı aynı zamanda dikkatli bir şekilde ele alınması gereken mahremiyet endişelerini de beraberinde getirmektedir.\n\nBu makalede, kuruluşların hasta mahremiyetini tehlikeye atmadan güvenliği güçlendiren AI çözümlerini nasıl uygulayabileceğini göstermek amacıyla sağlık sektöründen gerçek dünya örnekleri incelenmektedir. Ek olarak, şeffaf AI sistemleri oluşturmanın ve mahremiyet düzenlemelerine uymanın önemi tartışılmaktadır. Nihayetinde, bu makale, modern yönetim zorluklarında yol alırken hasta verilerini güvende tutmaya yardımcı olacak şekilde, AI'nın sağlık güvenliği uygulamalarına entegrasyonu için içgörüler ve öneriler sunmaktadır."
    }
  },
  {
    "id": "2601.15678v1",
    "title": "Connect the Dots: Knowledge Graph-Guided Crawler Attack on Retrieval-Augmented Generation Systems",
    "authors": [
      "Mengyu Yao",
      "Ziqi Zhang",
      "Ning Luo",
      "Shaofei Li",
      "Yifeng Cai"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15678v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15678v1",
    "content": {
      "en": "Retrieval-augmented generation (RAG) systems integrate document retrieval with large language models and have been widely adopted. However, in privacy-related scenarios, RAG introduces a new privacy risk: adversaries can issue carefully crafted queries to exfiltrate sensitive content from the underlying corpus gradually. Although recent studies have demonstrated multi-turn extraction attacks, they rely on heuristics and fail to perform long-term extraction planning. To address these limitations, we formulate the RAG extraction attack as an adaptive stochastic coverage problem (ASCP). In ASCP, each query is treated as a probabilistic action that aims to maximize conditional marginal gain (CMG), enabling principled long-term planning under uncertainty. However, integrating ASCP with practical RAG attack faces three key challenges: unobservable CMG, intractability in the action space, and feasibility constraints. To overcome these challenges, we maintain a global attacker-side state to guide the attack. Building on this idea, we introduce RAGCRAWLER, which builds a knowledge graph to represent revealed information, uses this global state to estimate CMG, and plans queries in semantic space that target unretrieved regions. In comprehensive experiments across diverse RAG architectures and datasets, our proposed method, RAGCRAWLER, consistently outperforms all baselines. It achieves up to 84.4% corpus coverage within a fixed query budget and deliver an average improvement of 20.7% over the top-performing baseline. It also maintains high semantic fidelity and strong content reconstruction accuracy with low attack cost. Crucially, RAGCRAWLER proves its robustness by maintaining effectiveness against advanced RAG systems employing query rewriting and multi-query retrieval strategies. Our work reveals significant security gaps and highlights the pressing need for stronger safeguards for RAG.",
      "tr": "**Makale Başlığı:** Connect the Dots: Knowledge Graph-Guided Crawler Attack on Retrieval-Augmented Generation Systems\n\n**Özet:**\n\nRetrieval-augmented generation (RAG) sistemleri, belge erişimini büyük dil modelleriyle entegre ederek geniş çapta benimsenmiştir. Bununla birlikte, gizlilikle ilgili senaryolarda RAG yeni bir gizlilik riski oluşturmaktadır: düşmanlar, altta yatan veri kümesinden hassas içeriği kademeli olarak dışarı çıkarmak için özenle hazırlanmış sorgular yürütebilirler. Son çalışmalar çok turlu çıkarım saldırılarını gösterse de, bu çalışmalar sezgilere dayanmakta ve uzun vadeli çıkarım planlaması yapamamaktadır. Bu sınırlılıkları ele almak için, RAG çıkarım saldırısını adaptive stochastic coverage problem (ASCP) olarak formüle ediyoruz. ASCP'de, her sorgu, conditional marginal gain (CMG) maksimize etmeyi amaçlayan olasılıksal bir eylem olarak ele alınır, bu da belirsizlik altında prensipli uzun vadeli planlamayı mümkün kılar. Ancak, ASCP'yi pratik RAG saldırısıyla entegre etmek üç temel zorlukla karşı karşıyadır: gözlemlenemeyen CMG, eylem uzayındaki karmaşıklık ve fizibilite kısıtlamaları. Bu zorlukların üstesinden gelmek için, saldırıyı yönlendirmek üzere küresel bir saldırgan tarafı durumu (global attacker-side state) sürdürüyoruz. Bu fikir üzerine, ortaya çıkan bilgileri temsil etmek için bir knowledge graph oluşturan, CMG'yi tahmin etmek için bu küresel durumu kullanan ve henüz erişilmeyen bölgeleri hedefleyen anlamsal uzayda (semantic space) sorgular planlayan RAGCRAWLER'ı sunuyoruz. Çeşitli RAG mimarileri ve veri kümeleri üzerindeki kapsamlı deneylerde, önerdiğimiz yöntem olan RAGCRAWLER, tüm taban çizgilerini (baselines) tutarlı bir şekilde geride bırakmaktadır. Sabit bir sorgu bütçesi dahilinde %84,4'e varan veri kümesi kapsamı elde etmekte ve en iyi performans gösteren taban çizgisine kıyasla ortalama %20,7'lik bir iyileşme sağlamaktadır. Ayrıca, yüksek anlamsal sadakat (semantic fidelity) ve düşük saldırı maliyetiyle güçlü içerik yeniden yapılandırma doğruluğunu (content reconstruction accuracy) korumaktadır. Kritik olarak, RAGCRAWLER, sorgu yeniden yazma (query rewriting) ve çoklu sorgu erişim (multi-query retrieval) stratejileri kullanan gelişmiş RAG sistemlerine karşı etkinliğini sürdürerek sağlamlığını kanıtlamaktadır. Çalışmamız, önemli güvenlik açıklarını ortaya koymakta ve RAG için daha güçlü korumaların acil ihtiyacını vurgulamaktadır."
    }
  },
  {
    "id": "2601.15663v1",
    "title": "TempoNet: Learning Realistic Communication and Timing Patterns for Network Traffic Simulation",
    "authors": [
      "Kristen Moore",
      "Diksha Goel",
      "Cody James Christopher",
      "Zhen Wang",
      "Minjune Kim"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15663v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15663v1",
    "content": {
      "en": "Realistic network traffic simulation is critical for evaluating intrusion detection systems, stress-testing network protocols, and constructing high-fidelity environments for cybersecurity training. While attack traffic can often be layered into training environments using red-teaming or replay methods, generating authentic benign background traffic remains a core challenge -- particularly in simulating the complex temporal and communication dynamics of real-world networks. This paper introduces TempoNet, a novel generative model that combines multi-task learning with multi-mark temporal point processes to jointly model inter-arrival times and all packet- and flow-header fields. TempoNet captures fine-grained timing patterns and higher-order correlations such as host-pair behavior and seasonal trends, addressing key limitations of GAN-, LLM-, and Bayesian-based methods that fail to reproduce structured temporal variation. TempoNet produces temporally consistent, high-fidelity traces, validated on real-world datasets. Furthermore, we show that intrusion detection models trained on TempoNet-generated background traffic perform comparably to those trained on real data, validating its utility for real-world security applications.",
      "tr": "**Makale Başlığı:** TempoNet: Ağ Trafiği Simülasyonu İçin Gerçekçi İletişim ve Zamanlama Desenlerini Öğrenmek\n\n**Özet:**\n\nGerçekçi ağ trafiği simülasyonu, saldırı tespit sistemlerinin değerlendirilmesi, ağ protokollerinin stres testlerinin yapılması ve siber güvenlik eğitimi için yüksek doğruluklu ortamların oluşturulması açısından kritiktir. Saldırı trafiği, red-teaming veya tekrar oynatma yöntemleri kullanılarak eğitim ortamlarına genellikle katmanlanabilirken, özellikle gerçek dünya ağlarının karmaşık zamansal ve iletişim dinamiklerini simüle etmede, özgün ve zararsız arka plan trafiği üretmek temel bir zorluk olmaya devam etmektedir. Bu makalede, multi-task learning ile multi-mark temporal point processes'i birleştiren, varış zamanlarını ve tüm paket ve akış başlığı alanlarını ortaklaşa modelleyen yeni bir üretici model olan TempoNet'i sunuyoruz. TempoNet, konak-çifti davranışları ve mevsimsel eğilimler gibi ince taneli zamanlama desenlerini ve üst düzey korelasyonları yakalayarak, yapılandırılmış zamansal değişimi yeniden üretemeyen GAN-, LLM- ve Bayesian-temelli yöntemlerin temel sınırlamalarını ele almaktadır. TempoNet, gerçek dünya veri kümeleri üzerinde doğrulanmış, zamansal olarak tutarlı ve yüksek doğruluklu izler üretir. Dahası, TempoNet ile üretilen arka plan trafiği üzerinde eğitilen saldırı tespit modellerinin, gerçek veriler üzerinde eğitilenlere kıyasla benzer performans gösterdiğini ortaya koyarak, gerçek dünya güvenlik uygulamaları için faydasını doğrulamaktayız."
    }
  },
  {
    "id": "2601.15652v1",
    "title": "Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models",
    "authors": [
      "Manish Bhatt"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.AI",
      "cs.CR",
      "cs.ET"
    ],
    "link": "http://arxiv.org/abs/2601.15652v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15652v1",
    "content": {
      "en": "Hallucinations in Large Language Models (LLMs) -- generations that are plausible but factually unfaithful -- remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims).   Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises (\"Sycophancy\").   This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.",
      "tr": "Makale Başlığı: Büyük Dil Modellerinde Halüsinasyon Tespiti için Predictive Coding ve Information Bottleneck\n\nÖzet:\nBüyük Dil Modelleri'ndeki (LLM) halüsinasyonlar -- yani olası görünen ancak gerçeklikten uzak üreticiler -- yüksek öncelikli kullanımlar için kritik bir engel olmaya devam etmektedir. Mevcut tespit yöntemleri genellikle hesaplama açısından pahalı harici retrieval loop'larına veya 70B+ parametre gerektiren opak black-box LLM judge'larına dayanmaktadır. Bu çalışmada, nörobilimden ilham alan sinyal tasarımı ile supervised machine learning'i birleştiren hibrit bir detection framework'i olan [Model Adı]'nı sunuyoruz. Predictive Coding (iç önceliklere karşı sürprizin nicelenmesi) ve Information Bottleneck (perturbasyon altında sinyal tutulmasının ölçülmesi) üzerine temellenen yorumlanabilir sinyaller çıkarıyoruz. Sistematik ablasyon yoluyla üç temel iyileştirmeyi gösteriyoruz: Entity-Focused Uptake (yüksek değerli token'lara odaklanma), Context Adherence (grounding gücünün ölçülmesi) ve Falsifiability Score (emin ama çelişkili iddiaların tespiti). HaluBench (n=200, mükemmel dengelenmiş) üzerinde yapılan değerlendirmede, teori güdümlü baseline'ımız 0.8017 AUROC elde etmektedir. BASE supervised modeller 0.8274 AUROC'a ulaşırken, IMPROVED özellikler performansı 0.8669 AUROC'a (%4.95 kazanç) yükseltmektedir, bu da mimariler arasında tutarlı iyileşmeler göstermektedir. Bu rekabetçi performans, Lynx'e kıyasla 75 kat daha az eğitim verisi (200'e karşılık 15.000 örnek), 1000 kat daha hızlı inference (5ms'ye karşılık 5s) kullanılarak ve tamamen yorumlanabilir kalarak elde edilmiştir. Kritik olarak, olumsuz bir sonuç raporluyoruz: Rationalization sinyali halüsinasyonları ayırt edememektedir, bu da LLM'lerin yanlış öncüller için tutarlı reasoning ürettiğini (\"Sycophancy\") önermektedir. Bu çalışma, sinyal mimarisinde kodlanmış domain knowledge'ın, LLM judge'larını ölçeklendirmeye kıyasla daha üstün data verimliliği sağladığını ve production deployment'a uygun, hafif (1M parametreden az), açıklanabilir modellerle güçlü performans elde ettiğini göstermektedir."
    }
  },
  {
    "id": "2601.15595v1",
    "title": "Data-Free Privacy-Preserving for LLMs via Model Inversion and Selective Unlearning",
    "authors": [
      "Xinjie Zhou",
      "Zhihui Yang",
      "Lechao Cheng",
      "Sai Wu",
      "Gang Chen"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15595v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15595v1",
    "content": {
      "en": "Large language models (LLMs) exhibit powerful capabilities but risk memorizing sensitive personally identifiable information (PII) from their training data, posing significant privacy concerns. While machine unlearning techniques aim to remove such data, they predominantly depend on access to the training data. This requirement is often impractical, as training data in real-world deployments is commonly proprietary or inaccessible. To address this limitation, we propose Data-Free Selective Unlearning (DFSU), a novel privacy-preserving framework that removes sensitive PII from an LLM without requiring its training data. Our approach first synthesizes pseudo-PII through language model inversion, then constructs token-level privacy masks for these synthetic samples, and finally performs token-level selective unlearning via a contrastive mask loss within a low-rank adaptation (LoRA) subspace. Extensive experiments on the AI4Privacy PII-Masking dataset using Pythia models demonstrate that our method effectively removes target PII while maintaining model utility.",
      "tr": "**Makale Başlığı:** Data-Free Privacy-Preserving for LLMs via Model Inversion and Selective Unlearning\n\n**Özet:**\n\nBüyük dil modelleri (LLM'ler) güçlü yetenekler sergilemekle birlikte, eğitim verilerinden hassas kişisel olarak tanımlanabilir bilgileri (PII) ezberleme riski taşır ve bu da önemli gizlilik endişeleri yaratır. Makine unlearning teknikleri bu tür verileri kaldırmayı amaçlasa da, bu teknikler çoğunlukla eğitim verilerine erişime dayanır. Gerçek dünya dağıtımlarında eğitim verilerinin yaygın olarak özel veya erişilemez olması nedeniyle bu gereklilik genellikle pratik değildir. Bu sınırlamanın üstesinden gelmek için, eğitim verilerine ihtiyaç duymadan bir LLM'den hassas PII'yi kaldıran yeni bir gizlilik koruma çerçevesi olan Data-Free Selective Unlearning (DFSU)'yu öneriyoruz. Yaklaşımımız ilk olarak language model inversion aracılığıyla psödo-PII sentezler, ardından bu sentetik örnekler için token-level privacy masks oluşturur ve son olarak bir low-rank adaptation (LoRA) subspace içinde contrastive mask loss yoluyla token-level selective unlearning gerçekleştirir. Pythia modellerini kullanarak AI4Privacy PII-Masking veri kümesi üzerinde yapılan kapsamlı deneyler, yöntemimizin modelin faydasını koruyarak hedef PII'yi etkili bir şekilde kaldırdığını göstermektedir."
    }
  },
  {
    "id": "2601.15474v1",
    "title": "Multi-Targeted Graph Backdoor Attack",
    "authors": [
      "Md Nabi Newaz Khan",
      "Abdullah Arafat Miah",
      "Yu Bi"
    ],
    "published_date": "2026-01-21",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2601.15474v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15474v1",
    "content": {
      "en": "Graph neural network (GNN) have demonstrated exceptional performance in solving critical problems across diverse domains yet remain susceptible to backdoor attacks. Existing studies on backdoor attack for graph classification are limited to single target attack using subgraph replacement based mechanism where the attacker implants only one trigger into the GNN model. In this paper, we introduce the first multi-targeted backdoor attack for graph classification task, where multiple triggers simultaneously redirect predictions to different target labels. Instead of subgraph replacement, we propose subgraph injection which preserves the structure of the original graphs while poisoning the clean graphs. Extensive experiments demonstrate the efficacy of our approach, where our attack achieves high attack success rates for all target labels with minimal impact on the clean accuracy. Experimental results on five dataset demonstrate the superior performance of our attack framework compared to the conventional subgraph replacement-based attack. Our analysis on four GNN models confirms the generalization capability of our attack which is effective regardless of the GNN model architectures and training parameters settings. We further investigate the impact of the attack design parameters including injection methods, number of connections, trigger sizes, trigger edge density and poisoning ratios. Additionally, our evaluation against state-of-the-art defenses (randomized smoothing and fine-pruning) demonstrates the robustness of our proposed multi-target attacks. This work highlights the GNN vulnerability against multi-targeted backdoor attack in graph classification task. Our source codes will be available at https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack.",
      "tr": "**Makale Başlığı:** Multi-Targeted Graph Backdoor Attack\n\n**Özet:**\n\nGraph neural network'ler (GNN'ler), çeşitli alanlardaki kritik problemleri çözmede olağanüstü performans göstermelerine rağmen, backdoor attack'lerine karşı hassaslığını korumaktadır. Graph classification'a yönelik mevcut backdoor attack çalışmaları, yalnızca tek bir hedef saldırıyla sınırlı kalıp, subgraph replacement bazlı bir mekanizma kullanarak saldırganın GNN modeline sadece bir tetikleyici yerleştirmesini içermektedir. Bu çalışmada, graph classification görevi için ilk kez multi-targeted backdoor attack'i sunuyoruz. Bu yaklaşımda, birden fazla tetikleyici eş zamanlı olarak farklı hedef etiketlere doğru tahminleri yönlendirmektedir. Subgraph replacement yerine, orijinal grafiklerin yapısını koruyarak temiz grafikleri zehirleyen subgraph injection'ı öneriyoruz. Kapsamlı deneyler, yaklaşımımızın etkinliğini göstermekte olup, saldırımız temiz doğruluğu minimum düzeyde etkileyerek tüm hedef etiketler için yüksek attack success rates'ler elde etmektedir. Beş veri kümesi üzerindeki deneysel sonuçlar, saldırı çerçevemizin geleneksel subgraph replacement tabanlı saldırılara kıyasla üstün performansını sergilemektedir. Dört GNN modeline yönelik analizimiz, saldırımızın genel yeteneğini doğrulamaktadır; bu saldırı, GNN model mimarilerinden ve eğitim parametre ayarlarından bağımsız olarak etkilidir. Ayrıca, injection methods, number of connections, trigger sizes, trigger edge density ve poisoning ratios gibi attack design parametrelerinin etkisini de incelemekteyiz. Ek olarak, state-of-the-art defenses'a (randomized smoothing ve fine-pruning) karşı yapılan değerlendirmemiz, önerdiğimiz multi-target attack'lerin robustluğunu göstermektedir. Bu çalışma, graph classification görevinde GNN'lerin multi-targeted backdoor attack'lere karşı hassasiyetini vurgulamaktadır. Kaynak kodlarımız https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack adresinde mevcuttur."
    }
  },
  {
    "id": "2601.15177v1",
    "title": "Dynamic Management of a Deep Learning-Based Anomaly Detection System for 5G Networks",
    "authors": [
      "Lorenzo Fernández Maimó",
      "Alberto Huertas Celdrán",
      "Manuel Gil Pérez",
      "Félix J. García Clemente",
      "Gregorio Martínez Pérez"
    ],
    "published_date": "2026-01-21",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.15177v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15177v1",
    "content": {
      "en": "Fog and mobile edge computing (MEC) will play a key role in the upcoming fifth generation (5G) mobile networks to support decentralized applications, data analytics and management into the network itself by using a highly distributed compute model. Furthermore, increasing attention is paid to providing user-centric cybersecurity solutions, which particularly require collecting, processing and analyzing significantly large amount of data traffic and huge number of network connections in 5G networks. In this regard, this paper proposes a MEC-oriented solution in 5G mobile networks to detect network anomalies in real-time and in autonomic way. Our proposal uses deep learning techniques to analyze network flows and to detect network anomalies. Moreover, it uses policies in order to provide an efficient and dynamic management system of the computing resources used in the anomaly detection process. The paper presents relevant aspects of the deployment of the proposal and experimental results to show its performance.",
      "tr": "İşte akademik makale başlığı ve özetinin istenen kriterlere göre Türkçeye çevrilmiş hali:\n\n**Makale Başlığı:** 5G Ağları İçin Derin Öğrenme Tabanlı Anomali Tespit Sisteminin Dinamik Yönetimi\n\n**Özet:**\nYaklaşan beşinci nesil (5G) mobil ağlarda, yüksek derecede dağıtılmış bir hesaplama modeli kullanarak ağın içine merkezi olmayan uygulamaları, veri analitiğini ve yönetimi desteklemek amacıyla fog ve mobile edge computing (MEC) anahtar rol oynayacaktır. Dahası, kullanıcı merkezli siber güvenlik çözümleri sunulmasına artan bir ilgi gösterilmektedir ki bu, özellikle 5G ağlarında önemli miktarda veri trafiği ve çok sayıda ağ bağlantısının toplanmasını, işlenmesini ve analiz edilmesini gerektirir. Bu bağlamda, bu makale 5G mobil ağlarında ağ anomalilerini gerçek zamanlı ve otonom bir şekilde tespit etmek için MEC odaklı bir çözüm önermektedir. Önerimiz, ağ akışlarını analiz etmek ve ağ anomalilerini tespit etmek için derin öğrenme tekniklerini kullanmaktadır. Ayrıca, anomali tespit sürecinde kullanılan hesaplama kaynaklarının verimli ve dinamik bir yönetim sistemini sağlamak amacıyla politikaları kullanmaktadır. Makale, önerinin dağıtımına ilişkin ilgili yönleri ve performansını göstermek için deneysel sonuçları sunmaktadır."
    }
  }
]