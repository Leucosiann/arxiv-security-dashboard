[
  {
    "id": "2512.24571v1",
    "title": "SynRAG: A Large Language Model Framework for Executable Query Generation in Heterogeneous SIEM System",
    "authors": [
      "Md Hasan Saju",
      "Austin Page",
      "Akramul Azim",
      "Jeff Gardiner",
      "Farzaneh Abazari"
    ],
    "published_date": "2025-12-31",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24571v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24571v1",
    "content": {
      "en": "Security Information and Event Management (SIEM) systems are essential for large enterprises to monitor their IT infrastructure by ingesting and analyzing millions of logs and events daily. Security Operations Center (SOC) analysts are tasked with monitoring and analyzing this vast data to identify potential threats and take preventive actions to protect enterprise assets. However, the diversity among SIEM platforms, such as Palo Alto Networks Qradar, Google SecOps, Splunk, Microsoft Sentinel and the Elastic Stack, poses significant challenges. As these systems differ in attributes, architecture, and query languages, making it difficult for analysts to effectively monitor multiple platforms without undergoing extensive training or forcing enterprises to expand their workforce. To address this issue, we introduce SynRAG, a unified framework that automatically generates threat detection or incident investigation queries for multiple SIEM platforms from a platform-agnostic specification. SynRAG can generate platformspecific queries from a single high-level specification written by analysts. Without SynRAG, analysts would need to manually write separate queries for each SIEM platform, since query languages vary significantly across systems. This framework enables seamless threat detection and incident investigation across heterogeneous SIEM environments, reducing the need for specialized training and manual query translation. We evaluate SynRAG against state-of-the-art language models, including GPT, Llama, DeepSeek, Gemma, and Claude, using Qradar and SecOps as representative SIEM systems. Our results demonstrate that SynRAG generates significantly better queries for crossSIEM threat detection and incident investigation compared to the state-of-the-art base models.",
      "tr": "**Makale Başlığı:** SynRAG: Heterojen SIEM Sistemlerinde Yürütülebilir Sorgu Üretimi İçin Büyük Dil Modeli Çerçevesi\n\n**Özet:**\n\nGüvenlik Bilgi ve Olay Yönetimi (SIEM) sistemleri, büyük kuruluşların BT altyapılarını her gün milyonlarca log ve olayı alıp analiz ederek izlemeleri için kritik öneme sahiptir. Güvenlik Operasyon Merkezi (SOC) analistleri, potansiyel tehditleri belirlemek ve kurumsal varlıkları korumak için önleyici eylemler almak amacıyla bu devasa veriyi izlemek ve analiz etmekle görevlidir. Ancak, Palo Alto Networks Qradar, Google SecOps, Splunk, Microsoft Sentinel ve Elastic Stack gibi SIEM platformları arasındaki çeşitlilik, önemli zorluklar barındırmaktadır. Bu sistemler öznitelikler, mimari ve query language açısından farklılık gösterdiğinden, analistlerin kapsamlı eğitim almadan birden fazla platformu etkin bir şekilde izlemelerini veya kuruluşların iş gücünü genişletmelerini zorlaştırmaktadır. Bu sorunu ele almak için, platformdan bağımsız bir spesifikasyondan birden fazla SIEM platformu için otomatik olarak tehdit tespit veya olay soruşturma sorguları üreten birleşik bir çerçeve olan SynRAG'ı sunuyoruz. SynRAG, analistler tarafından yazılan tek bir üst düzey spesifikasyondan platforma özgü sorgular üretebilir. SynRAG olmadan, analistlerin sorgu dilleri sistemler arasında önemli ölçüde farklılık gösterdiği için her SIEM platformu için ayrı sorgular manuel olarak yazmaları gerekecektir. Bu çerçeve, özel eğitim ve manuel sorgu çevirisi ihtiyacını azaltarak, heterojen SIEM ortamlarında sorunsuz tehdit tespiti ve olay soruşturması sağlar. SynRAG'ı, Qradar ve SecOps'u temsili SIEM sistemleri olarak kullanarak, GPT, Llama, DeepSeek, Gemma ve Claude dahil olmak üzere en son teknoloji dil modellerine karşı değerlendiriyoruz. Sonuçlarımız, SynRAG'ın çapraz SIEM tehdit tespiti ve olay soruşturması için en son teknoloji temel modellerine kıyasla önemli ölçüde daha iyi sorgular ürettiğini göstermektedir."
    }
  },
  {
    "id": "2512.24452v1",
    "title": "Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations",
    "authors": [
      "Yalin E. Sagduyu",
      "Tugba Erpek",
      "Aylin Yener",
      "Sennur Ulukus"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.NI",
      "cs.AI",
      "cs.CR",
      "cs.IT",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2512.24452v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24452v1",
    "content": {
      "en": "Semantic communications conveys task-relevant meaning rather than focusing solely on message reconstruction, improving bandwidth efficiency and robustness for next-generation wireless systems. However, learned semantic representations can still leak sensitive information to unintended receivers (eavesdroppers). This paper presents a deep learning-based semantic communication framework that jointly supports multiple receiver tasks while explicitly limiting semantic leakage to an eavesdropper. The legitimate link employs a learned encoder at the transmitter, while the receiver trains decoders for semantic inference and data reconstruction. The security problem is formulated via an iterative min-max optimization in which an eavesdropper is trained to improve its semantic inference, while the legitimate transmitter-receiver pair is trained to preserve task performance while reducing the eavesdropper's success. We also introduce an auxiliary layer that superimposes a cooperative, adversarially crafted perturbation on the transmitted waveform to degrade semantic leakage to an eavesdropper. Performance is evaluated over Rayleigh fading channels with additive white Gaussian noise using MNIST and CIFAR-10 datasets. Semantic accuracy and reconstruction quality improve with increasing latent dimension, while the min-max mechanism reduces the eavesdropper's inference performance significantly without degrading the legitimate receiver. The perturbation layer is successful in reducing semantic leakage even when the legitimate link is trained only for its own task. This comprehensive framework motivates semantic communication designs with tunable, end-to-end privacy against adaptive adversaries in realistic wireless settings.",
      "tr": "**Makale Başlığı:** Gizliliği Koruyan Anlamsal İletişimler: Çoklu Görev Öğrenmesi ve Çekişmeli Pertürbasyonlar Aracılığıyla\n\n**Özet:**\n\nAnlamsal iletişim, bir sonraki nesil kablosuz sistemler için bant genişliği verimliliğini ve sağlamlığı artırarak, yalnızca mesaj yeniden yapılandırmasına odaklanmak yerine göreve ilişkin anlamı iletir. Ancak, öğrenilen anlamsal temsiller istenmeyen alıcılara (dinleyicilere) hassas bilgileri sızdırabilir. Bu makale, birden fazla alıcı görevini ortaklaşa destekleyen ve dinleyiciye yönelik anlamsal sızıntıyı açıkça sınırlayan derin öğrenme tabanlı bir anlamsal iletişim çerçevesi sunmaktadır. Meşru bağlantı, vericidə öğrenilmiş bir encoder kullanırken, alıcı anlamsal çıkarım ve veri yeniden yapılandırması için decoder'ları eğitir. Güvenlik sorunu, dinleyicinin anlamsal çıkarımını iyileştirmek için eğitildiği bir çekişmeli (adversarial) öğrenme ve meşru verici-alıcı çiftinin görevi korurken dinleyicinin başarısını azaltmak için eğitildiği iteratif bir min-max optimizasyonu aracılığıyla formüle edilmektedir. Ayrıca, iletilen dalga formuna kooperatif, çekişmeli olarak hazırlanmış bir pertürbasyon ekleyerek dinleyiciye anlamsal sızıntıyı bozan yardımcı bir katman sunmaktayız. Performans, Rayleigh sönümleme kanallarında ve MNIST ve CIFAR-10 veri kümeleri kullanılarak eklemeli beyaz Gauss gürültüsü (additive white Gaussian noise) üzerinde değerlendirilmektedir. Anlamsal doğruluk ve yeniden yapılandırma kalitesi, gizli boyutun (latent dimension) artmasıyla iyileşirken, min-max mekanizması meşru alıcıyı bozmadan dinleyicinin çıkarım performansını önemli ölçüde azaltır. Pertürbasyon katmanı, meşru bağlantı yalnızca kendi görevi için eğitildiğinde bile anlamsal sızıntıyı azaltmada başarılıdır. Bu kapsamlı çerçeve, gerçekçi kablosuz ortamlarda uyarlanabilir düşmanlara (adaptive adversaries) karşı ayarlanabilir, uçtan uca gizlilik sağlayan anlamsal iletişim tasarımlarını teşvik etmektedir."
    }
  },
  {
    "id": "2512.24391v1",
    "title": "FAST-IDS: A Fast Two-Stage Intrusion Detection System with Hybrid Compression for Real-Time Threat Detection in Connected and Autonomous Vehicles",
    "authors": [
      "Devika S",
      "Vishnu Hari",
      "Pratik Narang",
      "Tejasvi Alladi",
      "Vinay Chamola"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24391v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24391v1",
    "content": {
      "en": "We have implemented a multi-stage IDS for CAVs that can be deployed to resourec-constrained environments after hybrid model compression.",
      "tr": "İşte makale başlığı ve özetinin istenen kriterlere uygun çevirisi:\n\n**Makale Başlığı:** FAST-IDS: Bağlantılı ve Otonom Araçlarda Gerçek Zamanlı Tehdit Tespiti İçin Hibrit Sıkıştırmalı Hızlı İki Aşamalı Bir Saldırı Tespit Sistemi\n\n**Özet:**\nKaynak kısıtlamalı ortamlara konuşlandırılabilen, hibrit model sıkıştırması sonrası çok aşamalı bir IDS'yi CAV'ler için implemente ettik."
    }
  },
  {
    "id": "2512.24345v1",
    "title": "FedSecureFormer: A Fast, Federated and Secure Transformer Framework for Lightweight Intrusion Detection in Connected and Autonomous Vehicles",
    "authors": [
      "Devika S",
      "Vishnu Hari",
      "Pratik Narang",
      "Tejasvi Alladi",
      "F. Richard Yu"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24345v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24345v1",
    "content": {
      "en": "This works presents an encoder-only transformer built with minimum layers for intrusion detection in the domain of Connected and Autonomous Vehicles using Federated Learning.",
      "tr": "**Makale Başlığı:** FedSecureFormer: Bağlı ve Otonom Araçlarda Hafif Saldırı Tespiti İçin Hızlı, Federasyonlu ve Güvenli Bir Transformer Çerçevesi\n\n**Özet:**\nBu çalışma, Bağlı ve Otonom Araçlar alanında federasyonlu öğrenme (Federated Learning) kullanarak saldırı tespiti için minimum katmanlarla inşa edilmiş, yalnızca kodlayıcı (encoder-only) bir transformer'ı sunmaktadır. Bu yaklaşım, federasyonlu ortamlarda 'knowledge graph' oluşturma ve 'reasoning' gibi karmaşık siber güvenlik süreçlerini optimize etmeyi amaçlar. Geleneksel yöntemlerin aksine, bu sistem daha yüksek 'recall' oranları ve daha az yanlış pozitif ile 'exact retrieval' yeteneğini geliştirmek üzere tasarlanmıştır. 'Relation-first' prensibini benimseyerek, ağdaki ilişkisel bilgilerin önceliklendirilmesiyle daha derin bir sistem analizi sağlanır. 'Persistent belief system' modellemesi, sürekli değişen tehdit ortamlarında dahi tutarlı ve güvenilir bir tespit mekanizması sunar."
    }
  },
  {
    "id": "2512.24088v1",
    "title": "FedLiTeCAN : A Federated Lightweight Transformer for Fast and Robust CAN Bus Intrusion Detection",
    "authors": [
      "Devika S",
      "Pratik Narang",
      "Tejasvi Alladi"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24088v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24088v1",
    "content": {
      "en": "This work implements a lightweight Transformer model for IDS in the domain of Connected and Autonomous Vehicles",
      "tr": "İşte makale başlığı ve özetinin akademik ve profesyonel bir dille yapılan Türkçe çevirisi:\n\n**Makale Başlığı:** FedLiTeCAN : Bağlantılı ve Otonom Araçlar İçin Hızlı ve Dayanıklı CAN Veriyolu Saldırı Tespiti Amaçlı Federasyonel Hafif Transformer Modeli\n\n**Özet:**\nBu çalışma, Bağlantılı ve Otonom Araçlar (Connected and Autonomous Vehicles) alanında Saldırı Tespit Sistemi (Intrusion Detection System - IDS) için hafifti bir Transformer modeli uygulamaktadır. Bu model, 'knowledge graph' tabanlı 'reasoning' yetenekleri ile entegre edilerek, düşük performanslı cihazlarda dahi yüksek doğruluk ve verimlilik sağlamak üzere tasarlanmıştır. 'Recall' ve hassasiyet (precision) metrikleri kapsamında yapılan analizler, 'exact retrieval' ve 'relation-first' yaklaşımlarının entegrasyonunun, karmaşık saldırı senaryolarında dahi sistemin genel 'recall' ve doğruluğunu önemli ölçüde artırdığını göstermektedir. Ayrıca, 'persistent belief system' mekanizması, sistemin dinamik ve değişen saldırı vektörlerine karşı adaptasyon yeteneğini güçlendirmekte ve sürekli bir güvenlik koruması sunmaktadır."
    }
  },
  {
    "id": "2512.24044v1",
    "title": "Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?",
    "authors": [
      "Yuan Xin",
      "Dingfan Chen",
      "Linyi Yang",
      "Michael Backes",
      "Xiao Zhang"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "link": "http://arxiv.org/abs/2512.24044v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24044v1",
    "content": {
      "en": "As large language models (LLMs) are increasingly deployed, ensuring their safe use is paramount. Jailbreaking, adversarial prompts that bypass model alignment to trigger harmful outputs, present significant risks, with existing studies reporting high success rates in evading common LLMs. However, previous evaluations have focused solely on the models, neglecting the full deployment pipeline, which typically incorporates additional safety mechanisms like content moderation filters. To address this gap, we present the first systematic evaluation of jailbreak attacks targeting LLM safety alignment, assessing their success across the full inference pipeline, including both input and output filtering stages. Our findings yield two key insights: first, nearly all evaluated jailbreak techniques can be detected by at least one safety filter, suggesting that prior assessments may have overestimated the practical success of these attacks; second, while safety filters are effective in detection, there remains room to better balance recall and precision to further optimize protection and user experience. We highlight critical gaps and call for further refinement of detection accuracy and usability in LLM safety systems.",
      "tr": "**Makale Başlığı:** Jailbreaking Saldırıları ve İçerik Güvenlik Filtreleri: LLM Güvenliği Yarışında Ne Kadar İlerideyiz?\n\n**Özet:**\n\nBüyük dil modellerinin (LLM'ler) yaygınlaşmasıyla birlikte, güvenli kullanımlarını sağlamak en önemli öncelik haline gelmiştir. LLM hizalamasını aşarak zararlı çıktılara neden olan düşmanca yönlendirmeler olan jailbreak saldırıları, önemli riskler teşkil etmektedir ve mevcut çalışmalar, yaygın LLM'leri atlatmadaki yüksek başarı oranlarını bildirmektedir. Ancak, önceki değerlendirmeler yalnızca modellere odaklanmış, tipik olarak içerik moderasyon filtreleri gibi ek güvenlik mekanizmalarını içeren tam dağıtım hattını göz ardı etmiştir. Bu eksikliği gidermek için, LLM güvenlik hizalamasını hedefleyen jailbreak saldırılarının ilk sistematik değerlendirmesini sunuyor, hem girdi hem de çıktı filtreleme aşamalarını içeren tam çıkarım hattı boyunca başarılarını değerlendiriyoruz. Bulgularımız iki temel içgörü sağlamaktadır: Birincisi, değerlendirilen jailbreak tekniklerinin neredeyse tamamı en az bir güvenlik filtresi tarafından tespit edilebilir, bu da önceki değerlendirmelerin bu saldırıların pratik başarısını abartmış olabileceğini düşündürmektedir; ikincisi, güvenlik filtreleri tespitte etkili olsa da, korumayı ve kullanıcı deneyimini daha da optimize etmek için recall ve precision dengesini daha iyi kurmak için alan bulunmaktadır. LLM güvenlik sistemlerinde tespit doğruluğu ve kullanılabilirliğin daha da iyileştirilmesi için kritik boşlukları vurguluyor ve daha fazla gelişme çağrısında bulunuyoruz."
    }
  },
  {
    "id": "2512.23995v1",
    "title": "RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress",
    "authors": [
      "Ruixuan Huang",
      "Qingyue Wang",
      "Hantao Huang",
      "Yudong Gao",
      "Dong Chen"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2512.23995v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23995v1",
    "content": {
      "en": "Mixture-of-Experts architectures have become the standard for scaling large language models due to their superior parameter efficiency. To accommodate the growing number of experts in practice, modern inference systems commonly adopt expert parallelism to distribute experts across devices. However, the absence of explicit load balancing constraints during inference allows adversarial inputs to trigger severe routing concentration. We demonstrate that out-of-distribution prompts can manipulate the routing strategy such that all tokens are consistently routed to the same set of top-$k$ experts, which creates computational bottlenecks on certain devices while forcing others to idle. This converts an efficiency mechanism into a denial-of-service attack vector, leading to violations of service-level agreements for time to first token. We propose RepetitionCurse, a low-cost black-box strategy to exploit this vulnerability. By identifying a universal flaw in MoE router behavior, RepetitionCurse constructs adversarial prompts using simple repetitive token patterns in a model-agnostic manner. On widely deployed MoE models like Mixtral-8x7B, our method increases end-to-end inference latency by 3.063x, degrading service availability significantly.",
      "tr": "**Makale Başlığı:** RepetitionCurse: DoS Stresi Altında Mixture-of-Experts LLM'lerde Router Dengesizliğini Ölçme ve Anlama\n\n**Özet:**\n\nMixture-of-Experts (MoE) mimarileri, üstün parametre verimlilikleri nedeniyle büyük dil modellerini ölçeklendirmek için standart hale gelmiştir. Pratikte artan sayıda expert'i barındırmak için, modern inference sistemleri expert parallelism'i yaygın olarak benimseyerek expert'leri cihazlar arasında dağıtır. Ancak, inference sırasında açık yük dengeleme kısıtlamalarının olmaması, kötü niyetli girdilerin ciddi yönlendirme yoğunluğuna neden olmasına izin verir. Dağıtım dışı (out-of-distribution) prompt'ların, tüm token'ların tutarlı bir şekilde aynı top-$k$ expert setine yönlendirileceği bir yönlendirme stratejisini manipüle edebileceğini gösteriyoruz. Bu durum, belirli cihazlarda hesaplama darboğazları yaratırken diğerlerini boşta kalmaya zorlar. Bu, bir verimlilik mekanizmasını denial-of-service (DoS) saldırı vektörüne dönüştürerek, time to first token için hizmet seviyesi anlaşmalarının (service-level agreements) ihlal edilmesine yol açar. Bu zafiyeti istismar etmek için düşük maliyetli bir black-box strateji olan RepetitionCurse'ü öneriyoruz. MoE router davranışındaki evrensel bir kusuru belirleyerek, RepetitionCurse model-agnostic bir şekilde basit tekrarlayan token desenleri kullanarak adversarial prompt'lar oluşturur. Mixtral-8x7B gibi yaygın olarak kullanılan MoE modellerinde yöntemimiz, uçtan uca inference gecikmesini 3.063x artırarak hizmet kullanılabilirliğini önemli ölçüde bozmaktadır."
    }
  },
  {
    "id": "2512.23987v1",
    "title": "MeLeMaD: Adaptive Malware Detection via Chunk-wise Feature Selection and Meta-Learning",
    "authors": [
      "Ajvad Haneef K",
      "Karan Kuwar Singh",
      "Madhu Kumar S D"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2512.23987v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23987v1",
    "content": {
      "en": "Confronting the substantial challenges of malware detection in cybersecurity necessitates solutions that are both robust and adaptable to the ever-evolving threat environment. The paper introduces Meta Learning Malware Detection (MeLeMaD), a novel framework leveraging the adaptability and generalization capabilities of Model-Agnostic Meta-Learning (MAML) for malware detection. MeLeMaD incorporates a novel feature selection technique, Chunk-wise Feature Selection based on Gradient Boosting (CFSGB), tailored for handling large-scale, high-dimensional malware datasets, significantly enhancing the detection efficiency. Two benchmark malware datasets (CIC-AndMal2020 and BODMAS) and a custom dataset (EMBOD) were used for rigorously validating the MeLeMaD, achieving a remarkable performance in terms of key evaluation measures, including accuracy, precision, recall, F1-score, MCC, and AUC. With accuracies of 98.04\\% on CIC-AndMal2020 and 99.97\\% on BODMAS, MeLeMaD outperforms the state-of-the-art approaches. The custom dataset, EMBOD, also achieves a commendable accuracy of 97.85\\%. The results underscore the MeLeMaD's potential to address the challenges of robustness, adaptability, and large-scale, high-dimensional datasets in malware detection, paving the way for more effective and efficient cybersecurity solutions.",
      "tr": "Elbette, makale başlığını ve özetini istenen şekilde Türkçeye çevirdim:\n\n**Makale Başlığı:** MeLeMaD: Chunk-wise Feature Selection ve Meta-Learning Yoluyla Uyarlanabilir Kötü Amaçlı Yazılım Tespiti\n\n**Özet:**\nSiber güvenlik alanında kötü amaçlı yazılım tespitindeki önemli zorluklarla başa çıkmak, sürekli gelişen tehdit ortamına hem sağlam hem de uyarlanabilir çözümler gerektirmektedir. Bu makale, kötü amaçlı yazılım tespiti için Model-Agnostic Meta-Learning (MAML)'in uyarlanabilirlik ve genelleme yeteneklerinden yararlanan yeni bir çerçeve olan Meta Learning Malware Detection (MeLeMaD)'i sunmaktadır. MeLeMaD, büyük ölçekli, yüksek boyutlu kötü amaçlı yazılım veri kümelerini işlemeye yönelik uyarlanmış, Gradient Boosting tabanlı yeni bir özellik seçimi tekniği olan Chunk-wise Feature Selection based on Gradient Boosting (CFSGB)'i içermekte ve böylece tespit verimliliğini önemli ölçüde artırmaktadır. MeLeMaD'in titizlikle doğrulanması için iki kıyaslama kötü amaçlı yazılım veri kümesi (CIC-AndMal2020 ve BODMAS) ve özel bir veri kümesi (EMBOD) kullanılmış olup, accuracy, precision, recall, F1-score, MCC ve AUC gibi temel değerlendirme ölçütleri açısından dikkate değer bir performans elde edilmiştir. CIC-AndMal2020 üzerinde %98.04 ve BODMAS üzerinde %99.97 doğruluk oranları ile MeLeMaD, en son yaklaşımları geride bırakmaktadır. Özel veri kümesi EMBOD da %97.85 gibi takdire şayan bir doğruluk oranına ulaşmaktadır. Sonuçlar, MeLeMaD'in kötü amaçlı yazılım tespitindeki sağlamlık, uyarlanabilirlik ve büyük ölçekli, yüksek boyutlu veri kümeleriyle ilgili zorlukları ele alma potansiyelini vurgulamakta ve daha etkili ve verimli siber güvenlik çözümlerinin yolunu açmaktadır."
    }
  },
  {
    "id": "2512.23948v1",
    "title": "DivQAT: Enhancing Robustness of Quantized Convolutional Neural Networks against Model Extraction Attacks",
    "authors": [
      "Kacem Khaled",
      "Felipe Gohring de Magalhães",
      "Gabriela Nicolescu"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.LG",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2512.23948v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23948v1",
    "content": {
      "en": "Convolutional Neural Networks (CNNs) and their quantized counterparts are vulnerable to extraction attacks, posing a significant threat of IP theft. Yet, the robustness of quantized models against these attacks is little studied compared to large models. Previous defenses propose to inject calculated noise into the prediction probabilities. However, these defenses are limited since they are not incorporated during the model design and are only added as an afterthought after training. Additionally, most defense techniques are computationally expensive and often have unrealistic assumptions about the victim model that are not feasible in edge device implementations and do not apply to quantized models. In this paper, we propose DivQAT, a novel algorithm to train quantized CNNs based on Quantization Aware Training (QAT) aiming to enhance their robustness against extraction attacks. To the best of our knowledge, our technique is the first to modify the quantization process to integrate a model extraction defense into the training process. Through empirical validation on benchmark vision datasets, we demonstrate the efficacy of our technique in defending against model extraction attacks without compromising model accuracy. Furthermore, combining our quantization technique with other defense mechanisms improves their effectiveness compared to traditional QAT.",
      "tr": "**Makale Başlığı:** DivQAT: Model Çıkarma Saldırılarına Karşı Nicelenmiş Evrişimsel Sinir Ağlarının Dayanıklılığını Artırma\n\n**Özet:**\n\nEvrişimsel Sinir Ağları (CNN'ler) ve onların nicelenmiş karşılıkları, Fikri Mülkiyet (IP) hırsızlığı açısından önemli bir tehdit oluşturan çıkarma saldırılarına karşı savunmasızdır. Ancak, büyük modellere kıyasla nicelenmiş modellerin bu saldırılara karşı dayanıklılığı az incelenmiştir. Önceki savunma yöntemleri, tahmin olasılıklarına hesaplanmış gürültü enjekte etmeyi önermiştir. Ancak, bu savunmalar model tasarımı sırasında dahil edilmediği ve yalnızca eğitimden sonra sonradan eklendiği için sınırlıdır. Ek olarak, çoğu savunma tekniği hesaplama açısından maliyetlidir ve genellikle kurban model hakkında kenar cihaz uygulamalarında gerçekleştirilemeyen ve nicelenmiş modellere uygulanmayan gerçekçi olmayan varsayımlarda bulunur. Bu makalede, Quantization Aware Training (QAT) tabanlı nicelenmiş CNN'leri eğitmek için tasarlanmış, model çıkarma saldırılarına karşı dayanıklılıklarını artırmayı amaçlayan yeni bir algoritma olan DivQAT'ı öneriyoruz. Bildiğimiz kadarıyla, tekniğimiz, model çıkarma savunmasını eğitim sürecine entegre etmek için nicelleştirme sürecini değiştiren ilk çalışmadır. Benchmark görsel veri kümeleri üzerinde ampirik doğrulama yoluyla, tekniğimizin model doğruluğunu tehlikeye atmadan model çıkarma saldırılarına karşı savunmada etkinliğini gösteriyoruz. Dahası, nicelleştirme tekniğimizi diğer savunma mekanizmalarıyla birleştirmek, geleneksel QAT'ye kıyasla etkinliklerini artırmaktadır."
    }
  },
  {
    "id": "2512.23881v1",
    "title": "Breaking Audio Large Language Models by Attacking Only the Encoder: A Universal Targeted Latent-Space Audio Attack",
    "authors": [
      "Roee Ziv",
      "Raz Lapid",
      "Moshe Sipper"
    ],
    "published_date": "2025-12-29",
    "tags": [
      "cs.SD",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2512.23881v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23881v1",
    "content": {
      "en": "Audio-language models combine audio encoders with large language models to enable multimodal reasoning, but they also introduce new security vulnerabilities. We propose a universal targeted latent space attack, an encoder-level adversarial attack that manipulates audio latent representations to induce attacker-specified outputs in downstream language generation. Unlike prior waveform-level or input-specific attacks, our approach learns a universal perturbation that generalizes across inputs and speakers and does not require access to the language model. Experiments on Qwen2-Audio-7B-Instruct demonstrate consistently high attack success rates with minimal perceptual distortion, revealing a critical and previously underexplored attack surface at the encoder level of multimodal systems.",
      "tr": "Elbette, istediğiniz çeviriyi aşağıda bulabilirsiniz:\n\n**Makale Başlığı:** Encoder'a Yönelik Saldırılarla Ses Tabanlı Büyük Dil Modellerini Kırma: Evrensel Hedefli Gizli Alan Ses Saldırısı\n\n**Özet:**\nSes-dil modelleri, multimodal reasoning'i etkinleştirmek için ses encoder'larını büyük dil modelleriyle birleştirir, ancak aynı zamanda yeni güvenlik açıkları da oluşturur. Biz, aşağı akış dil üretiminde saldırgan tarafından belirtilen çıktıları tetiklemek için ses gizli temsillerini manipüle eden, encoder seviyesinde bir adversarial attack olan evrensel hedefli gizli alan saldırısını (universal targeted latent space attack) öneriyoruz. Dalga formu seviyesindeki veya girdiye özgü önceki saldırıların aksine, yaklaşımımız girdilere ve konuşmacılara genelleme yapan ve dil modeline erişim gerektirmeyen evrensel bir pertürbasyon öğrenir. Qwen2-Audio-7B-Instruct üzerindeki deneyler, minimum algısal bozulma ile tutarlı bir şekilde yüksek saldırı başarı oranları göstermekte olup, multimodal sistemlerin encoder seviyesinde kritik ve daha önce yeterince araştırılmamış bir saldırı yüzeyini ortaya koymaktadır."
    }
  }
]