[
  {
    "id": "2512.24571v1",
    "title": "SynRAG: A Large Language Model Framework for Executable Query Generation in Heterogeneous SIEM System",
    "authors": [
      "Md Hasan Saju",
      "Austin Page",
      "Akramul Azim",
      "Jeff Gardiner",
      "Farzaneh Abazari"
    ],
    "published_date": "2025-12-31",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24571v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24571v1",
    "content": {
      "en": "Security Information and Event Management (SIEM) systems are essential for large enterprises to monitor their IT infrastructure by ingesting and analyzing millions of logs and events daily. Security Operations Center (SOC) analysts are tasked with monitoring and analyzing this vast data to identify potential threats and take preventive actions to protect enterprise assets. However, the diversity among SIEM platforms, such as Palo Alto Networks Qradar, Google SecOps, Splunk, Microsoft Sentinel and the Elastic Stack, poses significant challenges. As these systems differ in attributes, architecture, and query languages, making it difficult for analysts to effectively monitor multiple platforms without undergoing extensive training or forcing enterprises to expand their workforce. To address this issue, we introduce SynRAG, a unified framework that automatically generates threat detection or incident investigation queries for multiple SIEM platforms from a platform-agnostic specification. SynRAG can generate platformspecific queries from a single high-level specification written by analysts. Without SynRAG, analysts would need to manually write separate queries for each SIEM platform, since query languages vary significantly across systems. This framework enables seamless threat detection and incident investigation across heterogeneous SIEM environments, reducing the need for specialized training and manual query translation. We evaluate SynRAG against state-of-the-art language models, including GPT, Llama, DeepSeek, Gemma, and Claude, using Qradar and SecOps as representative SIEM systems. Our results demonstrate that SynRAG generates significantly better queries for crossSIEM threat detection and incident investigation compared to the state-of-the-art base models.",
      "tr": "**Makale Başlığı:** SynRAG: Heterojen SIEM Sistemleri İçin Yürütülebilir Sorgu Üretimine Yönelik Bir Büyük Dil Modeli Çerçevesi\n\n**Özet:**\n\nGüvenlik Bilgi ve Olay Yönetimi (SIEM) sistemleri, büyük kurumsal yapılar için IT altyapılarını izlemek, günlük milyonlarca kaydı ve olayı işlemek ve analiz etmek açısından elzemdir. Güvenlik Operasyon Merkezi (SOC) analistleri, potansiyel tehditleri tespit etmek ve kurumsal varlıkları korumak için önleyici eylemler almak amacıyla bu devasa veriyi izleme ve analiz etme görevini üstlenir. Ancak, Palo Alto Networks Qradar, Google SecOps, Splunk, Microsoft Sentinel ve Elastic Stack gibi SIEM platformları arasındaki çeşitlilik, önemli zorluklar sunmaktadır. Bu sistemler öznitelikler, mimari ve sorgu dilleri açısından farklılık gösterdiğinden, analistlerin kapsamlı eğitimden geçmeden veya şirketlerin iş gücünü genişletmek zorunda kalmadan birden fazla platformu etkili bir şekilde izlemesi güçleşmektedir. Bu sorunu ele almak için, platform-bağımsız bir spesifikasyondan birden fazla SIEM platformu için otomatik olarak tehdit algılama veya olay inceleme sorguları üreten birleşik bir çerçeve olan SynRAG'ı sunuyoruz. SynRAG, analistler tarafından yazılan tek bir üst düzey spesifikasyondan platforma özgü sorgular üretebilir. SynRAG olmadan, sorgu dillerinin sistemler arasında önemli ölçüde farklılık göstermesi nedeniyle analistlerin her SIEM platformu için ayrı ayrı sorgular yazması gerekirdi. Bu çerçeve, heterojen SIEM ortamlarında sorunsuz tehdit algılama ve olay inceleme olanağı sağlayarak özel eğitim ve manuel sorgu çevirisi ihtiyacını azaltmaktadır. SynRAG'ı, Qradar ve SecOps'u temsili SIEM sistemleri olarak kullanarak, GPT, Llama, DeepSeek, Gemma ve Claude dahil olmak üzere en gelişmiş dil modellerine karşı değerlendiriyoruz. Sonuçlarımız, SynRAG'ın çapraz-SIEM tehdit algılama ve olay inceleme için en gelişmiş temel modellere kıyasla anlamlı derecede daha iyi sorgular ürettiğini göstermektedir."
    }
  },
  {
    "id": "2512.24452v1",
    "title": "Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations",
    "authors": [
      "Yalin E. Sagduyu",
      "Tugba Erpek",
      "Aylin Yener",
      "Sennur Ulukus"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.NI",
      "cs.AI",
      "cs.CR",
      "cs.IT",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2512.24452v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24452v1",
    "content": {
      "en": "Semantic communications conveys task-relevant meaning rather than focusing solely on message reconstruction, improving bandwidth efficiency and robustness for next-generation wireless systems. However, learned semantic representations can still leak sensitive information to unintended receivers (eavesdroppers). This paper presents a deep learning-based semantic communication framework that jointly supports multiple receiver tasks while explicitly limiting semantic leakage to an eavesdropper. The legitimate link employs a learned encoder at the transmitter, while the receiver trains decoders for semantic inference and data reconstruction. The security problem is formulated via an iterative min-max optimization in which an eavesdropper is trained to improve its semantic inference, while the legitimate transmitter-receiver pair is trained to preserve task performance while reducing the eavesdropper's success. We also introduce an auxiliary layer that superimposes a cooperative, adversarially crafted perturbation on the transmitted waveform to degrade semantic leakage to an eavesdropper. Performance is evaluated over Rayleigh fading channels with additive white Gaussian noise using MNIST and CIFAR-10 datasets. Semantic accuracy and reconstruction quality improve with increasing latent dimension, while the min-max mechanism reduces the eavesdropper's inference performance significantly without degrading the legitimate receiver. The perturbation layer is successful in reducing semantic leakage even when the legitimate link is trained only for its own task. This comprehensive framework motivates semantic communication designs with tunable, end-to-end privacy against adaptive adversaries in realistic wireless settings.",
      "tr": "Makale Başlığı: Gizlilik Korumalı Anlamsal İletişimler: Çoklu Görev Öğrenimi ve Çekişmeli Bozucu Etkiler Üzerinden\n\nÖzet:\nAnlamsal iletişimler, bir sonraki nesil kablosuz sistemler için bant genişliği verimliliğini ve sağlamlığını artırarak yalnızca mesaj yeniden yapımına odaklanmak yerine görevle ilgili anlamı iletir. Ancak, öğrenilmiş anlamsal temsiller, istenmeyen alıcılara (gizlice dinleyenler) hassas bilgileri sızdırabilir. Bu makale, birden fazla alıcı görevini ortaklaşa destekleyen ve aynı zamanda bir gizlice dinleyene yönelik anlamsal sızıntıyı açıkça sınırlayan derin öğrenme tabanlı bir anlamsal iletişim çerçevesi sunmaktadır. Meşru bağlantı, verici tarafında öğrenilmiş bir encoder kullanırken, alıcı anlamsal çıkarım ve veri yeniden yapımı için decoders eğitir. Güvenlik problemi, bir gizlice dinleyenin anlamsal çıkarımını iyileştirmek için eğitildiği, aynı zamanda meşru verici-alıcı çiftinin görev performansını korurken gizlice dinleyenin başarısını azalttığı yinelemeli bir min-max optimizasyonu aracılığıyla formüle edilir. Ayrıca, iletilen dalga biçimine, gizlice dinleyene yönelik anlamsal sızıntıyı bozmak için işbirlikçi, çekişmeli olarak tasarlanmış bir bozucu etki süperpozisyonu yapan yardımcı bir katman da tanıtılmaktadır. Performans, MNIST ve CIFAR-10 veri kümeleri kullanılarak eklemeli beyaz Gauss gürültüsü ile Rayleigh solma kanalları üzerinde değerlendirilir. Anlamsal doğruluk ve yeniden yapım kalitesi, artan gizli boyut ile iyileşirken, min-max mekanizması meşru alıcıyı bozmadan gizlice dinleyenin çıkarım performansını önemli ölçüde azaltır. Bozucu etki katmanı, meşru bağlantı yalnızca kendi görevi için eğitildiğinde bile anlamsal sızıntıyı azaltmada başarılıdır. Bu kapsamlı çerçeve, gerçekçi kablosuz ortamlarda uyarlanabilir düşmanlara karşı ayarlanabilir, uçtan uca gizlilik sağlayan anlamsal iletişim tasarımlarını teşvik etmektedir."
    }
  },
  {
    "id": "2512.24391v1",
    "title": "FAST-IDS: A Fast Two-Stage Intrusion Detection System with Hybrid Compression for Real-Time Threat Detection in Connected and Autonomous Vehicles",
    "authors": [
      "Devika S",
      "Vishnu Hari",
      "Pratik Narang",
      "Tejasvi Alladi",
      "Vinay Chamola"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24391v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24391v1",
    "content": {
      "en": "We have implemented a multi-stage IDS for CAVs that can be deployed to resourec-constrained environments after hybrid model compression.",
      "tr": "Elbette, makale başlığını ve özetini istenen şekilde çevirdim:\n\n**Makale Başlığı:** FAST-IDS: Bağlantılı ve Otonom Araçlarda Gerçek Zamanlı Tehdit Tespiti İçin Hibrit Sıkıştırmalı Hızlı İki Aşamalı Bir Saldırı Tespit Sistemi\n\n**Özet:**\nKaynak kısıtlı ortamlara dağıtılabilen hibrit model sıkıştırmasının ardından, bağlantılı ve otonom araçlar (CAVs) için çok aşamalı bir IDS (Intrusion Detection System) uyguladık."
    }
  },
  {
    "id": "2512.24345v1",
    "title": "FedSecureFormer: A Fast, Federated and Secure Transformer Framework for Lightweight Intrusion Detection in Connected and Autonomous Vehicles",
    "authors": [
      "Devika S",
      "Vishnu Hari",
      "Pratik Narang",
      "Tejasvi Alladi",
      "F. Richard Yu"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24345v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24345v1",
    "content": {
      "en": "This works presents an encoder-only transformer built with minimum layers for intrusion detection in the domain of Connected and Autonomous Vehicles using Federated Learning.",
      "tr": "Elbette, makale başlığı ve özetinin çevirisi aşağıdadır:\n\n**Makale Başlığı:** FedSecureFormer: Bağlantılı ve Otonom Araçlarda Hafif Saldırı Tespitine Yönelik Hızlı, Dağıtılmış ve Güvenli Bir Transformer Çerçevesi\n\n**Özet:**\nBu çalışma, Bağlantılı ve Otonom Araçlar alanında saldırı tespiti için minimum katmanlarla inşa edilmiş bir encoder-only transformer sunmaktadır. Bu yaklaşım, Federated Learning kullanılarak gerçekleştirilmektedir."
    }
  },
  {
    "id": "2512.24088v1",
    "title": "FedLiTeCAN : A Federated Lightweight Transformer for Fast and Robust CAN Bus Intrusion Detection",
    "authors": [
      "Devika S",
      "Pratik Narang",
      "Tejasvi Alladi"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24088v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24088v1",
    "content": {
      "en": "This work implements a lightweight Transformer model for IDS in the domain of Connected and Autonomous Vehicles",
      "tr": "**Makale Başlığı:** FedLiTeCAN : Bağlantılı ve Otonom Araçlar için Hızlı ve Sağlam CAN Veriyolu Saldırı Tespitine Yönelik Bir Federated Hafif Transformer Modeli\n\n**Özet:**\n\nBu çalışma, Bağlantılı ve Otonom Araçlar (Connected and Autonomous Vehicles) alanında Saldırı Tespit Sistemi (Intrusion Detection System - IDS) olarak görev yapacak, hafif bir Transformer modeli uygulamaktadır. Bu model, CAN veriyolu saldırılarının tespiti için hem etkinlik hem de verimlilik odaklı olarak tasarlanmıştır. FedLiTeCAN, dağıtık ortamlarda modelin eğitimini sağlayan federasyon öğrenme prensiplerini benimseyerek, merkezi bir veri toplama ve işleme ihtiyacını ortadan kaldırır. Bu yaklaşım, hassas verilerin korunmasını sağlarken, aynı zamanda büyük veri kümelerinin yönetilmesinde de esneklik sunar. Modelin hafifliği, gerçek zamanlı tespit gerektiren otonom araç sistemlerinin sınırlı işlem gücü ve bellek kaynaklarıyla uyumlu çalışmasını temin eder. FedLiTeCAN, siber güvenlik tehditlerine karşı daha hızlı ve daha sağlam bir savunma mekanizması oluşturmayı amaçlamaktadır."
    }
  },
  {
    "id": "2512.24044v1",
    "title": "Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?",
    "authors": [
      "Yuan Xin",
      "Dingfan Chen",
      "Linyi Yang",
      "Michael Backes",
      "Xiao Zhang"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "link": "http://arxiv.org/abs/2512.24044v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24044v1",
    "content": {
      "en": "As large language models (LLMs) are increasingly deployed, ensuring their safe use is paramount. Jailbreaking, adversarial prompts that bypass model alignment to trigger harmful outputs, present significant risks, with existing studies reporting high success rates in evading common LLMs. However, previous evaluations have focused solely on the models, neglecting the full deployment pipeline, which typically incorporates additional safety mechanisms like content moderation filters. To address this gap, we present the first systematic evaluation of jailbreak attacks targeting LLM safety alignment, assessing their success across the full inference pipeline, including both input and output filtering stages. Our findings yield two key insights: first, nearly all evaluated jailbreak techniques can be detected by at least one safety filter, suggesting that prior assessments may have overestimated the practical success of these attacks; second, while safety filters are effective in detection, there remains room to better balance recall and precision to further optimize protection and user experience. We highlight critical gaps and call for further refinement of detection accuracy and usability in LLM safety systems.",
      "tr": "Makale Başlığı: Jailbreaking Saldırıları ve İçerik Güvenliği Filtreleri: LLM Güvenliği Yarışında Ne Kadar İlerideyiz?\n\nÖzet:\nBüyük dil modelleri (LLM'ler) yaygınlaştıkça, güvenli kullanımlarının sağlanması hayati önem taşımaktadır. Jailbreaking, model hizalamasını atlatarak zararlı çıktılara neden olan advers prompts, önemli riskler teşkil etmekte olup, mevcut çalışmalar yaygın LLM'leri atlatmada yüksek başarı oranları bildirmektedir. Ancak, önceki değerlendirmeler yalnızca modellere odaklanmış, genellikle içerik moderasyon filtreleri gibi ek güvenlik mekanizmalarını içeren tam deployment pipeline'ını göz ardı etmiştir. Bu boşluğu gidermek için, LLM güvenlik hizalamasını hedef alan jailbreak saldırılarının ilk sistematik değerlendirmesini sunuyoruz; bu değerlendirme, hem input hem de output filtreleme aşamalarını içeren tam inference pipeline'ı boyunca başarılarını ölçmektedir. Bulgularımız iki temel içgörü sağlamaktadır: birincisi, değerlendirilen jailbreak tekniklerinin neredeyse tamamı en az bir güvenlik filtresi tarafından tespit edilebilir, bu da önceki değerlendirmelerin bu saldırıların pratik başarısını abartmış olabileceğini düşündürmektedir; ikincisi, güvenlik filtreleri tespitte etkili olsa da, korumayı ve kullanıcı deneyimini daha da optimize etmek için recall ve precision'ı dengelemek adına geliştirilebilecek alanlar bulunmaktadır. LLM güvenlik sistemlerinde tespit doğruluğu ve kullanılabilirlik alanındaki kritik boşluklara dikkat çekmekte ve daha fazla iyileştirme çağrısında bulunmaktayız."
    }
  },
  {
    "id": "2512.23995v1",
    "title": "RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress",
    "authors": [
      "Ruixuan Huang",
      "Qingyue Wang",
      "Hantao Huang",
      "Yudong Gao",
      "Dong Chen"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2512.23995v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23995v1",
    "content": {
      "en": "Mixture-of-Experts architectures have become the standard for scaling large language models due to their superior parameter efficiency. To accommodate the growing number of experts in practice, modern inference systems commonly adopt expert parallelism to distribute experts across devices. However, the absence of explicit load balancing constraints during inference allows adversarial inputs to trigger severe routing concentration. We demonstrate that out-of-distribution prompts can manipulate the routing strategy such that all tokens are consistently routed to the same set of top-$k$ experts, which creates computational bottlenecks on certain devices while forcing others to idle. This converts an efficiency mechanism into a denial-of-service attack vector, leading to violations of service-level agreements for time to first token. We propose RepetitionCurse, a low-cost black-box strategy to exploit this vulnerability. By identifying a universal flaw in MoE router behavior, RepetitionCurse constructs adversarial prompts using simple repetitive token patterns in a model-agnostic manner. On widely deployed MoE models like Mixtral-8x7B, our method increases end-to-end inference latency by 3.063x, degrading service availability significantly.",
      "tr": "**Makale Başlığı:** RepetitionCurse: DoS Stresi Altında Mixture-of-Experts LLM'lerde Yönlendirici Dengesizliğini Ölçme ve Anlama\n\n**Özet:**\n\nMixture-of-Experts mimarileri, üstün parametre verimlilikleri sayesinde büyük dil modellerini ölçeklendirmek için standart haline gelmiştir. Pratikte artan sayıda uzmanı barındırmak için modern çıkarım sistemleri, uzmanları cihazlara dağıtmak üzere yaygın olarak expert parallelism'i benimsemektedir. Ancak, çıkarım sırasında açık yük dengeleme kısıtlamalarının olmaması, kötü niyetli girdilerin ciddi yönlendirme konsantrasyonunu tetiklemesine izin vermektedir. Dağıtım dışı (out-of-distribution) istemlerin, tüm token'ların tutarlı bir şekilde aynı top-$k$ uzmana yönlendirilmesini sağlayacak şekilde yönlendirme stratejisini manipüle edebildiğini gösteriyoruz; bu durum, belirli cihazlarda hesaplama darboğazları yaratırken diğerlerini boşta kalmaya zorlamaktadır. Bu, bir verimlilik mekanizmasını hizmet reddi saldırı vektörüne dönüştürerek, zamanla ilk token'a ulaşma (time to first token) için hizmet seviyesi anlaşmalarının ihlal edilmesine yol açmaktadır. Bu zafiyetten yararlanmak için düşük maliyetli bir black-box stratejisi olan RepetitionCurse'ü öneriyoruz. MoE yönlendirici davranışındaki evrensel bir kusuru tespit ederek, RepetitionCurse, modelden bağımsız (model-agnostic) bir şekilde basit tekrarlayan token kalıpları kullanarak kötü niyetli istemler oluşturmaktadır. Mixtral-8x7B gibi yaygın olarak dağıtılmış MoE modellerinde, yöntemimiz uçtan uca çıkarım gecikmesini 3.063 kat artırarak hizmet kullanılabilirliğini önemli ölçüde düşürmektedir."
    }
  },
  {
    "id": "2512.23987v1",
    "title": "MeLeMaD: Adaptive Malware Detection via Chunk-wise Feature Selection and Meta-Learning",
    "authors": [
      "Ajvad Haneef K",
      "Karan Kuwar Singh",
      "Madhu Kumar S D"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2512.23987v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23987v1",
    "content": {
      "en": "Confronting the substantial challenges of malware detection in cybersecurity necessitates solutions that are both robust and adaptable to the ever-evolving threat environment. The paper introduces Meta Learning Malware Detection (MeLeMaD), a novel framework leveraging the adaptability and generalization capabilities of Model-Agnostic Meta-Learning (MAML) for malware detection. MeLeMaD incorporates a novel feature selection technique, Chunk-wise Feature Selection based on Gradient Boosting (CFSGB), tailored for handling large-scale, high-dimensional malware datasets, significantly enhancing the detection efficiency. Two benchmark malware datasets (CIC-AndMal2020 and BODMAS) and a custom dataset (EMBOD) were used for rigorously validating the MeLeMaD, achieving a remarkable performance in terms of key evaluation measures, including accuracy, precision, recall, F1-score, MCC, and AUC. With accuracies of 98.04\\% on CIC-AndMal2020 and 99.97\\% on BODMAS, MeLeMaD outperforms the state-of-the-art approaches. The custom dataset, EMBOD, also achieves a commendable accuracy of 97.85\\%. The results underscore the MeLeMaD's potential to address the challenges of robustness, adaptability, and large-scale, high-dimensional datasets in malware detection, paving the way for more effective and efficient cybersecurity solutions.",
      "tr": "Makale Başlığı: MeLeMaD: Chunk-wise Feature Selection ve Meta-Learning Yoluyla Adaptif Zararlı Yazılım Tespiti\n\nÖzet:\nSiber güvenlik alanındaki zararlı yazılım tespitindeki önemli zorluklarla yüzleşmek, hem sağlam hem de sürekli gelişen tehdit ortamına uyum sağlayabilen çözümler gerektirmektedir. Bu makale, zararlı yazılım tespiti için Model-Agnostic Meta-Learning (MAML)'in adaptasyon ve genelleme yeteneklerinden yararlanan yeni bir çerçeve olan Meta Learning Malware Detection (MeLeMaD)'i sunmaktadır. MeLeMaD, büyük ölçekli, yüksek boyutlu zararlı yazılım veri kümelerini işlemek için özel olarak tasarlanmış ve tespit verimliliğini önemli ölçüde artıran yeni bir özellik seçimi tekniği olan Gradient Boosting tabanlı Chunk-wise Feature Selection (CFSGB)'i bünyesinde barındırmaktadır. MeLeMaD'in CIC-AndMal2020 ve BODMAS olmak üzere iki karşılaştırmalı zararlı yazılım veri kümesi ve özel bir veri kümesi (EMBOD) üzerinde titizlikle doğrulanması, doğruluk, kesinlik, recall, F1-score, MCC ve AUC gibi temel değerlendirme ölçütleri açısından dikkate değer bir performans elde edilmesini sağlamıştır. CIC-AndMal2020 üzerinde %98.04, BODMAS üzerinde ise %99.97 doğruluk oranlarıyla MeLeMaD, en güncel yaklaşımların performansını aşmaktadır. Özel veri kümesi EMBOD de %97.85'lik takdire şayan bir doğruluk elde etmiştir. Elde edilen sonuçlar, MeLeMaD'in zararlı yazılım tespitinde karşılaşılan sağlamlık, adaptasyon ve büyük ölçekli, yüksek boyutlu veri kümeleri zorluklarını ele alma potansiyelini vurgulamakta, böylece daha etkili ve verimli siber güvenlik çözümlerinin yolunu açmaktadır."
    }
  },
  {
    "id": "2512.23948v1",
    "title": "DivQAT: Enhancing Robustness of Quantized Convolutional Neural Networks against Model Extraction Attacks",
    "authors": [
      "Kacem Khaled",
      "Felipe Gohring de Magalhães",
      "Gabriela Nicolescu"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.LG",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2512.23948v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23948v1",
    "content": {
      "en": "Convolutional Neural Networks (CNNs) and their quantized counterparts are vulnerable to extraction attacks, posing a significant threat of IP theft. Yet, the robustness of quantized models against these attacks is little studied compared to large models. Previous defenses propose to inject calculated noise into the prediction probabilities. However, these defenses are limited since they are not incorporated during the model design and are only added as an afterthought after training. Additionally, most defense techniques are computationally expensive and often have unrealistic assumptions about the victim model that are not feasible in edge device implementations and do not apply to quantized models. In this paper, we propose DivQAT, a novel algorithm to train quantized CNNs based on Quantization Aware Training (QAT) aiming to enhance their robustness against extraction attacks. To the best of our knowledge, our technique is the first to modify the quantization process to integrate a model extraction defense into the training process. Through empirical validation on benchmark vision datasets, we demonstrate the efficacy of our technique in defending against model extraction attacks without compromising model accuracy. Furthermore, combining our quantization technique with other defense mechanisms improves their effectiveness compared to traditional QAT.",
      "tr": "İşte akademik makale başlığı ve özetinin çevirisi:\n\n**Makale Başlığı:** DivQAT: Model Çıkarma Saldırılarına Karşı Kuantize Edilmiş Evrişimsel Sinir Ağlarının Dayanıklılığını Artırma\n\n**Özet:**\nEvrişimsel Sinir Ağları (CNN'ler) ve bunların kuantize edilmiş muadilleri, fikri mülkiyet hırsızlığı açısından önemli bir tehdit oluşturan çıkarma saldırılarına karşı savunmasızdır. Ancak, büyük modellere kıyasla kuantize edilmiş modellerin bu saldırılara karşı dayanıklılığı az çalışılmıştır. Önceki savunmalar, tahmin olasılıklarına hesaplanmış gürültü enjekte etmeyi önermiştir. Bununla birlikte, bu savunmalar model tasarımı sırasında entegre edilmediklerinden ve yalnızca eğitimden sonra sonradan eklendiklerinden sınırlıdır. Ek olarak, çoğu savunma tekniği hesaplama açısından pahalıdır ve genellikle kurban model hakkında kenar cihaz uygulamalarında uygulanabilir olmayan ve kuantize edilmiş modellere uygulanmayan gerçekçi olmayan varsayımlara sahiptir. Bu makalede, çıkarma saldırılarına karşı dayanıklılıklarını artırmayı hedefleyen Quantization Aware Training (QAT) tabanlı kuantize edilmiş CNN'leri eğitmek için yeni bir algoritma olan DivQAT'ı öneriyoruz. Bildiğimiz kadarıyla, tekniğimiz, model çıkarma savunmasını eğitim sürecine entegre etmek için kuantizasyon sürecini değiştiren ilk çalışmadır. Temel görsel veri kümeleri üzerindeki ampirik doğrulama yoluyla, model doğruluğundan ödün vermeden model çıkarma saldırılarına karşı savunmada tekniğimizin etkinliğini gösteriyoruz. Dahası, kuantizasyon tekniğimizi diğer savunma mekanizmalarıyla birleştirmek, geleneksel QAT ile karşılaştırıldığında etkinliklerini artırmaktadır."
    }
  },
  {
    "id": "2512.23881v1",
    "title": "Breaking Audio Large Language Models by Attacking Only the Encoder: A Universal Targeted Latent-Space Audio Attack",
    "authors": [
      "Roee Ziv",
      "Raz Lapid",
      "Moshe Sipper"
    ],
    "published_date": "2025-12-29",
    "tags": [
      "cs.SD",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2512.23881v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23881v1",
    "content": {
      "en": "Audio-language models combine audio encoders with large language models to enable multimodal reasoning, but they also introduce new security vulnerabilities. We propose a universal targeted latent space attack, an encoder-level adversarial attack that manipulates audio latent representations to induce attacker-specified outputs in downstream language generation. Unlike prior waveform-level or input-specific attacks, our approach learns a universal perturbation that generalizes across inputs and speakers and does not require access to the language model. Experiments on Qwen2-Audio-7B-Instruct demonstrate consistently high attack success rates with minimal perceptual distortion, revealing a critical and previously underexplored attack surface at the encoder level of multimodal systems.",
      "tr": "Makale Başlığı: Kodlayıcıya Yönelik Saldırılarla Ses Büyük Dil Modellerini Kırmak: Evrensel Hedeflenmiş Gizli Alan Ses Saldırısı\n\nÖzet:\nİşitsel dil modelleri, çok modlu akıl yürütmeyi etkinleştirmek amacıyla işitsel kodlayıcıları büyük dil modelleriyle birleştirir, ancak aynı zamanda yeni güvenlik açıkları da ortaya çıkarırlar. Biz, işitsel gizli temsilleri manipüle ederek aşağı akış dil üretiminde saldırgan tarafından belirlenen çıktıları tetikleyen bir kodlayıcı düzeyinde düşmanca saldırı olan evrensel hedefli gizli alan saldırısı öneriyoruz. Önceki dalga formu düzeyindeki veya girdi özgü saldırıların aksine, yaklaşımımız girdiler ve konuşmacılar arasında genelleme yapan ve dil modeline erişim gerektirmeyen evrensel bir pertürbasyon öğrenir. Qwen2-Audio-7B-Instruct üzerindeki deneyler, minimum algısal bozulma ile tutarlı bir şekilde yüksek saldırı başarı oranları göstermekte olup, çok modlu sistemlerin kodlayıcı düzeyinde kritik ve daha önce yeterince araştırılmamış bir saldırı yüzeyini ortaya koymaktadır."
    }
  }
]