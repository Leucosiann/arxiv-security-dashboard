[
  {
    "id": "2601.16140v1",
    "title": "Learning to Watermark in the Latent Space of Generative Models",
    "authors": [
      "Sylvestre-Alvise Rebuffi",
      "Tuan Tran",
      "Valeriu Lacatusu",
      "Pierre Fernandez",
      "Tomáš Souček"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2601.16140v1",
    "pdf_link": "https://arxiv.org/pdf/2601.16140v1",
    "content": {
      "en": "Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.",
      "tr": "**Makale Başlığı:** Öğrenme ile Üretici Modellerin Gizli Uzayında Filigranlama\n\n**Özet:**\n\nMevcut yapay zeka ile üretilmiş görseller için filigranlama yaklaşımları sıklıkla piksel uzayında uygulanan post-hoc yöntemlere dayanmakta olup, bu durum hesaplama yükünü ve potansiyel görsel bozulmaları beraberinde getirmektedir. Bu çalışmada, gizli uzay filigranlamayı incelemekte ve hem difüzyon hem de otoregresif modellerde çalışan, gizli filigranlama için birleşik bir yaklaşım olan DistSeal'ı sunmaktayız. Yaklaşımımız, üretici modellerin gizli uzayında post-hoc filigranlama modellerini eğiterek çalışır. Bu gizli filigranlayıcıların, ya üretici modelin kendisine ya da gizli kod çözücüye etkili bir şekilde damıtılabildiğini, böylece model içi filigranlamayı mümkün kıldığını göstermekteyiz. Elde edilen gizli filigranlar, benzer algılanamazlık ve piksel uzayı tabanlı temellere kıyasla 20 kata kadar hızlanma sağlarken rekabetçi bir dayanıklılık sunmaktadır. Deneylerimiz, gizli uzay filigranlayıcılarının damıtılmasının, piksel uzayı filigranlayıcılarının damıtılmasından daha üstün olduğunu ortaya koyarak, hem daha verimli hem de daha dayanıklı bir çözüm sunmaktadır."
    }
  },
  {
    "id": "2601.15824v1",
    "title": "Introducing the Generative Application Firewall (GAF)",
    "authors": [
      "Joan Vendrell Farreny",
      "Martí Jordà Roca",
      "Miquel Cornudella Gaya",
      "Rodrigo Fernández Baón",
      "Víctor García Martínez"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.15824v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15824v1",
    "content": {
      "en": "This paper introduces the Generative Application Firewall (GAF), a new architectural layer for securing LLM applications. Existing defenses -- prompt filters, guardrails, and data-masking -- remain fragmented; GAF unifies them into a single enforcement point, much like a WAF coordinates defenses for web traffic, while also covering autonomous agents and their tool interactions.",
      "tr": "**Makale Başlığı:** Generative Application Firewall (GAF) Tanıtımı\n\n**Özet:**\n\nBu çalışma, LLM uygulamalarını güvence altına almak için yeni bir mimari katman olan Generative Application Firewall (GAF)'ı tanıtmaktadır. Mevcut savunma mekanizmaları — prompt filters, guardrails ve data-masking — parçalı bir yapı sergilemektedir; GAF, WAF'ın web trafiği için savunmaları koordine etmesine benzer şekilde, bunları tek bir yaptırım noktası altında birleştirirken, aynı zamanda otonom ajanları ve araç etkileşimlerini de kapsamaktadır."
    }
  },
  {
    "id": "2601.15754v1",
    "title": "CAFE-GB: Scalable and Stable Feature Selection for Malware Detection via Chunk-wise Aggregated Gradient Boosting",
    "authors": [
      "Ajvad Haneef K",
      "Karan Kuwar Singh",
      "Madhu Kumar S D"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15754v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15754v1",
    "content": {
      "en": "High-dimensional malware datasets often exhibit feature redundancy, instability, and scalability limitations, which hinder the effectiveness and interpretability of machine learning-based malware detection systems. Although feature selection is commonly employed to mitigate these issues, many existing approaches lack robustness when applied to large-scale and heterogeneous malware data. To address this gap, this paper proposes CAFE-GB (Chunk-wise Aggregated Feature Estimation using Gradient Boosting), a scalable feature selection framework designed to produce stable and globally consistent feature rankings for high-dimensional malware detection. CAFE-GB partitions training data into overlapping chunks, estimates local feature importance using gradient boosting models, and aggregates these estimates to derive a robust global ranking. Feature budget selection is performed separately through a systematic k-selection and stability analysis to balance detection performance and robustness. The proposed framework is evaluated on two large-scale malware datasets: BODMAS and CIC-AndMal2020, representing large and diverse malware feature spaces. Experimental results show that classifiers trained on CAFE-GB -selected features achieve performance parity with full-feature baselines across multiple metrics, including Accuracy, F1-score, MCC, ROC-AUC, and PR-AUC, while reducing feature dimensionality by more than 95\\%. Paired Wilcoxon signed-rank tests confirm that this reduction does not introduce statistically significant performance degradation. Additional analyses demonstrate low inter-feature redundancy and improved interpretability through SHAP-based explanations. Runtime and memory profiling further indicate reduced downstream classification overhead. Overall, CAFE-GB provides a stable, interpretable, and scalable feature selection strategy for large-scale malware detection.",
      "tr": "İşte istenen akademik makale başlığı ve özetinin Türkçeye çevirisi:\n\n**Makale Başlığı:** CAFE-GB: Malware Tespiti İçin Chunk-wise Aggregated Gradient Boosting ile Ölçeklenebilir ve Kararlı Özellik Seçimi\n\n**Özet:**\nYüksek boyutlu malware veri kümeleri sıklıkla özellik fazlalığı, kararsızlık ve ölçeklenebilirlik sınırlamaları sergiler; bu durum, makine öğrenmesi tabanlı malware tespit sistemlerinin etkinliğini ve yorumlanabilirliğini engeller. Özellik seçimi bu sorunları azaltmak için yaygın olarak kullanılsa da, mevcut yaklaşımların çoğu büyük ölçekli ve heterojen malware verilerine uygulandığında sağlamlıktan yoksundur. Bu boşluğu doldurmak amacıyla bu makale, yüksek boyutlu malware tespiti için kararlı ve küresel olarak tutarlı özellik sıralamaları üreten ölçeklenebilir bir özellik seçimi çerçevesi olan CAFE-GB'yi (Chunk-wise Aggregated Feature Estimation using Gradient Boosting) önermektedir. CAFE-GB, eğitim verilerini örtüşen parçalara böler, gradient boosting modellerini kullanarak yerel özellik önemini tahmin eder ve sağlam bir küresel sıralama türetmek için bu tahminleri toplar. Özellik bütçesi seçimi, tespit performansı ve sağlamlık arasında denge kurmak amacıyla sistematik bir k-selection ve stability analysis aracılığıyla ayrı olarak gerçekleştirilir. Önerilen çerçeve, büyük ve çeşitli malware özellik alanlarını temsil eden iki büyük ölçekli malware veri kümesi üzerinde değerlendirilmiştir: BODMAS ve CIC-AndMal2020. Deneysel sonuçlar, CAFE-GB ile seçilen özelliklerle eğitilen sınıflandırıcıların, tam özellikli temel hatlara kıyasla Accuracy, F1-score, MCC, ROC-AUC ve PR-AUC dahil olmak üzere birden fazla metrikte performans denkliği sağladığını, aynı zamanda özellik boyutluluğunu %95'in üzerinde azalttığını göstermektedir. Paired Wilcoxon signed-rank testleri, bu azalmanın istatistiksel olarak anlamlı bir performans düşüşü yaratmadığını doğrulamaktadır. Ek analizler, düşük özellikler arası fazlalık ve SHAP-based explanations yoluyla geliştirilmiş yorumlanabilirlik göstermektedir. Runtime ve memory profiling ayrıca azalan downstream classification overhead'ini de göstermektedir. Genel olarak, CAFE-GB büyük ölçekli malware tespiti için kararlı, yorumlanabilir ve ölçeklenebilir bir özellik seçimi stratejisi sunmaktadır."
    }
  },
  {
    "id": "2601.15697v1",
    "title": "Balancing Security and Privacy: The Pivotal Role of AI in Modern Healthcare Systems",
    "authors": [
      "Binu V P",
      "Deepthy K Bhaskar",
      "Minimol B"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15697v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15697v1",
    "content": {
      "en": "As digital threats continue to grow, organizations must find ways to enhance security while protecting user privacy. This paper explores how artificial intelligence (AI) plays a crucial role in achieving this balance. AI technologies can improve security by detecting threats, monitoring systems, and automating responses. However, using AI also raises privacy concerns that need careful consideration.We examine real-world examples from the healthcare sector to illustrate how organizations can implement AI solutions that strengthen security without compromising patient privacy. Additionally, we discuss the importance of creating transparent AI systems and adhering to privacy regulations.Ultimately, this paper provides insights and recommendations for integrating AI into healthcare security practices, helping organizations navigate the challenges of modern management while keeping patient data safe.",
      "tr": "**Makale Başlığı:** Güvenlik ve Gizliliğin Dengelenmesi: Modern Sağlık Sistemlerinde Yapay Zekanın Kilit Rolü\n\n**Özet:**\n\nDijital tehditlerin artmaya devam ettiği bu dönemde, kuruluşların güvenliklerini artırmanın yanı sıra kullanıcı gizliliğini de koruma yolları bulmaları gerekmektedir. Bu makale, yapay zekanın (AI) bu dengeyi sağlamada ne kadar kritik bir rol oynadığını incelemektedir. AI teknolojileri, tehditleri tespit ederek, sistemleri izleyerek ve tepkileri otomatikleştirerek güvenliği iyileştirebilir. Ancak AI kullanımı aynı zamanda dikkatli bir şekilde ele alınması gereken gizlilik endişelerini de beraberinde getirmektedir. Bu makale, kuruluşların hasta gizliliğinden ödün vermeden güvenliği güçlendiren AI çözümlerini nasıl uygulayabileceklerini göstermek için sağlık sektöründen gerçek dünya örneklerini incelemektedir. Ayrıca, şeffaf AI sistemleri oluşturmanın ve gizlilik düzenlemelerine uymanın önemini tartışmaktayız. Nihayetinde bu makale, AI'nın sağlık güvenliği uygulamalarına entegrasyonu için içgörüler ve öneriler sunarak, kuruluşların hasta verilerini güvende tutarken modern yönetim zorluklarını aşmalarına yardımcı olmaktadır."
    }
  },
  {
    "id": "2601.15678v1",
    "title": "Connect the Dots: Knowledge Graph-Guided Crawler Attack on Retrieval-Augmented Generation Systems",
    "authors": [
      "Mengyu Yao",
      "Ziqi Zhang",
      "Ning Luo",
      "Shaofei Li",
      "Yifeng Cai"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15678v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15678v1",
    "content": {
      "en": "Retrieval-augmented generation (RAG) systems integrate document retrieval with large language models and have been widely adopted. However, in privacy-related scenarios, RAG introduces a new privacy risk: adversaries can issue carefully crafted queries to exfiltrate sensitive content from the underlying corpus gradually. Although recent studies have demonstrated multi-turn extraction attacks, they rely on heuristics and fail to perform long-term extraction planning. To address these limitations, we formulate the RAG extraction attack as an adaptive stochastic coverage problem (ASCP). In ASCP, each query is treated as a probabilistic action that aims to maximize conditional marginal gain (CMG), enabling principled long-term planning under uncertainty. However, integrating ASCP with practical RAG attack faces three key challenges: unobservable CMG, intractability in the action space, and feasibility constraints. To overcome these challenges, we maintain a global attacker-side state to guide the attack. Building on this idea, we introduce RAGCRAWLER, which builds a knowledge graph to represent revealed information, uses this global state to estimate CMG, and plans queries in semantic space that target unretrieved regions. In comprehensive experiments across diverse RAG architectures and datasets, our proposed method, RAGCRAWLER, consistently outperforms all baselines. It achieves up to 84.4% corpus coverage within a fixed query budget and deliver an average improvement of 20.7% over the top-performing baseline. It also maintains high semantic fidelity and strong content reconstruction accuracy with low attack cost. Crucially, RAGCRAWLER proves its robustness by maintaining effectiveness against advanced RAG systems employing query rewriting and multi-query retrieval strategies. Our work reveals significant security gaps and highlights the pressing need for stronger safeguards for RAG.",
      "tr": "İşte makale başlığının ve özetinin Türkçe çevirisi:\n\n**Makale Başlığı:** Noktaları Birleştir: Retrieval-Augmented Generation Sistemlerine Karşı Bilgi Grafiği Güdümlü Tarayıcı Saldırısı\n\n**Özet:**\nRetrieval-augmented generation (RAG) sistemleri, belge erişimini büyük dil modelleriyle entegre ederek yaygın olarak benimsenmiştir. Ancak, gizlilikle ilgili senaryolarda RAG yeni bir gizlilik riski ortaya koymaktadır: düşmanlar, altta yatan veri kümesinden hassas içeriği kademeli olarak sızdırmak için özenle hazırlanmış sorgular yürütebilirler. Son çalışmalar çok turlu çıkarma saldırılarını gösterse de, bunlar sezgilere dayanmakta ve uzun vadeli çıkarma planlaması yapamamaktadır. Bu sınırlılıkları gidermek için, RAG çıkarma saldırısını adaptif bir stokastik kapsama problemi (ASCP) olarak formüle ediyoruz. ASCP'de, her sorgu, koşullu marjinal kazancı (CMG) maksimize etmeyi amaçlayan olasılıksal bir eylem olarak ele alınır, bu da belirsizlik altında ilkeli uzun vadeli planlamaya olanak tanır. Ancak, ASCP'yi pratik RAG saldırısıyla entegre etmek üç temel zorlukla karşı karşıyadır: gözlemlenemeyen CMG, eylem alanındaki karmaşıklık ve fizibilite kısıtlamaları. Bu zorlukların üstesinden gelmek için saldırıyı yönlendirmek amacıyla global bir saldırgan tarafı durumu sürdürüyoruz. Bu fikirden yola çıkarak, ortaya çıkan bilgileri temsil etmek için bir knowledge graph oluşturan, global durumu kullanarak CMG'yi tahmin eden ve henüz erişilmeyen bölgeleri hedefleyen anlamsal alanda sorguları planlayan RAGCRAWLER'ı sunuyoruz. Çeşitli RAG mimarileri ve veri kümeleri üzerinde yürütülen kapsamlı deneylerde, önerdiğimiz RAGCRAWLER yöntemi tutarlı bir şekilde tüm taban çizgilerini geride bırakmaktadır. Sabit bir sorgu bütçesi dahilinde %84,4'e varan veri kümesi kapsamı elde etmekte ve en iyi performans gösteren taban çizgisine göre ortalama %20,7'lik bir iyileşme sağlamaktadır. Ayrıca, düşük saldırı maliyetiyle yüksek anlamsal sadakat ve güçlü içerik yeniden yapılandırma doğruluğu korumaktadır. Kritik olarak, RAGCRAWLER sorgu yeniden yazma ve çoklu sorgu erişim stratejileri kullanan gelişmiş RAG sistemlerine karşı etkililiğini koruyarak sağlamlığını kanıtlamaktadır. Çalışmamız önemli güvenlik açıklarını ortaya koymakta ve RAG için daha güçlü korumalara duyulan acil ihtiyacı vurgulamaktadır."
    }
  },
  {
    "id": "2601.15663v1",
    "title": "TempoNet: Learning Realistic Communication and Timing Patterns for Network Traffic Simulation",
    "authors": [
      "Kristen Moore",
      "Diksha Goel",
      "Cody James Christopher",
      "Zhen Wang",
      "Minjune Kim"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15663v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15663v1",
    "content": {
      "en": "Realistic network traffic simulation is critical for evaluating intrusion detection systems, stress-testing network protocols, and constructing high-fidelity environments for cybersecurity training. While attack traffic can often be layered into training environments using red-teaming or replay methods, generating authentic benign background traffic remains a core challenge -- particularly in simulating the complex temporal and communication dynamics of real-world networks. This paper introduces TempoNet, a novel generative model that combines multi-task learning with multi-mark temporal point processes to jointly model inter-arrival times and all packet- and flow-header fields. TempoNet captures fine-grained timing patterns and higher-order correlations such as host-pair behavior and seasonal trends, addressing key limitations of GAN-, LLM-, and Bayesian-based methods that fail to reproduce structured temporal variation. TempoNet produces temporally consistent, high-fidelity traces, validated on real-world datasets. Furthermore, we show that intrusion detection models trained on TempoNet-generated background traffic perform comparably to those trained on real data, validating its utility for real-world security applications.",
      "tr": "Makale Başlığı: TempoNet: Ağ Trafiği Simülasyonu İçin Gerçekçi İletişim ve Zamanlama Desenlerini Öğrenme\n\nÖzet:\nGerçekçi ağ trafiği simülasyonu, saldırı tespit sistemlerinin değerlendirilmesi, ağ protokollerinin stres testi ve siber güvenlik eğitimi için yüksek doğrulukta ortamların oluşturulması açısından kritik öneme sahiptir. Saldırı trafiği genellikle red-teaming veya tekrar oynatma yöntemleri kullanılarak eğitim ortamlarına katmanlanabilirken, özgün zararsız arka plan trafiği üretmek, özellikle gerçek dünya ağlarının karmaşık zamansal ve iletişim dinamiklerinin simüle edilmesiyle ilgili olarak, temel bir zorluk olmaya devam etmektedir. Bu makale, çoklu görev öğrenimini (multi-task learning) çok işaretli zamansal nokta süreçleri (multi-mark temporal point processes) ile birleştirerek, varışlar arası zamanları ve tüm paket ve akış başlığı alanlarını ortaklaşa modelleyen yeni bir üretken model olan TempoNet'i tanıtmaktadır. TempoNet, makine öğrenimi tabanlı yöntemlerin (GAN-, LLM-, ve Bayesian-based methods) yapısal zamansal değişimi yeniden üretememe gibi temel sınırlılıklarını ele alarak, sunucu-çifti davranışı (host-pair behavior) ve mevsimsel eğilimler (seasonal trends) gibi ince taneli zamanlama desenlerini ve üst düzey korelasyonları yakalar. TempoNet, gerçek dünya veri kümeleri üzerinde doğrulanmış, zamansal olarak tutarlı ve yüksek doğrulukta izler üretir. Dahası, TempoNet tarafından üretilen arka plan trafiği üzerinde eğitilen saldırı tespit modellerinin gerçek veriler üzerinde eğitilenlere kıyasla benzer performans gösterdiğini ortaya koyuyoruz; bu da onun gerçek dünya güvenlik uygulamaları için faydasını doğrulamaktadır."
    }
  },
  {
    "id": "2601.15652v1",
    "title": "Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models",
    "authors": [
      "Manish Bhatt"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.AI",
      "cs.CR",
      "cs.ET"
    ],
    "link": "http://arxiv.org/abs/2601.15652v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15652v1",
    "content": {
      "en": "Hallucinations in Large Language Models (LLMs) -- generations that are plausible but factually unfaithful -- remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims).   Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises (\"Sycophancy\").   This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.",
      "tr": "**Makale Başlığı:** Large Language Model'larda Halüsinasyon Tespiti İçin Predictive Coding ve Information Bottleneck\n\n**Özet:**\n\nLarge Language Model'larda (LLM'ler) halüsinasyonlar -- olası ancak olgusal olarak sadık olmayan çıktılar -- yüksek riskli dağıtım için kritik bir engel olmaya devam etmektedir. Mevcut tespit yöntemleri genellikle hesaplama açısından pahalı harici retrieval döngülerine veya 70B+ parametre gerektiren şeffaf olmayan black-box LLM yargıçlarına dayanmaktadır. Bu çalışmada, nörobilimden ilham alan sinyal tasarımı ile denetimli makine öğrenmesini birleştiren hibrit bir tespit çerçevesi olan [Model Adı]'nı tanıtıyoruz. Predictive Coding (içsel önceliklere karşı sürprizin nicelleştirilmesi) ve Information Bottleneck (pertürbasyon altında sinyal tutma ölçümü) üzerine temellenen yorumlanabilir sinyaller çıkarıyoruz. Sistematik ablasyon yoluyla üç temel geliştirmeyi gösteriyoruz: Entity-Focused Uptake (yüksek değerli token'lara odaklanma), Context Adherence (grounding gücünün ölçülmesi) ve Falsifiability Score (emin ama çelişkili iddiaların tespiti). HaluBench (n=200, mükemmel dengeli) üzerinde yapılan değerlendirmede, teori güdümlü temel modelimiz 0.8017 AUROC elde etmektedir. BASE denetimli modeller 0.8274 AUROC'a ulaşırken, IMPROVED özellikler performansı 0.8669 AUROC'a (%4.95 kazanç) yükseltmekte, mimariler arasında tutarlı iyileşmeler göstermektedir. Bu rekabetçi performans, Lynx'e kıyasla 75 kat daha az eğitim verisi (200'e karşı 15.000 örnek), 1000 kat daha hızlı inference (5ms'ye karşı 5s) kullanılarak elde edilmiş ve tamamen yorumlanabilir kalmıştır. Kritik olarak, olumsuz bir sonuç raporluyoruz: Rationalization sinyalinin halüsinasyonları ayırt etmede başarısız olduğu, bu da LLM'lerin yanlış önermeler için tutarlı reasoning ürettiğini (\"Sycophancy\") düşündürmektedir. Bu çalışma, sinyal mimarisinde kodlanmış alan bilgisinin, LLM yargıçlarının ölçeklenmesine kıyasla üstün veri verimliliği sağladığını ve üretim dağıtımına uygun, hafif (1M parametreden az), açıklanabilir modellerle güçlü performans elde ettiğini göstermektedir."
    }
  },
  {
    "id": "2601.15595v1",
    "title": "Data-Free Privacy-Preserving for LLMs via Model Inversion and Selective Unlearning",
    "authors": [
      "Xinjie Zhou",
      "Zhihui Yang",
      "Lechao Cheng",
      "Sai Wu",
      "Gang Chen"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15595v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15595v1",
    "content": {
      "en": "Large language models (LLMs) exhibit powerful capabilities but risk memorizing sensitive personally identifiable information (PII) from their training data, posing significant privacy concerns. While machine unlearning techniques aim to remove such data, they predominantly depend on access to the training data. This requirement is often impractical, as training data in real-world deployments is commonly proprietary or inaccessible. To address this limitation, we propose Data-Free Selective Unlearning (DFSU), a novel privacy-preserving framework that removes sensitive PII from an LLM without requiring its training data. Our approach first synthesizes pseudo-PII through language model inversion, then constructs token-level privacy masks for these synthetic samples, and finally performs token-level selective unlearning via a contrastive mask loss within a low-rank adaptation (LoRA) subspace. Extensive experiments on the AI4Privacy PII-Masking dataset using Pythia models demonstrate that our method effectively removes target PII while maintaining model utility.",
      "tr": "Makale Başlığı: Veri-Serbest Gizlilik Koruma için LLM'ler Üzerine Model Tersine Çevirme ve Seçici Unlearning\n\nÖzet:\nBüyük dil modelleri (LLM'ler), güçlü yetenekler sergilemekle birlikte, eğitim verilerinden hassas kişisel tanımlayıcı bilgileri (PII) ezberleme riski taşır ve bu da önemli gizlilik endişelerine yol açar. Makine unlearning teknikleri bu tür verileri kaldırmayı amaçlasa da, büyük ölçüde eğitim verilerine erişime bağlıdır. Gerçek dünya dağıtımlarında eğitim verileri yaygın olarak özel mülkiyetli veya erişilemez olduğundan, bu gereklilik genellikle pratik değildir. Bu sınırlamayı ele almak için, eğitim verilerine ihtiyaç duymadan bir LLM'den hassas PII'leri kaldıran yeni bir gizlilik koruma çerçevesi olan Data-Free Selective Unlearning (DFSU)'yu öneriyoruz. Yaklaşımımız ilk olarak language model inversion aracılığıyla sözde-PII sentezler, ardından bu sentetik örnekler için token-level privacy masks oluşturur ve son olarak low-rank adaptation (LoRA) subspace'i içinde bir contrastive mask loss aracılığıyla token-level selective unlearning gerçekleştirir. Pythia modelleri kullanılarak AI4Privacy PII-Masking veri kümesi üzerinde yapılan kapsamlı deneyler, yöntemimizin hedef PII'yi modelin faydasını koruyarak etkili bir şekilde kaldırdığını göstermektedir."
    }
  },
  {
    "id": "2601.15474v1",
    "title": "Multi-Targeted Graph Backdoor Attack",
    "authors": [
      "Md Nabi Newaz Khan",
      "Abdullah Arafat Miah",
      "Yu Bi"
    ],
    "published_date": "2026-01-21",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2601.15474v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15474v1",
    "content": {
      "en": "Graph neural network (GNN) have demonstrated exceptional performance in solving critical problems across diverse domains yet remain susceptible to backdoor attacks. Existing studies on backdoor attack for graph classification are limited to single target attack using subgraph replacement based mechanism where the attacker implants only one trigger into the GNN model. In this paper, we introduce the first multi-targeted backdoor attack for graph classification task, where multiple triggers simultaneously redirect predictions to different target labels. Instead of subgraph replacement, we propose subgraph injection which preserves the structure of the original graphs while poisoning the clean graphs. Extensive experiments demonstrate the efficacy of our approach, where our attack achieves high attack success rates for all target labels with minimal impact on the clean accuracy. Experimental results on five dataset demonstrate the superior performance of our attack framework compared to the conventional subgraph replacement-based attack. Our analysis on four GNN models confirms the generalization capability of our attack which is effective regardless of the GNN model architectures and training parameters settings. We further investigate the impact of the attack design parameters including injection methods, number of connections, trigger sizes, trigger edge density and poisoning ratios. Additionally, our evaluation against state-of-the-art defenses (randomized smoothing and fine-pruning) demonstrates the robustness of our proposed multi-target attacks. This work highlights the GNN vulnerability against multi-targeted backdoor attack in graph classification task. Our source codes will be available at https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack.",
      "tr": "**Makale Başlığı:** Çok Hedefli Graph Backdoor Saldırısı\n\n**Özet:**\n\nGraph neural network (GNN), çeşitli alanlardaki kritik sorunların çözümünde olağanüstü performans göstermiş olmalarına rağmen, backdoor saldırılarına karşı savunmasız kalmaktadır. Grafik sınıflandırması için mevcut backdoor saldırısı çalışmaları, yalnızca bir tetikleyiciyi GNN modeline yerleştiren, subgraph replacement temelli bir mekanizma kullanarak tek hedefli saldırıyla sınırlıdır. Bu makalede, grafik sınıflandırması görevi için ilk çok hedefli backdoor saldırısını tanıtıyoruz; burada birden fazla tetikleyici, tahminleri aynı anda farklı hedef etiketlere yönlendirir. Subgraph replacement yerine, orijinal grafiklerin yapısını korurken temiz grafikleri zehirleyen subgraph injection'ı öneriyoruz. Kapsamlı deneyler, yaklaşımımızın etkinliğini göstermektedir; saldırımız, temiz doğruluğa minimum etkiyle tüm hedef etiketler için yüksek saldırı başarı oranları elde etmektedir. Beş veri kümesi üzerindeki deneysel sonuçlar, saldırı çerçevemizin geleneksel subgraph replacement temelli saldırıya kıyasla üstün performansını göstermektedir. Dört GNN modeli üzerindeki analizimiz, saldırımızın genelleme yeteneğini doğrulamaktadır; bu yetenek, GNN model mimarilerinden ve eğitim parametre ayarlarından bağımsız olarak etkilidir. Ayrıca, enjeksiyon yöntemleri, bağlantı sayısı, tetikleyici boyutları, tetikleyici kenar yoğunluğu ve zehirleme oranları dahil olmak üzere saldırı tasarım parametrelerinin etkisini de araştırıyoruz. Ek olarak, en son savunmalara (randomized smoothing ve fine-pruning) karşı değerlendirmemiz, önerilen çok hedefli saldırılarımızın sağlamlığını göstermektedir. Bu çalışma, grafik sınıflandırması görevinde GNN'lerin çok hedefli backdoor saldırılarına karşı savunmasızlığını vurgulamaktadır. Kaynak kodlarımız https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack adresinde mevcuttur."
    }
  },
  {
    "id": "2601.15177v1",
    "title": "Dynamic Management of a Deep Learning-Based Anomaly Detection System for 5G Networks",
    "authors": [
      "Lorenzo Fernández Maimó",
      "Alberto Huertas Celdrán",
      "Manuel Gil Pérez",
      "Félix J. García Clemente",
      "Gregorio Martínez Pérez"
    ],
    "published_date": "2026-01-21",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.15177v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15177v1",
    "content": {
      "en": "Fog and mobile edge computing (MEC) will play a key role in the upcoming fifth generation (5G) mobile networks to support decentralized applications, data analytics and management into the network itself by using a highly distributed compute model. Furthermore, increasing attention is paid to providing user-centric cybersecurity solutions, which particularly require collecting, processing and analyzing significantly large amount of data traffic and huge number of network connections in 5G networks. In this regard, this paper proposes a MEC-oriented solution in 5G mobile networks to detect network anomalies in real-time and in autonomic way. Our proposal uses deep learning techniques to analyze network flows and to detect network anomalies. Moreover, it uses policies in order to provide an efficient and dynamic management system of the computing resources used in the anomaly detection process. The paper presents relevant aspects of the deployment of the proposal and experimental results to show its performance.",
      "tr": "İşte makale başlığı ve özetinin Türkçe çevirisi:\n\n**Makale Başlığı:** 5G Ağları İçin Derin Öğrenme Tabanlı Anomali Tespit Sisteminin Dinamik Yönetimi\n\n**Özet:**\nSis ve mobil kenar bilişim (MEC), merkezi olmayan uygulamaları, veri analitiğini ve yönetimi yüksek derecede dağıtılmış bir bilişim modeli kullanarak ağın kendisine desteklemek için yaklaşan beşinci nesil (5G) mobil ağlarda kilit rol oynayacaktır. Dahası, kullanıcı merkezli siber güvenlik çözümleri sağlamaya giderek daha fazla önem verilmektedir; bu da özellikle 5G ağlarında önemli miktarda veri trafiğini ve çok sayıda ağ bağlantısını toplama, işleme ve analiz etmeyi gerektirir. Bu doğrultuda, bu makale 5G mobil ağlarında ağ anomalilerini gerçek zamanlı ve otonom bir şekilde tespit etmek için MEC odaklı bir çözüm önermektedir. Önerimiz, ağ akışlarını analiz etmek ve ağ anomalilerini tespit etmek için derin öğrenme tekniklerini kullanır. Ayrıca, anomali tespit sürecinde kullanılan bilişim kaynaklarının verimli ve dinamik bir yönetim sistemini sağlamak için politikaları kullanır. Makale, önerinin dağıtımının ilgili yönlerini ve performansını gösteren deneysel sonuçları sunmaktadır."
    }
  }
]