[
  {
    "id": "2601.16140v1",
    "title": "Learning to Watermark in the Latent Space of Generative Models",
    "authors": [
      "Sylvestre-Alvise Rebuffi",
      "Tuan Tran",
      "Valeriu Lacatusu",
      "Pierre Fernandez",
      "Tomáš Souček"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2601.16140v1",
    "pdf_link": "https://arxiv.org/pdf/2601.16140v1",
    "content": {
      "en": "Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.",
      "tr": "**Makale Başlığı:** Öğrenerek Üretici Modellerin Latent Space'inde Watermark Uygulamak\n\n**Özet:**\n\nYapay zeka tarafından üretilen görseller için mevcut watermark uygulaması yaklaşımları genellikle piksel uzayında uygulanan post-hoc yöntemlere dayanır, bu da hesaplama yükü ve potansiyel görsel bozulmalar meydana getirir. Bu çalışmada, latent uzay watermark uygulamasını araştırmakta ve hem diffusion hem de autoregressive modellerde işleyen, birleşik bir latent watermark yaklaşımı olan DistSeal'ı sunmaktayız. Yaklaşımımız, üretici modellerin latent uzayında post-hoc watermark modellerini eğiterek çalışmaktadır. Bu latent watermarker'ların, ya üretici modelin kendisine ya da latent dekodere etkili bir şekilde distilled edilebileceğini ve böylece model içi watermark uygulamasını mümkün kıldığını göstermekteyiz. Elde edilen latent watermark'lar, piksel uzayı temel çizgilerine kıyasla benzer algılanamazlık ve 20 kata kadar hız artışı sunarken rekabetçi bir dayanıklılık sağlamaktadır. Deneylerimiz ayrıca, latent watermarker'ları distilling etmenin, piksel uzayı olanları distilling etmeye göre daha üstün olduğunu ortaya koymaktadır, bu da hem daha verimli hem de daha dayanıklı bir çözüm sunmaktadır."
    }
  },
  {
    "id": "2601.15824v1",
    "title": "Introducing the Generative Application Firewall (GAF)",
    "authors": [
      "Joan Vendrell Farreny",
      "Martí Jordà Roca",
      "Miquel Cornudella Gaya",
      "Rodrigo Fernández Baón",
      "Víctor García Martínez"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.15824v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15824v1",
    "content": {
      "en": "This paper introduces the Generative Application Firewall (GAF), a new architectural layer for securing LLM applications. Existing defenses -- prompt filters, guardrails, and data-masking -- remain fragmented; GAF unifies them into a single enforcement point, much like a WAF coordinates defenses for web traffic, while also covering autonomous agents and their tool interactions.",
      "tr": "İşte akademik makale başlığının ve özetinin istenen şekilde çevrilmiş hali:\n\n**Makale Başlığı:** Generative Application Firewall (GAF)'in Tanıtılması\n\n**Özet:**\nBu makale, LLM uygulamalarını güvence altına almak için yeni bir mimari katman olan Generative Application Firewall (GAF)'i tanıtmaktadır. Mevcut savunmalar — prompt filters, guardrails ve data-masking — parçalı kalmaktadır; GAF, bunları tek bir denetim noktası altında birleştirerek, tıpkı bir WAF'ın web trafiği için savunmaları koordine etmesi gibi, aynı zamanda otonom ajanları ve araç etkileşimlerini de kapsamaktadır."
    }
  },
  {
    "id": "2601.15754v1",
    "title": "CAFE-GB: Scalable and Stable Feature Selection for Malware Detection via Chunk-wise Aggregated Gradient Boosting",
    "authors": [
      "Ajvad Haneef K",
      "Karan Kuwar Singh",
      "Madhu Kumar S D"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15754v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15754v1",
    "content": {
      "en": "High-dimensional malware datasets often exhibit feature redundancy, instability, and scalability limitations, which hinder the effectiveness and interpretability of machine learning-based malware detection systems. Although feature selection is commonly employed to mitigate these issues, many existing approaches lack robustness when applied to large-scale and heterogeneous malware data. To address this gap, this paper proposes CAFE-GB (Chunk-wise Aggregated Feature Estimation using Gradient Boosting), a scalable feature selection framework designed to produce stable and globally consistent feature rankings for high-dimensional malware detection. CAFE-GB partitions training data into overlapping chunks, estimates local feature importance using gradient boosting models, and aggregates these estimates to derive a robust global ranking. Feature budget selection is performed separately through a systematic k-selection and stability analysis to balance detection performance and robustness. The proposed framework is evaluated on two large-scale malware datasets: BODMAS and CIC-AndMal2020, representing large and diverse malware feature spaces. Experimental results show that classifiers trained on CAFE-GB -selected features achieve performance parity with full-feature baselines across multiple metrics, including Accuracy, F1-score, MCC, ROC-AUC, and PR-AUC, while reducing feature dimensionality by more than 95\\%. Paired Wilcoxon signed-rank tests confirm that this reduction does not introduce statistically significant performance degradation. Additional analyses demonstrate low inter-feature redundancy and improved interpretability through SHAP-based explanations. Runtime and memory profiling further indicate reduced downstream classification overhead. Overall, CAFE-GB provides a stable, interpretable, and scalable feature selection strategy for large-scale malware detection.",
      "tr": "Elbette, akademik makale başlığını ve özetini istediğiniz şekilde Türkçeye çevirdim. Teknik terimler İngilizce bırakılarak resmi ve akademik bir dil kullanılmıştır.\n\n**Makale Başlığı:** CAFE-GB: Kümeler Halinde Toplanan Gradient Boosting Aracılığıyla Kötü Amaçlı Yazılım Tespiti İçin Ölçeklenebilir ve Kararlı Özellik Seçimi\n\n**Özet:**\nYüksek boyutlu kötü amaçlı yazılım veri kümeleri sıklıkla özellik fazlalığı, kararsızlık ve ölçeklenebilirlik sınırlamaları sergiler; bu durum, makine öğrenmesi tabanlı kötü amaçlı yazılım tespit sistemlerinin etkinliğini ve yorumlanabilirliğini engellemektedir. Özellik seçimi bu sorunları azaltmak için yaygın olarak kullanılmakla birlikte, mevcut yaklaşımların çoğu büyük ölçekli ve heterojen kötü amaçlı yazılım verilerine uygulandığında sağlamlık eksikliği yaşamaktadır. Bu boşluğu gidermek amacıyla bu makale, yüksek boyutlu kötü amaçlı yazılım tespiti için kararlı ve küresel olarak tutarlı özellik sıralamaları üreten ölçeklenebilir bir özellik seçimi çerçevesi olan CAFE-GB (Chunk-wise Aggregated Feature Estimation using Gradient Boosting) önermektedir. CAFE-GB, eğitim verilerini örtüşen kümeler halinde böler, gradient boosting modelleri kullanarak yerel özellik önemini tahmin eder ve sağlam bir küresel sıralama türetmek için bu tahminleri toplar. Özellik bütçe seçimi, tespit performansı ile sağlamlık arasında denge kurmak için sistematik bir k-selection ve kararlılık analizi yoluyla ayrı olarak gerçekleştirilir. Önerilen çerçeve, büyük ve çeşitli kötü amaçlı yazılım özellik alanlarını temsil eden iki büyük ölçekli kötü amaçlı yazılım veri kümesi üzerinde değerlendirilmiştir: BODMAS ve CIC-AndMal2020. Deneysel sonuçlar, CAFE-GB ile seçilen özellikler üzerinde eğitilen sınıflandırıcıların, doğruluk (Accuracy), F1-skoru (F1-score), MCC, ROC-AUC ve PR-AUC dahil olmak üzere birden fazla metrikte tam özellikli taban çizgileriyle performans denkliği sağladığını, aynı zamanda özellik boyutluluğunu %95'in üzerinde azalttığını göstermektedir. Eşleştirilmiş Wilcoxon işaretli sıralama testleri, bu azalmanın istatistiksel olarak anlamlı bir performans düşüşüne neden olmadığını doğrulamaktadır. Ek analizler, SHAP tabanlı açıklamalar aracılığıyla düşük özellikler arası fazlalığı ve iyileştirilmiş yorumlanabilirliği ortaya koymaktadır. Çalışma zamanı ve bellek profillemesi de aşağı akış sınıflandırma ek yükünün azaldığını göstermektedir. Genel olarak, CAFE-GB, büyük ölçekli kötü amaçlı yazılım tespiti için kararlı, yorumlanabilir ve ölçeklenebilir bir özellik seçimi stratejisi sunmaktadır."
    }
  },
  {
    "id": "2601.15697v1",
    "title": "Balancing Security and Privacy: The Pivotal Role of AI in Modern Healthcare Systems",
    "authors": [
      "Binu V P",
      "Deepthy K Bhaskar",
      "Minimol B"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15697v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15697v1",
    "content": {
      "en": "As digital threats continue to grow, organizations must find ways to enhance security while protecting user privacy. This paper explores how artificial intelligence (AI) plays a crucial role in achieving this balance. AI technologies can improve security by detecting threats, monitoring systems, and automating responses. However, using AI also raises privacy concerns that need careful consideration.We examine real-world examples from the healthcare sector to illustrate how organizations can implement AI solutions that strengthen security without compromising patient privacy. Additionally, we discuss the importance of creating transparent AI systems and adhering to privacy regulations.Ultimately, this paper provides insights and recommendations for integrating AI into healthcare security practices, helping organizations navigate the challenges of modern management while keeping patient data safe.",
      "tr": "İşte akademik makale başlığı ve özetinin çevirisi:\n\n**Makale Başlığı:** Dijital Tehditler Sürekli Artarken, Kuruluşların Güvenliği Artırmanın ve Kullanıcı Gizliliğini Korumanın Yollarını Bulması Gerekmektedir. Bu Makale, Yapay Zekanın (AI) Bu Dengenin Sağlanmasında Nasıl Kritik Bir Rol Oynadığını İncelemektedir. AI Teknolojileri, Tehditleri Tespit Ederek, Sistemleri İzleyerek ve Otomatik Yanıtlar Üreterek Güvenliği Artırabilir. Ancak, AI Kullanımı Aynı Zamanda Dikkatli Bir Şekilde Değerlendirilmesi Gereken Gizlilik Kaygılarını da Ortaya Çıkarmaktadır. Kuruluşların Hasta Gizliliğinden Ödün Vermeden Güvenliği Güçlendiren AI Çözümlerini Nasıl Uygulayabileceğini Göstermek İçin Sağlık Sektöründen Gerçek Dünya Örneklerini İnceliyoruz. Ek Olarak, Şeffaf AI Sistemleri Oluşturmanın ve Gizlilik Düzenlemelerine Uymanın Önemini Tartışıyoruz. Nihayetinde, Bu Makale, Kuruluşların Modern Yönetimin Zorluklarında Yol Almasına ve Hasta Verilerini Güvenli Tutmasına Yardımcı Olacak Şekilde, AI'nın Sağlık Güvenliği Uygulamalarına Entegrasyonu İçin İçgörüler ve Öneriler Sunmaktadır."
    }
  },
  {
    "id": "2601.15678v1",
    "title": "Connect the Dots: Knowledge Graph-Guided Crawler Attack on Retrieval-Augmented Generation Systems",
    "authors": [
      "Mengyu Yao",
      "Ziqi Zhang",
      "Ning Luo",
      "Shaofei Li",
      "Yifeng Cai"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15678v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15678v1",
    "content": {
      "en": "Retrieval-augmented generation (RAG) systems integrate document retrieval with large language models and have been widely adopted. However, in privacy-related scenarios, RAG introduces a new privacy risk: adversaries can issue carefully crafted queries to exfiltrate sensitive content from the underlying corpus gradually. Although recent studies have demonstrated multi-turn extraction attacks, they rely on heuristics and fail to perform long-term extraction planning. To address these limitations, we formulate the RAG extraction attack as an adaptive stochastic coverage problem (ASCP). In ASCP, each query is treated as a probabilistic action that aims to maximize conditional marginal gain (CMG), enabling principled long-term planning under uncertainty. However, integrating ASCP with practical RAG attack faces three key challenges: unobservable CMG, intractability in the action space, and feasibility constraints. To overcome these challenges, we maintain a global attacker-side state to guide the attack. Building on this idea, we introduce RAGCRAWLER, which builds a knowledge graph to represent revealed information, uses this global state to estimate CMG, and plans queries in semantic space that target unretrieved regions. In comprehensive experiments across diverse RAG architectures and datasets, our proposed method, RAGCRAWLER, consistently outperforms all baselines. It achieves up to 84.4% corpus coverage within a fixed query budget and deliver an average improvement of 20.7% over the top-performing baseline. It also maintains high semantic fidelity and strong content reconstruction accuracy with low attack cost. Crucially, RAGCRAWLER proves its robustness by maintaining effectiveness against advanced RAG systems employing query rewriting and multi-query retrieval strategies. Our work reveals significant security gaps and highlights the pressing need for stronger safeguards for RAG.",
      "tr": "İşte makale başlığının ve özetinin Türkçe çevirisi:\n\n**Makale Başlığı:** Noktaları Birleştirin: Retrieval-Augmented Generation Sistemlerine Karşı Bilgi Grafiği Güdümlü Tarayıcı Saldırısı\n\n**Özet:**\nRetrieval-augmented generation (RAG) sistemleri, belge alımını büyük dil modelleriyle entegre eder ve yaygın olarak benimsenmiştir. Ancak, gizlilikle ilgili senaryolarda RAG yeni bir gizlilik riski oluşturur: saldırganlar, temel veri kümesinden hassas içeriği kademeli olarak dışarı çıkarmak için dikkatlice hazırlanmış sorgular düzenleyebilir. Son çalışmalar çok turlu çıkarım saldırılarını gösterse de, bu çalışmalar sezgilere dayanır ve uzun vadeli çıkarım planlaması yapamaz. Bu sınırlılıkları ele almak için RAG çıkarım saldırısını, adaptive stochastic coverage problem (ASCP) olarak formüle ediyoruz. ASCP'de, her sorgu, conditional marginal gain (CMG) maksimize etmeyi amaçlayan olasılıksal bir eylem olarak kabul edilir, bu da belirsizlik altında prensipli uzun vadeli planlamayı mümkün kılar. Ancak, ASCP'yi pratik RAG saldırısıyla entegre etmek üç temel zorlukla karşı karşıyadır: gözlemlenemeyen CMG, eylem alanındaki zorluk ve fizibilite kısıtlamaları. Bu zorlukların üstesinden gelmek için, saldırıyı yönlendirmek üzere global bir saldırgan tarafı durumu (global attacker-side state) sürdürüyoruz. Bu fikirden yola çıkarak, ortaya çıkan bilgileri temsil etmek üzere bir knowledge graph oluşturan, CMG'yi tahmin etmek için bu global durumu kullanan ve henüz alınmamış bölgeleri hedefleyen anlamsal uzayda (semantic space) sorguları planlayan RAGCRAWLER'ı sunuyoruz. Çeşitli RAG mimarileri ve veri kümeleri üzerindeki kapsamlı deneylerde, önerdiğimiz yöntem RAGCRAWLER, tüm taban çizgilerini tutarlı bir şekilde geride bırakmaktadır. Sabit bir sorgu bütçesi içinde %84,4'e kadar veri kümesi kapsama alanı elde etmekte ve en iyi performans gösteren taban çizgisine göre ortalama %20,7'lik bir iyileşme sağlamaktadır. Ayrıca, yüksek anlamsal sadakat (semantic fidelity) ve düşük saldırı maliyetiyle güçlü içerik yeniden yapılandırma doğruluğunu korur. En önemlisi, RAGCRAWLER, sorgu yeniden yazma (query rewriting) ve çoklu sorgu alma (multi-query retrieval) stratejileri uygulayan gelişmiş RAG sistemlerine karşı etkinliğini sürdürerek sağlamlığını kanıtlar. Çalışmamız, önemli güvenlik açıklarını ortaya koymakta ve RAG için daha güçlü korumalara olan acil ihtiyacı vurgulamaktadır."
    }
  },
  {
    "id": "2601.15663v1",
    "title": "TempoNet: Learning Realistic Communication and Timing Patterns for Network Traffic Simulation",
    "authors": [
      "Kristen Moore",
      "Diksha Goel",
      "Cody James Christopher",
      "Zhen Wang",
      "Minjune Kim"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15663v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15663v1",
    "content": {
      "en": "Realistic network traffic simulation is critical for evaluating intrusion detection systems, stress-testing network protocols, and constructing high-fidelity environments for cybersecurity training. While attack traffic can often be layered into training environments using red-teaming or replay methods, generating authentic benign background traffic remains a core challenge -- particularly in simulating the complex temporal and communication dynamics of real-world networks. This paper introduces TempoNet, a novel generative model that combines multi-task learning with multi-mark temporal point processes to jointly model inter-arrival times and all packet- and flow-header fields. TempoNet captures fine-grained timing patterns and higher-order correlations such as host-pair behavior and seasonal trends, addressing key limitations of GAN-, LLM-, and Bayesian-based methods that fail to reproduce structured temporal variation. TempoNet produces temporally consistent, high-fidelity traces, validated on real-world datasets. Furthermore, we show that intrusion detection models trained on TempoNet-generated background traffic perform comparably to those trained on real data, validating its utility for real-world security applications.",
      "tr": "**Makale Başlığı:** TempoNet: Ağ Trafiği Simülasyonu İçin Gerçekçi İletişim ve Zamanlama Desenlerini Öğrenmek\n\n**Özet:**\nGerçekçi ağ trafiği simülasyonu, saldırı tespit sistemlerinin değerlendirilmesi, ağ protokollerinin stres testi ve siber güvenlik eğitimi için yüksek sadakatli ortamların oluşturulması açısından kritik öneme sahiptir. Saldırı trafiği genellikle red-teaming veya replay yöntemleri kullanılarak eğitim ortamlarına katmanlanabilirken, özgün zararsız arka plan trafiği üretmek, özellikle gerçek dünya ağlarının karmaşık zamansal ve iletişim dinamiklerini simüle etmede temel bir zorluk olmaya devam etmektedir. Bu makale, çoklu görev öğrenimini (multi-task learning) çok işaretli zamansal nokta süreçleri (multi-mark temporal point processes) ile birleştiren yeni bir üretici model olan TempoNet'i tanıtmaktadır. TempoNet, paket varış zamanlarını ve tüm paket ve akış başlığı alanlarını (packet- and flow-header fields) ortaklaşa modellemektedir. TempoNet, konak çifti davranışı (host-pair behavior) ve mevsimsel eğilimler gibi üst düzey korelasyonları ve hassas zamanlama desenlerini yakalamaktadır. Bu model, yapılandırılmış zamansal değişimi yeniden üretemeyen GAN-, LLM- ve Bayesian tabanlı yöntemlerin (GAN-, LLM-, and Bayesian-based methods) temel sınırlılıklarını ele almaktadır. TempoNet, gerçek dünya veri kümelerinde doğrulanmış, zamansal olarak tutarlı, yüksek sadakatli izler (high-fidelity traces) üretmektedir. Dahası, TempoNet tarafından üretilen arka plan trafiği üzerinde eğitilen saldırı tespit modellerinin, gerçek veriler üzerinde eğitilen modellere kıyasla benzer performans gösterdiğini ortaya koymaktayız. Bu durum, TempoNet'in gerçek dünya güvenlik uygulamaları için faydasını doğrulamaktadır."
    }
  },
  {
    "id": "2601.15652v1",
    "title": "Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models",
    "authors": [
      "Manish Bhatt"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.AI",
      "cs.CR",
      "cs.ET"
    ],
    "link": "http://arxiv.org/abs/2601.15652v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15652v1",
    "content": {
      "en": "Hallucinations in Large Language Models (LLMs) -- generations that are plausible but factually unfaithful -- remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims).   Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises (\"Sycophancy\").   This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.",
      "tr": "Elbette, akademik makale başlığı ve özetinin istenen şekilde çevirisi aşağıdadır:\n\n**Makale Başlığı:** Large Language Models'ta Halüsinasyon Tespiti İçin Predictive Coding ve Information Bottleneck\n\n**Özet:**\n\nLarge Language Models'taki (LLM) halüsinasyonlar -- yani makul ancak olgusal olarak sadık olmayan çıktılar -- yüksek riskli dağıtımlar için kritik bir engel olmaya devam etmektedir. Mevcut tespit yöntemleri genellikle hesaplama açısından pahalı harici retrieval döngülerine veya 70B+ parametre gerektiren opak black-box LLM yargıçlarına dayanmaktadır. Bu çalışmada, nörobilimden esinlenen sinyal tasarımı ile supervised machine learning'i birleştiren hibrit bir tespit framework'ü olan [Model Adı]'nı tanıtıyoruz. Predictive Coding (iç önceliklere karşı sürprizin ölçülmesi) ve Information Bottleneck (pertürbasyon altındaki sinyal tutulmasının ölçülmesi) ilkelerine dayanan yorumlanabilir sinyaller çıkarıyoruz. Sistematik ablasyon çalışmalarıyla üç temel iyileştirmeyi gösteriyoruz: Entity-Focused Uptake (yüksek değerli token'lara odaklanma), Context Adherence (temellendirme gücünün ölçülmesi) ve Falsifiability Score (güvenli ancak çelişkili iddiaların tespiti). HaluBench üzerinde yapılan değerlendirmelerde (n=200, mükemmel dengeli), teori güdümlü taban çizgimiz 0.8017 AUROC elde etmektedir. BASE supervised modeller 0.8274 AUROC'a ulaşırken, IMPROVED özellikler performansı 0.8669 AUROC'a (4.95% kazanç) yükseltmektedir. Bu durum, mimariler boyunca tutarlı iyileşmeler göstermektedir. Bu rekabetçi performans, Lynx'e kıyasla 75 kat daha az eğitim verisi (200'e karşılık 15.000 örnek), 1000 kat daha hızlı inference (5ms'ye karşılık 5s) kullanılarak ve tamamen yorumlanabilir kalarak elde edilmiştir. Önemlisi, olumsuz bir sonuç rapor ediyoruz: Rationalization sinyalinin halüsinasyonları ayırt edemediği, LLM'lerin yanlış öncüller için tutarlı reasoning ürettiğini (\"Sycophancy\") düşündürmektedir. Bu çalışma, sinyal mimarisinde kodlanmış alan bilgisinin, LLM yargıçlarının ölçeklenmesine kıyasla üstün veri verimliliği sağladığını, üretim dağıtımına uygun hafif (1M parametrenin altında), açıklanabilir modellerle güçlü performans elde ettiğini göstermektedir."
    }
  },
  {
    "id": "2601.15595v1",
    "title": "Data-Free Privacy-Preserving for LLMs via Model Inversion and Selective Unlearning",
    "authors": [
      "Xinjie Zhou",
      "Zhihui Yang",
      "Lechao Cheng",
      "Sai Wu",
      "Gang Chen"
    ],
    "published_date": "2026-01-22",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2601.15595v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15595v1",
    "content": {
      "en": "Large language models (LLMs) exhibit powerful capabilities but risk memorizing sensitive personally identifiable information (PII) from their training data, posing significant privacy concerns. While machine unlearning techniques aim to remove such data, they predominantly depend on access to the training data. This requirement is often impractical, as training data in real-world deployments is commonly proprietary or inaccessible. To address this limitation, we propose Data-Free Selective Unlearning (DFSU), a novel privacy-preserving framework that removes sensitive PII from an LLM without requiring its training data. Our approach first synthesizes pseudo-PII through language model inversion, then constructs token-level privacy masks for these synthetic samples, and finally performs token-level selective unlearning via a contrastive mask loss within a low-rank adaptation (LoRA) subspace. Extensive experiments on the AI4Privacy PII-Masking dataset using Pythia models demonstrate that our method effectively removes target PII while maintaining model utility.",
      "tr": "Makale Başlığı: LLM'ler İçin Model İnversiyonu ve Seçici Unlearning Yoluyla Veri Gerektirmeyen Gizlilik Koruma\n\nÖzet:\nBüyük dil modelleri (LLM'ler) güçlü yetenekler sergiler ancak eğitim verilerinden hassas kişisel tanımlayıcı bilgileri (PII) ezberleme riski taşır, bu da önemli gizlilik endişeleri doğurur. Makine unlearning teknikleri bu tür verileri kaldırmayı hedeflerken, büyük ölçüde eğitim verilerine erişime bağlıdır. Gerçek dünya dağıtımlarında eğitim verileri yaygın olarak tescilli veya erişilemez olduğundan bu gereklilik sıklıkla pratikte uygulanamazdır. Bu sınırlamanın üstesinden gelmek için, eğitim verisine ihtiyaç duymadan bir LLM'den hassas PII'yi kaldıran yeni bir gizlilik koruma çerçevesi olan Veri Gerektirmeyen Seçici Unlearning (DFSU) öneriyoruz. Yaklaşımımız ilk olarak language model inversion aracılığıyla sözde PII sentezler, ardından bu sentetik örnekler için token-level privacy masks oluşturur ve son olarak düşük rank adaptasyonu (LoRA) alt uzayında bir contrastive mask loss aracılığıyla token-level selective unlearning gerçekleştirir. Pythia modelleri kullanılarak AI4Privacy PII-Masking veri kümesi üzerinde yapılan kapsamlı deneyler, yöntemimizin model faydasını korurken hedef PII'yi etkili bir şekilde kaldırdığını göstermektedir."
    }
  },
  {
    "id": "2601.15474v1",
    "title": "Multi-Targeted Graph Backdoor Attack",
    "authors": [
      "Md Nabi Newaz Khan",
      "Abdullah Arafat Miah",
      "Yu Bi"
    ],
    "published_date": "2026-01-21",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2601.15474v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15474v1",
    "content": {
      "en": "Graph neural network (GNN) have demonstrated exceptional performance in solving critical problems across diverse domains yet remain susceptible to backdoor attacks. Existing studies on backdoor attack for graph classification are limited to single target attack using subgraph replacement based mechanism where the attacker implants only one trigger into the GNN model. In this paper, we introduce the first multi-targeted backdoor attack for graph classification task, where multiple triggers simultaneously redirect predictions to different target labels. Instead of subgraph replacement, we propose subgraph injection which preserves the structure of the original graphs while poisoning the clean graphs. Extensive experiments demonstrate the efficacy of our approach, where our attack achieves high attack success rates for all target labels with minimal impact on the clean accuracy. Experimental results on five dataset demonstrate the superior performance of our attack framework compared to the conventional subgraph replacement-based attack. Our analysis on four GNN models confirms the generalization capability of our attack which is effective regardless of the GNN model architectures and training parameters settings. We further investigate the impact of the attack design parameters including injection methods, number of connections, trigger sizes, trigger edge density and poisoning ratios. Additionally, our evaluation against state-of-the-art defenses (randomized smoothing and fine-pruning) demonstrates the robustness of our proposed multi-target attacks. This work highlights the GNN vulnerability against multi-targeted backdoor attack in graph classification task. Our source codes will be available at https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack.",
      "tr": "**Makale Başlığı: Multi-Targeted Graph Backdoor Attack**\n\n**Özet:**\n\nGraph neural network (GNN'ler), çeşitli alanlardaki kritik sorunları çözmede olağanüstü performans sergilemelerine rağmen, backdoor attack'lara karşı hassasiyetlerini korumaktadır. Graph classification için mevcut backdoor attack çalışmaları, yalnızca bir tetikleyiciyi GNN modeline yerleştiren subgraph replacement tabanlı mekanizma üzerinden tek hedefli saldırılarla sınırlıdır. Bu makalede, graph classification görevi için ilk kez multi-targeted backdoor attack'ı tanıtıyoruz; bu saldırıda birden fazla tetikleyici, tahminleri eşzamanlı olarak farklı hedef etiketlere yönlendirir. Subgraph replacement yerine, orijinal grafiğin yapısını korurken temiz grafikleri zehirleyen subgraph injection'ı öneriyoruz. Kapsamlı deneyler, yaklaşımımızın etkinliğini göstermektedir; saldırımız, temiz doğruluk üzerindeki minimum etkiyle tüm hedef etiketler için yüksek attack success rates elde etmektedir. Beş veri kümesi üzerinde yapılan deneysel sonuçlar, saldırı çerçevemizin geleneksel subgraph replacement tabanlı saldırıya kıyasla üstün performansını ortaya koymaktadır. Dört GNN modelini içeren analizimiz, GNN model mimarilerinden ve eğitim parametreleri ayarlarından bağımsız olarak etkili olan saldırımızın generalization capability'sini doğrulamaktadır. Ayrıca, injection methods, number of connections, trigger sizes, trigger edge density ve poisoning ratios gibi attack design parametrelerinin etkisini daha detaylı inceledik. Ek olarak, state-of-the-art savunmalara (randomized smoothing ve fine-pruning) karşı yapılan değerlendirmemiz, önerdiğimiz multi-target saldırıların robustness'ını göstermektedir. Bu çalışma, graph classification görevinde GNN'lerin multi-targeted backdoor attack'lara karşı savunmasızlığını vurgulamaktadır. Kaynak kodlarımız https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack adresinde sunulacaktır."
    }
  },
  {
    "id": "2601.15177v1",
    "title": "Dynamic Management of a Deep Learning-Based Anomaly Detection System for 5G Networks",
    "authors": [
      "Lorenzo Fernández Maimó",
      "Alberto Huertas Celdrán",
      "Manuel Gil Pérez",
      "Félix J. García Clemente",
      "Gregorio Martínez Pérez"
    ],
    "published_date": "2026-01-21",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2601.15177v1",
    "pdf_link": "https://arxiv.org/pdf/2601.15177v1",
    "content": {
      "en": "Fog and mobile edge computing (MEC) will play a key role in the upcoming fifth generation (5G) mobile networks to support decentralized applications, data analytics and management into the network itself by using a highly distributed compute model. Furthermore, increasing attention is paid to providing user-centric cybersecurity solutions, which particularly require collecting, processing and analyzing significantly large amount of data traffic and huge number of network connections in 5G networks. In this regard, this paper proposes a MEC-oriented solution in 5G mobile networks to detect network anomalies in real-time and in autonomic way. Our proposal uses deep learning techniques to analyze network flows and to detect network anomalies. Moreover, it uses policies in order to provide an efficient and dynamic management system of the computing resources used in the anomaly detection process. The paper presents relevant aspects of the deployment of the proposal and experimental results to show its performance.",
      "tr": "**Makale Başlığı Çevirisi:** 5G Ağları İçin Derin Öğrenme Tabanlı Anomali Tespit Sisteminin Dinamik Yönetimi\n\n**Özet Çevirisi:**\n\nGelişmekte olan beşinci nesil (5G) mobil ağlarda, oldukça dağıtık bir hesaplama modeli kullanarak ağın kendisine merkezi olmayan uygulamaları, veri analitiğini ve yönetimi desteklemek için fog ve mobile edge computing (MEC) kritik bir rol oynayacaktır. Dahası, özellikle 5G ağlarındaki büyük miktardaki veri trafiğini ve çok sayıda ağ bağlantısını toplama, işleme ve analiz etme ihtiyacını ortaya çıkaran, kullanıcı odaklı siber güvenlik çözümleri sunulmasına giderek daha fazla önem verilmektedir. Bu doğrultuda, bu makale 5G mobil ağlarda ağ anormalliklerini gerçek zamanlı ve otonom bir şekilde tespit etmek için MEC odaklı bir çözüm sunmaktadır. Önerimiz, ağ akışlarını analiz etmek ve ağ anormalliklerini tespit etmek için derin öğrenme tekniklerini kullanmaktadır. Ayrıca, anomali tespit sürecinde kullanılan hesaplama kaynaklarının verimli ve dinamik bir yönetim sistemini sağlamak amacıyla politikalar kullanmaktadır. Makale, önerinin dağıtımına ilişkin ilgili yönleri ve performansını göstermek için deneysel sonuçları sunmaktadır."
    }
  }
]