[
  {
    "id": "2602.03085v1",
    "title": "The Trigger in the Haystack: Extracting and Reconstructing LLM Backdoor Triggers",
    "authors": [
      "Blake Bullwinkel",
      "Giorgio Severi",
      "Keegan Hines",
      "Amanda Minnich",
      "Ram Shankar Siva Kumar"
    ],
    "published_date": "2026-02-03",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2602.03085v1",
    "pdf_link": "https://arxiv.org/pdf/2602.03085v1",
    "content": {
      "en": "Detecting whether a model has been poisoned is a longstanding problem in AI security. In this work, we present a practical scanner for identifying sleeper agent-style backdoors in causal language models. Our approach relies on two key findings: first, sleeper agents tend to memorize poisoning data, making it possible to leak backdoor examples using memory extraction techniques. Second, poisoned LLMs exhibit distinctive patterns in their output distributions and attention heads when backdoor triggers are present in the input. Guided by these observations, we develop a scalable backdoor scanning methodology that assumes no prior knowledge of the trigger or target behavior and requires only inference operations. Our scanner integrates naturally into broader defensive strategies and does not alter model performance. We show that our method recovers working triggers across multiple backdoor scenarios and a broad range of models and fine-tuning methods.",
      "tr": "**Makale Başlığı:** The Trigger in the Haystack: LLM Geri Kapı Tetikleyicilerinin Çıkarılması ve Yeniden Yapılandırılması\n\n**Özet:**\nBir modelin zehirlenip zehirlenmediğini tespit etmek, AI security alanında uzun süredir devam eden bir sorundur. Bu çalışmada, nedensel dil modellerinde sleeper agent tarzı geri kapıları belirlemek için pratik bir tarayıcı sunuyoruz. Yaklaşımımız iki temel bulguya dayanmaktadır: ilk olarak, sleeper agent'lar zehirlenme verilerini ezberleme eğilimindedir, bu da memory extraction techniques kullanılarak backdoor örneklerinin sızdırılmasını mümkün kılar. İkinci olarak, zehirlenmiş LLM'ler, girdi içinde backdoor tetikleyicileri bulunduğunda, çıktı dağılımları ve attention heads'larında belirgin desenler sergilerler. Bu gözlemlerden yola çıkarak, tetikleyici veya hedef davranış hakkında önceden bilgi sahibi olmayı varsaymayan ve yalnızca inference operations gerektiren ölçeklenebilir bir backdoor tarama metodolojisi geliştiriyoruz. Tarayıcımız, daha geniş savunma stratejilerine doğal olarak entegre olur ve model performansını değiştirmez. Yöntemimizin, birden fazla backdoor senaryosunda ve geniş bir model ve fine-tuning yöntemleri yelpazesinde çalışan tetikleyicileri kurtardığını gösteriyoruz."
    }
  },
  {
    "id": "2602.03035v1",
    "title": "Generalizable and Interpretable RF Fingerprinting with Shapelet-Enhanced Large Language Models",
    "authors": [
      "Tianya Zhao",
      "Junqing Zhang",
      "Haowen Xu",
      "Xiaoyan Sun",
      "Jun Dai"
    ],
    "published_date": "2026-02-03",
    "tags": [
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2602.03035v1",
    "pdf_link": "https://arxiv.org/pdf/2602.03035v1",
    "content": {
      "en": "Deep neural networks (DNNs) have achieved remarkable success in radio frequency (RF) fingerprinting for wireless device authentication. However, their practical deployment faces two major limitations: domain shift, where models trained in one environment struggle to generalize to others, and the black-box nature of DNNs, which limits interpretability. To address these issues, we propose a novel framework that integrates a group of variable-length two-dimensional (2D) shapelets with a pre-trained large language model (LLM) to achieve efficient, interpretable, and generalizable RF fingerprinting. The 2D shapelets explicitly capture diverse local temporal patterns across the in-phase and quadrature (I/Q) components, providing compact and interpretable representations. Complementarily, the pre-trained LLM captures more long-range dependencies and global contextual information, enabling strong generalization with minimal training overhead. Moreover, our framework also supports prototype generation for few-shot inference, enhancing cross-domain performance without additional retraining. To evaluate the effectiveness of our proposed method, we conduct extensive experiments on six datasets across various protocols and domains. The results show that our method achieves superior standard and few-shot performance across both source and unseen domains.",
      "tr": "Elbette, makale başlığı ve özetinin çevirisi aşağıdadır:\n\n**Makale Başlığı:** Generalizable and Interpretable RF Fingerprinting with Shapelet-Enhanced Large Language Models\n\n**Özet:**\nDerin öğrenme ağları (DNNs), kablosuz cihaz kimlik doğrulaması için radyo frekansı (RF) parmak izi alma alanında dikkate değer başarılar elde etmiştir. Ancak, pratik uygulamaları iki önemli sınırlamayla karşı karşıyadır: alan kayması (domain shift), yani bir ortamda eğitilen modellerin diğerlerine genelleştirilmesinde zorlanması ve DNN'lerin yorumlanabilirliği (interpretability) sınırlayan kara kutu (black-box) doğası. Bu sorunları ele almak amacıyla, verimli, yorumlanabilir ve genellenebilir RF parmak izi alma özelliğini elde etmek için bir grup değişken uzunlukta iki boyutlu (2D) shapelet'i önceden eğitilmiş büyük dil modeli (LLM) ile entegre eden yeni bir framework öneriyoruz. 2D shapelet'ler, faz içi (in-phase) ve faz dışı (quadrature) (I/Q) bileşenler boyunca çeşitli yerel zamansal desenleri açıkça yakalayarak kompakt ve yorumlanabilir temsiller sunar. Tamamlayıcı olarak, önceden eğitilmiş LLM daha uzun menzilli bağımlılıkları ve küresel bağlamsal bilgileri yakalar, bu da minimum eğitim maliyetiyle güçlü genelleme (generalization) sağlar. Dahası, framework'ümüz ek yeniden eğitim gerektirmeden alanlar arası performansı artıran az sayıda örnekle çıkarım (few-shot inference) için prototip üretimini de desteklemektedir. Önerilen yöntemimizin etkinliğini değerlendirmek için, çeşitli protokoller ve alanları kapsayan altı veri seti üzerinde kapsamlı deneyler gerçekleştiriyoruz. Sonuçlar, yöntemimizin hem kaynak hem de görülmemiş alanlarda üstün standart ve az sayıda örnekle çıkarım performansına ulaştığını göstermektedir."
    }
  },
  {
    "id": "2602.03012v1",
    "title": "CVE-Factory: Scaling Expert-Level Agentic Tasks for Code Security Vulnerability",
    "authors": [
      "Xianzhen Luo",
      "Jingyuan Zhang",
      "Shiqi Zhou",
      "Rain Huang",
      "Chuan Xiao"
    ],
    "published_date": "2026-02-03",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2602.03012v1",
    "pdf_link": "https://arxiv.org/pdf/2602.03012v1",
    "content": {
      "en": "Evaluating and improving the security capabilities of code agents requires high-quality, executable vulnerability tasks. However, existing works rely on costly, unscalable manual reproduction and suffer from outdated data distributions. To address these, we present CVE-Factory, the first multi-agent framework to achieve expert-level quality in automatically transforming sparse CVE metadata into fully executable agentic tasks. Cross-validation against human expert reproductions shows that CVE-Factory achieves 95\\% solution correctness and 96\\% environment fidelity, confirming its expert-level quality. It is also evaluated on the latest realistic vulnerabilities and achieves a 66.2\\% verified success. This automation enables two downstream contributions. First, we construct LiveCVEBench, a continuously updated benchmark of 190 tasks spanning 14 languages and 153 repositories that captures emerging threats including AI-tooling vulnerabilities. Second, we synthesize over 1,000 executable training environments, the first large-scale scaling of agentic tasks in code security. Fine-tuned Qwen3-32B improves from 5.3\\% to 35.8\\% on LiveCVEBench, surpassing Claude 4.5 Sonnet, with gains generalizing to Terminal Bench (12.5\\% to 31.3\\%). We open-source CVE-Factory, LiveCVEBench, Abacus-cve (fine-tuned model), training dataset, and leaderboard. All resources are available at https://github.com/livecvebench/CVE-Factory .",
      "tr": "İşte akademik makale başlığı ve özetinin istenen şekilde çevirisi:\n\n**Makale Başlığı:** CVE-Factory: Kod Güvenliği Açıkları İçin Uzman Seviyesinde Agentic Görevlerin Ölçeklendirilmesi\n\n**Özet:**\nKod ajanlarının güvenlik yeteneklerini değerlendirmek ve geliştirmek, yüksek kaliteli, yürütülebilir zafiyet görevleri gerektirir. Ancak mevcut çalışmalar, maliyetli, ölçeklenemeyen manuel yeniden üretimlere dayanmakta ve güncelliğini yitirmiş veri dağılımlarından muzdariptir. Bunları ele almak için, seyrek CVE metadata'sını otomatik olarak tam yürütülebilir agentic görevlere dönüştürmede uzman seviyesinde kaliteye ulaşan ilk çoklu-ajan (multi-agent) framework'ümüz CVE-Factory'yi sunuyoruz. İnsan uzman yeniden üretimlerine karşı çapraz doğrulama, CVE-Factory'nin %95 çözüm doğruluğu ve %96 environment fidelity'ye ulaştığını göstermekte, bu da onun uzman seviyesindeki kalitesini doğrulamaktadır. Ayrıca, en son gerçekçi zafiyetler üzerinde değerlendirilmiş ve %66.2 doğrulanmış başarı elde etmiştir. Bu otomasyon, iki ikincil katkı sağlamaktadır. İlk olarak, AI-tooling zafiyetleri dahil olmak üzere ortaya çıkan tehditleri kapsayan, 14 dil ve 153 depoyu kapsayan 190 görevden oluşan sürekli güncellenen bir benchmark olan LiveCVEBench'i inşa ediyoruz. İkinci olarak, kod güvenliğinde agentic görevlerin ilk büyük ölçekli ölçeklenmesi olan 1.000'den fazla yürütülebilir eğitim ortamı sentezliyoruz. İnce ayarlanmış (fine-tuned) Qwen3-32B, LiveCVEBench üzerinde %5.3'ten %35.8'e yükselerek Claude 4.5 Sonnet'i geride bırakmakta ve elde edilen kazançlar Terminal Bench'e (önce %12.5, sonra %31.3) genellemektedir. CVE-Factory, LiveCVEBench, Abacus-cve (fine-tuned model), eğitim veri seti ve leaderboard'u açık kaynak olarak sunuyoruz. Tüm kaynaklar https://github.com/livecvebench/CVE-Factory adresinden temin edilebilir."
    }
  },
  {
    "id": "2602.02962v1",
    "title": "Q-ShiftDP: A Differentially Private Parameter-Shift Rule for Quantum Machine Learning",
    "authors": [
      "Hoang M. Ngo",
      "Nhat Hoang-Xuan",
      "Quan Nguyen",
      "Nguyen Do",
      "Incheol Shin"
    ],
    "published_date": "2026-02-03",
    "tags": [
      "cs.LG",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2602.02962v1",
    "pdf_link": "https://arxiv.org/pdf/2602.02962v1",
    "content": {
      "en": "Quantum Machine Learning (QML) promises significant computational advantages, but preserving training data privacy remains challenging. Classical approaches like differentially private stochastic gradient descent (DP-SGD) add noise to gradients but fail to exploit the unique properties of quantum gradient estimation. In this work, we introduce the Differentially Private Parameter-Shift Rule (Q-ShiftDP), the first privacy mechanism tailored to QML. By leveraging the inherent boundedness and stochasticity of quantum gradients computed via the parameter-shift rule, Q-ShiftDP enables tighter sensitivity analysis and reduces noise requirements. We combine carefully calibrated Gaussian noise with intrinsic quantum noise to provide formal privacy and utility guarantees, and show that harnessing quantum noise further improves the privacy-utility trade-off. Experiments on benchmark datasets demonstrate that Q-ShiftDP consistently outperforms classical DP methods in QML.",
      "tr": "Makale Başlığı: Q-ShiftDP: Kuantum Makine Öğrenmesi için Diferansiyel Olarak Gizli Parametre Kaydırma Kuralı\n\nÖzet:\nKuantum Makine Öğrenmesi (QML), önemli hesaplama avantajları vaat etmektedir, ancak eğitim verilerinin gizliliğini korumak zorluğunu sürdürmektedir. Diferansiyel olarak gizli stokastik gradyan inişi (DP-SGD) gibi klasik yaklaşımlar gradyanlara gürültü ekler, ancak kuantum gradyan tahmininin benzersiz özelliklerinden yararlanamaz. Bu çalışmada, QML'ye özel ilk gizlilik mekanizması olan Diferansiyel Olarak Gizli Parametre Kaydırma Kuralı'nı (Q-ShiftDP) sunmaktayız. Parametre kaydırma kuralı aracılığıyla hesaplanan kuantum gradyanlarının içsel sınırlılığı ve stokastik doğasından yararlanarak Q-ShiftDP, daha sıkı bir hassasiyet analizi sağlar ve gürültü gereksinimlerini azaltır. Resmi gizlilik ve fayda garantileri sağlamak için dikkatlice kalibre edilmiş Gaussian gürültüyü içsel kuantum gürültüsü ile birleştiriyoruz ve kuantum gürültüsünden yararlanmanın gizlilik-fayda takasını daha da iyileştirdiğini gösteriyoruz. Karşılaştırmalı veri kümeleri üzerindeki deneyler, Q-ShiftDP'nin QML'de klasik DP yöntemlerinden tutarlı bir şekilde daha iyi performans gösterdiğini ortaya koymaktadır."
    }
  },
  {
    "id": "2602.02929v1",
    "title": "RPG-AE: Neuro-Symbolic Graph Autoencoders with Rare Pattern Mining for Provenance-Based Anomaly Detection",
    "authors": [
      "Asif Tauhid",
      "Sidahmed Benabderrahmane",
      "Mohamad Altrabulsi",
      "Ahamed Foisal",
      "Talal Rahwan"
    ],
    "published_date": "2026-02-03",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.NE"
    ],
    "link": "http://arxiv.org/abs/2602.02929v1",
    "pdf_link": "https://arxiv.org/pdf/2602.02929v1",
    "content": {
      "en": "Advanced Persistent Threats (APTs) are sophisticated, long-term cyberattacks that are difficult to detect because they operate stealthily and often blend into normal system behavior. This paper presents a neuro-symbolic anomaly detection framework that combines a Graph Autoencoder (GAE) with rare pattern mining to identify APT-like activities in system-level provenance data. Our approach first constructs a process behavioral graph using k-Nearest Neighbors based on feature similarity, then learns normal relational structure using a Graph Autoencoder. Anomaly candidates are identified through deviations between observed and reconstructed graph structure. To further improve detection, we integrate an rare pattern mining module that discovers infrequent behavioral co-occurrences and uses them to boost anomaly scores for processes exhibiting rare signatures. We evaluate the proposed method on the DARPA Transparent Computing datasets and show that rare-pattern boosting yields substantial gains in anomaly ranking quality over the baseline GAE. Compared with existing unsupervised approaches on the same benchmark, our single unified model consistently outperforms individual context-based detectors and achieves performance competitive with ensemble aggregation methods that require multiple separate detectors. These results highlight the value of coupling graph-based representation learning with classical pattern mining to improve both effectiveness and interpretability in provenance-based security anomaly detection.",
      "tr": "**Makale Başlığı:** RPG-AE: Provenance Tabanlı Anomali Tespiti için Nadir Desen Madenciliği ile Nöro-Sembolik Grafik Otomatik Kodlayıcıları\n\n**Özet:**\nAdvanced Persistent Threats (APTs), gizlice hareket etmeleri ve genellikle normal sistem davranışlarına karışmaları nedeniyle tespiti zor olan sofistike, uzun süreli siber saldırılardır. Bu makale, sistem düzeyindeki provenance verilerinde APT benzeri faaliyetleri belirlemek için Nadir Desen Madenciliği ile bir Graph Autoencoder (GAE)'ı birleştiren bir nöro-sembolik anomali tespit çerçevesi sunmaktadır. Yaklaşımımız öncelikle özellik benzerliğine dayalı k-Nearest Neighbors kullanarak bir süreç davranış grafiği oluşturur, ardından bir Graph Autoencoder kullanarak normal ilişkisel yapıyı öğrenir. Anomali adayları, gözlemlenen ve yeniden yapılandırılan grafik yapısı arasındaki sapmalar yoluyla belirlenir. Tespiti daha da iyileştirmek için, nadir davranışsal eşzamanlılıkları keşfeden ve nadir imzalar sergileyen süreçler için anomali puanlarını artırmak amacıyla bunları kullanan bir rare pattern mining modülü entegre ediyoruz. Önerilen yöntemi DARPA Transparent Computing veri kümeleri üzerinde değerlendiriyoruz ve rare-pattern boosting'in temel GAE'ye göre anomali sıralama kalitesinde önemli kazanımlar sağladığını gösteriyoruz. Aynı benchmark üzerinde mevcut denetimsiz yaklaşımlarla karşılaştırıldığında, tekil birleşik modelimiz bireysel bağlam tabanlı dedektörlerden tutarlı bir şekilde daha iyi performans gösterir ve birden fazla ayrı dedektör gerektiren ensemble aggregation yöntemleriyle rekabetçi performans elde eder. Bu sonuçlar, provenance tabanlı güvenlik anomali tespitinde hem etkinliği hem de yorumlanabilirliği artırmak için grafik tabanlı temsil öğrenmesini klasik pattern mining ile eşleştirmenin değerini vurgulamaktadır."
    }
  },
  {
    "id": "2602.02925v1",
    "title": "Refining Decision Boundaries In Anomaly Detection Using Similarity Search Within the Feature Space",
    "authors": [
      "Sidahmed Benabderrahmane",
      "Petko Valtchev",
      "James Cheney",
      "Talal Rahwan"
    ],
    "published_date": "2026-02-02",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.NE"
    ],
    "link": "http://arxiv.org/abs/2602.02925v1",
    "pdf_link": "https://arxiv.org/pdf/2602.02925v1",
    "content": {
      "en": "Detecting rare and diverse anomalies in highly imbalanced datasets-such as Advanced Persistent Threats (APTs) in cybersecurity-remains a fundamental challenge for machine learning systems. Active learning offers a promising direction by strategically querying an oracle to minimize labeling effort, yet conventional approaches often fail to exploit the intrinsic geometric structure of the feature space for model refinement. In this paper, we introduce SDA2E, a Sparse Dual Adversarial Attention-based AutoEncoder designed to learn compact and discriminative latent representations from imbalanced, high-dimensional data. We further propose a similarity-guided active learning framework that integrates three novel strategies to refine decision boundaries efficiently: mormal-like expansion, which enriches the training set with points similar to labeled normals to improve reconstruction fidelity; anomaly-like prioritization, which boosts ranking accuracy by focusing on points resembling known anomalies; and a hybrid strategy that combines both for balanced model refinement and ranking. A key component of our framework is a new similarity measure, Normalized Matching 1s (SIM_NM1), tailored for sparse binary embeddings. We evaluate SDA2E extensively across 52 imbalanced datasets, including multiple DARPA Transparent Computing scenarios, and benchmark it against 15 state-of-the-art anomaly detection methods. Results demonstrate that SDA2E consistently achieves superior ranking performance (nDCG up to 1.0 in several cases) while reducing the required labeled data by up to 80% compared to passive training. Statistical tests confirm the significance of these improvements. Our work establishes a robust, efficient, and statistically validated framework for anomaly detection that is particularly suited to cybersecurity applications such as APT detection.",
      "tr": "**Makale Başlığı:** Özellik Uzayında Benzerlik Araması Kullanarak Anomali Tespitinde Karar Sınırlarını İyileştirme\n\n**Özet:**\n\nSiber güvenlikteki Advanced Persistent Threats (APTs) gibi yüksek derecede dengesiz veri kümelerindeki nadir ve çeşitli anomalilerin tespiti, makine öğrenimi sistemleri için temel bir zorluk olmaya devam etmektedir. Active learning, etiketleme çabasını en aza indirmek için stratejik olarak bir oracle'a sorgu yaparak umut verici bir yön sunar; ancak geleneksel yaklaşımlar, model iyileştirmesi için özellik uzayının içsel geometrik yapısından yararlanmakta sıklıkla yetersiz kalmaktadır. Bu makalede, dengesiz, yüksek boyutlu verilerden kompakt ve ayırt edici latent temsiller öğrenmek üzere tasarlanmış bir Sparse Dual Adversarial Attention-based AutoEncoder olan SDA2E'yi tanıtıyoruz. Ayrıca, karar sınırlarını verimli bir şekilde iyileştirmek için üç yeni stratejiyi entegre eden benzerlik güdümlü bir active learning framework'ü öneriyoruz: ricostruction fidelity'yi geliştirmek için etiketlenmiş normal noktalara benzeyen noktalarla eğitim setini zenginleştiren mormal-like expansion; bilinen anomalilere benzeyen noktalara odaklanarak ranking accuracy'yi artıran anomaly-like prioritization; ve dengeli model iyileştirmesi ile ranking'i birleştiren hibrit bir strateji. Framework'ümüzün temel bir bileşeni, sparse binary embeddings için özel olarak tasarlanmış yeni bir benzerlik ölçüsü olan Normalized Matching 1s (SIM_NM1)'dir. SDA2E'yi, DARPA Transparent Computing senaryoları dahil olmak üzere 52 dengesiz veri kümesinde kapsamlı bir şekilde değerlendiriyor ve 15 state-of-the-art anomali tespit yöntemiyle karşılaştırıyoruz. Sonuçlar, SDA2E'nin pasif eğitime kıyasla gerekli etiketli veriyi %80'e kadar azaltırken, tutarlı bir şekilde üstün ranking performansı (bazı durumlarda 1.0'a kadar nDCG) elde ettiğini göstermektedir. İstatistiksel testler bu iyileştirmelerin anlamlılığını doğrulamaktadır. Çalışmamız, özellikle APT tespiti gibi siber güvenlik uygulamalarına uygun, sağlam, verimli ve istatistiksel olarak doğrulanmış bir anomali tespit framework'ü oluşturmaktadır."
    }
  },
  {
    "id": "2602.02781v1",
    "title": "Evaluating False Alarm and Missing Attacks in CAN IDS",
    "authors": [
      "Nirab Hossain",
      "Pablo Moriano"
    ],
    "published_date": "2026-02-02",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2602.02781v1",
    "pdf_link": "https://arxiv.org/pdf/2602.02781v1",
    "content": {
      "en": "Modern vehicles rely on electronic control units (ECUs) interconnected through the Controller Area Network (CAN), making in-vehicle communication a critical security concern. Machine learning (ML)-based intrusion detection systems (IDS) are increasingly deployed to protect CAN traffic, yet their robustness against adversarial manipulation remains largely unexplored. We present a systematic adversarial evaluation of CAN IDS using the ROAD dataset, comparing four shallow learning models with a deep neural network-based detector. Using protocol-compliant, payload-level perturbations generated via FGSM, BIM and PGD, we evaluate adversarial effects on both benign and malicious CAN frames. While all models achieve strong baseline performance under benign conditions, adversarial perturbations reveal substantial vulnerabilities. Although shallow and deep models are robust to false-alarm induction, with the deep neural network (DNN) performing best on benign traffic, all architectures suffer significant increases in missed attacks. Notably, under gradient-based attacks, the shallow model extra trees (ET) demonstrates improved robustness to missed-attack induction compared to the other models. Our results demonstrate that adversarial manipulation can simultaneously trigger false alarms and evade detection, underscoring the need for adversarial robustness evaluation in safety-critical automotive IDS.",
      "tr": "**Makale Başlığı:** CAN IDS'de Yanlış Alarm ve Saldırı Gözden Kaçırma Değerlendirmesi\n\n**Özet:**\n\nModern araçlar, Controller Area Network (CAN) üzerinden birbirine bağlı elektronik kontrol ünitelerine (ECU'lar) dayanır ve araç içi iletişimi kritik bir güvenlik endişesi haline getirir. Makine öğrenmesi (ML) tabanlı saldırı tespit sistemleri (IDS), CAN trafiğini korumak için giderek daha fazla kullanılmaktadır, ancak gelişigüzel manipülasyona karşı dayanıklılıkları büyük ölçüde keşfedilmemiş durumdadır. Bu çalışmada, ROAD veri kümesi kullanılarak CAN IDS'nin sistematik bir gelişigüzel değerlendirmesi sunulmakta ve dört sığ öğrenme modeli, derin bir sinir ağı tabanlı dedektör ile karşılaştırılmaktadır. FGSM, BIM ve PGD aracılığıyla üretilen protokole uygun, payload seviyesindeki pertürbasyonlar kullanılarak, hem zararsız hem de kötü niyetli CAN çerçeveleri üzerindeki gelişigüzel etkiler değerlendirilmektedir. Tüm modeller zararsız koşullar altında güçlü bir temel performans sergilerken, gelişigüzel pertürbasyonlar önemli zafiyetleri ortaya çıkarmaktadır. Sığ ve derin modeller yanlış alarmların tetiklenmesine karşı dayanıklı olsa da (derin sinir ağı (DNN) zararsız trafikte en iyi performansı göstermektedir), tüm mimarilerde gözden kaçan saldırılarda önemli artışlar görülmektedir. Özellikle, gradyan tabanlı saldırılar altında, sığ model extra trees (ET), diğer modellere kıyasla gözden kaçan saldırıların tetiklenmesine karşı daha iyi bir dayanıklılık sergilemektedir. Sonuçlarımız, gelişigüzel manipülasyonun aynı anda yanlış alarmları tetikleyebildiğini ve tespit edilmekten kaçabildiğini göstermekte ve güvenlik açısından kritik otomotiv IDS'lerinde gelişigüzel dayanıklılık değerlendirmesinin gerekliliğini vurgulamaktadır."
    }
  },
  {
    "id": "2602.02766v1",
    "title": "Privately Fine-Tuned LLMs Preserve Temporal Dynamics in Tabular Data",
    "authors": [
      "Lucas Rosenblatt",
      "Peihan Liu",
      "Ryan McKenna",
      "Natalia Ponomareva"
    ],
    "published_date": "2026-02-02",
    "tags": [
      "cs.LG",
      "cs.CL",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2602.02766v1",
    "pdf_link": "https://arxiv.org/pdf/2602.02766v1",
    "content": {
      "en": "Research on differentially private synthetic tabular data has largely focused on independent and identically distributed rows where each record corresponds to a unique individual. This perspective neglects the temporal complexity in longitudinal datasets, such as electronic health records, where a user contributes an entire (sub) table of sequential events. While practitioners might attempt to model such data by flattening user histories into high-dimensional vectors for use with standard marginal-based mechanisms, we demonstrate that this strategy is insufficient. Flattening fails to preserve temporal coherence even when it maintains valid marginal distributions. We introduce PATH, a novel generative framework that treats the full table as the unit of synthesis and leverages the autoregressive capabilities of privately fine-tuned large language models. Extensive evaluations show that PATH effectively captures long-range dependencies that traditional methods miss. Empirically, our method reduces the distributional distance to real trajectories by over 60% and reduces state transition errors by nearly 50% compared to leading marginal mechanisms while achieving similar marginal fidelity.",
      "tr": "**Makale Başlığı:** Privately Fine-Tuned LLMs Temporal Dynamics in Tabular Data'da Korur\n\n**Özet:**\n\nDifferentially private sentetik tablo verileri üzerine yapılan araştırmalar büyük ölçüde bağımsız ve aynı şekilde dağılmış satırlara odaklanmıştır; burada her kayıt benzersiz bir bireye karşılık gelir. Bu bakış açısı, elektronik sağlık kayıtları gibi boylamsal veri kümelerindeki zamansal karmaşıklığı göz ardı eder; burada bir kullanıcı sıralı olaylardan oluşan bir (alt) tablonun tamamını sağlar. Uygulayıcılar, bu tür verileri standart marjinal tabanlı mekanizmalarla kullanmak üzere kullanıcı geçmişlerini yüksek boyutlu vektörlere düzleştirerek modellemeye çalışsalar da, bu stratejinin yetersiz olduğunu gösteriyoruz. Düzleştirme, geçerli marjinal dağılımları korusa bile zamansal tutarlılığı korumada başarısız olur. Biz, tüm tabloyu sentez birimi olarak ele alan ve privately fine-tuned large language models'ın otoregresif yeteneklerinden yararlanan yeni bir üretken çerçeve olan PATH'ı sunuyoruz. Kapsamlı değerlendirmeler, PATH'ın geleneksel yöntemlerin gözden kaçırdığı uzun menzilli bağımlılıkları etkili bir şekilde yakaladığını göstermektedir. Ampirik olarak, yöntemimiz gerçek yörüngelere olan dağılımsal mesafeyi %60'tan fazla azaltır ve benzer marjinal doğruluk sağlarken önde gelen marjinal mekanizmalara kıyasla durum geçiş hatalarını neredeyse %50 azaltır."
    }
  },
  {
    "id": "2602.02689v1",
    "title": "Eidolon: A Practical Post-Quantum Signature Scheme Based on k-Colorability in the Age of Graph Neural Networks",
    "authors": [
      "Asmaa Cherkaoui",
      "Ramon Flores",
      "Delaram Kahrobaei",
      "Richard Wilson"
    ],
    "published_date": "2026-02-02",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2602.02689v1",
    "pdf_link": "https://arxiv.org/pdf/2602.02689v1",
    "content": {
      "en": "We propose Eidolon, a practical post-quantum signature scheme based on the NP-complete k-colorability problem. Our construction generalizes the Goldreich-Micali-Wigderson zero-knowledge protocol to arbitrary k >= 3, applies the Fiat-Shamir transform, and uses Merkle-tree commitments to compress signatures from O(tn) to O(t log n). Crucially, we generate hard instances via planted \"quiet\" colorings that preserve the statistical profile of random graphs. We present the first empirical security analysis of such a scheme against both classical solvers (ILP, DSatur) and a custom graph neural network (GNN) attacker. Experiments show that for n >= 60, neither approach recovers the secret coloring, demonstrating that well-engineered k-coloring instances can resist modern cryptanalysis, including machine learning. This revives combinatorial hardness as a credible foundation for post-quantum signatures.",
      "tr": "**Makale Başlığı:** Eidolon: Yapay Sinir Ağları Çağında k-Colorability Temelli Pratik Kuantum Sonrası İmza Şeması\n\n**Özet:**\n\nBu çalışmada, NP-tam k-colorability problemine dayanan pratik bir post-quantum imza şeması olan Eidolon'u sunuyoruz. İnşaatımız, Goldreich-Micali-Wigderson sıfır-bilgi protokolünü keyfi k >= 3'e genellemekte, Fiat-Shamir transformunu uygulamakta ve Merkle-tree commitments kullanarak imzaları O(tn)'den O(t log n)'e sıkıştırmaktadır. Kritik olarak, rastgele grafiklerin istatistiksel profilini koruyan ekilmiş \"sakin\" renklendirmeler aracılığıyla zor örnekler üretiyoruz. Bu tür bir şemanın hem klasik çözücülere (ILP, DSatur) hem de özel bir graph neural network (GNN) saldırganına karşı ilk ampirik güvenlik analizini sunuyoruz. Deneyler, n >= 60 için, hiçbir yaklaşımın gizli renklendirmeyi geri kazanamadığını göstermektedir, bu da iyi tasarlanmış k-coloring örneklerinin makine öğrenmesi dahil olmak üzere modern kriptanalize direnebileceğini ortaya koymaktadır. Bu bulgu, post-quantum imzalar için inanılır bir temel olarak kombinatoryal zorluğu yeniden canlandırmaktadır."
    }
  },
  {
    "id": "2602.02686v1",
    "title": "Monotonicity as an Architectural Bias for Robust Language Models",
    "authors": [
      "Patrick Cooper",
      "Alireza Nadali",
      "Ashutosh Trivedi",
      "Alvaro Velasquez"
    ],
    "published_date": "2026-02-02",
    "tags": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2602.02686v1",
    "pdf_link": "https://arxiv.org/pdf/2602.02686v1",
    "content": {
      "en": "Large language models (LLMs) are known to exhibit brittle behavior under adversarial prompts and jailbreak attacks, even after extensive alignment and fine-tuning. This fragility reflects a broader challenge of modern neural language models: small, carefully structured perturbations in high-dimensional input spaces can induce large and unpredictable changes in internal semantic representations and output.   We investigate monotonicity as an architectural inductive bias for improving the robustness of Transformer-based language models. Monotonicity constrains semantic transformations so that strengthening information, evidence, or constraints cannot lead to regressions in the corresponding internal representations. Such order-preserving behavior has long been exploited in control and safety-critical systems to simplify reasoning and improve robustness, but has traditionally been viewed as incompatible with the expressivity required by neural language models.   We show that this trade-off is not inherent. By enforcing monotonicity selectively in the feed-forward sublayers of sequence-to-sequence Transformers -- while leaving attention mechanisms unconstrained -- we obtain monotone language models that preserve the performance of their pretrained counterparts. This architectural separation allows negation, contradiction, and contextual interactions to be introduced explicitly through attention, while ensuring that subsequent semantic refinement is order-preserving. Empirically, monotonicity substantially improves robustness: adversarial attack success rates drop from approximately 69% to 19%, while standard summarization performance degrades only marginally.",
      "tr": "**Makale Başlığı:** Monotonicity as an Architectural Bias for Robust Language Models\n\n**Özet:**\n\nBüyük dil modelleri (LLMs), kapsamlı hizalama (alignment) ve ince ayar (fine-tuning) işlemlerine rağmen, kötü niyetli istemler (adversarial prompts) ve jailbreak saldırıları karşısında kırılgan (brittle) davranışlar sergilemesiyle bilinmektedir. Bu kırılganlık, modern yapay sinir ağları tabanlı dil modellerinin daha geniş bir sorununu yansıtmaktadır: yüksek boyutlu girdi uzaylarındaki küçük, dikkatlice yapılandırılmış pertürbasyonlar, iç anlamsal temsillerde ve çıktıda büyük ve öngörülemeyen değişikliklere neden olabilir. Transformer tabanlı dil modellerinin sağlamlığını (robustness) artırmak için bir mimari endüktif yanlılık (architectural inductive bias) olarak monotonluğu (monotonicity) araştırıyoruz. Monotonluk, bilgi, kanıt veya kısıtlamaların güçlendirilmesinin ilgili iç temsillerde gerilemelere yol açamayacağı şekilde anlamsal dönüşümleri sınırlar. Bu tür sıra koruyucu (order-preserving) davranış, akıl yürütmeyi (reasoning) basitleştirmek ve sağlamlığı iyileştirmek için kontrol ve güvenlik açısından kritik sistemlerde uzun süredir kullanılmaktadır, ancak geleneksel olarak yapay sinir ağları dil modelleri için gereken ifade edici güce (expressivity) uyumsuz olarak görülmüştür. Bu ödünleşimin (trade-off) doğasında olmadığını gösteriyoruz. Sıralı-dizilişli (sequence-to-sequence) Transformer'ların ileri beslemeli alt katmanlarında (feed-forward sublayers) monotonluğu seçici olarak zorlayarak – dikkat mekanizmalarını (attention mechanisms) kısıtlı bırakarak – önceden eğitilmiş muadillerinin performansını koruyan monoton dil modelleri elde ediyoruz. Bu mimari ayrım, olumsuzlama (negation), çelişki (contradiction) ve bağlamsal etkileşimlerin (contextual interactions) dikkat aracılığıyla açıkça tanıtılmasına izin verirken, sonraki anlamsal iyileştirmenin sıra koruyucu olmasını sağlamaktadır. Ampirik olarak, monotonluk sağlamlığı önemli ölçüde artırmaktadır: kötü niyetli saldırı başarı oranları yaklaşık %69'dan %19'a düşerken, standart özetleme (summarization) performansı yalnızca marjinal olarak düşmektedir."
    }
  }
]