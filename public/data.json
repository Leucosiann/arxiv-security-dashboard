[
  {
    "id": "2512.24571v1",
    "title": "SynRAG: A Large Language Model Framework for Executable Query Generation in Heterogeneous SIEM System",
    "authors": [
      "Md Hasan Saju",
      "Austin Page",
      "Akramul Azim",
      "Jeff Gardiner",
      "Farzaneh Abazari"
    ],
    "published_date": "2025-12-31",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24571v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24571v1",
    "content": {
      "en": "Security Information and Event Management (SIEM) systems are essential for large enterprises to monitor their IT infrastructure by ingesting and analyzing millions of logs and events daily. Security Operations Center (SOC) analysts are tasked with monitoring and analyzing this vast data to identify potential threats and take preventive actions to protect enterprise assets. However, the diversity among SIEM platforms, such as Palo Alto Networks Qradar, Google SecOps, Splunk, Microsoft Sentinel and the Elastic Stack, poses significant challenges. As these systems differ in attributes, architecture, and query languages, making it difficult for analysts to effectively monitor multiple platforms without undergoing extensive training or forcing enterprises to expand their workforce. To address this issue, we introduce SynRAG, a unified framework that automatically generates threat detection or incident investigation queries for multiple SIEM platforms from a platform-agnostic specification. SynRAG can generate platformspecific queries from a single high-level specification written by analysts. Without SynRAG, analysts would need to manually write separate queries for each SIEM platform, since query languages vary significantly across systems. This framework enables seamless threat detection and incident investigation across heterogeneous SIEM environments, reducing the need for specialized training and manual query translation. We evaluate SynRAG against state-of-the-art language models, including GPT, Llama, DeepSeek, Gemma, and Claude, using Qradar and SecOps as representative SIEM systems. Our results demonstrate that SynRAG generates significantly better queries for crossSIEM threat detection and incident investigation compared to the state-of-the-art base models.",
      "tr": "**Makale Başlığı:** SynRAG: Heterojen SIEM Sistemlerinde Yürütülebilir Sorgu Üretimi için Büyük Dil Modeli Çerçevesi\n\n**Özet:**\n\nKurumsal düzeydeki işletmeler için Güvenlik Bilgi ve Olay Yönetimi (SIEM) sistemleri, günlük milyonlarca log ve olayı alıp analiz ederek IT altyapılarını izlemek açısından kritik öneme sahiptir. Güvenlik Operasyon Merkezi (SOC) analistleri, potansiyel tehditleri belirlemek ve kurumsal varlıkları korumak için önleyici eylemler almak amacıyla bu büyük veri setini izleme ve analiz etme görevini üstlenirler. Ancak, Palo Alto Networks Qradar, Google SecOps, Splunk, Microsoft Sentinel ve Elastic Stack gibi SIEM platformları arasındaki çeşitlilik önemli zorluklar yaratmaktadır. Bu sistemler, nitelikleri, mimarileri ve sorgu dilleri açısından farklılık gösterdiği için, analistlerin kapsamlı bir eğitim almadan birden fazla platformu etkin bir şekilde izlemelerini veya işletmelerin iş gücünü genişletmek zorunda kalmalarını zorlaştırmaktadır. Bu sorunu ele almak üzere, platform bağımsız bir spesifikasyondan birden fazla SIEM platformu için otomatik olarak tehdit algılama veya olay inceleme sorguları üreten birleşik bir çerçeve olan SynRAG'ı sunuyoruz. SynRAG, analistler tarafından yazılan tek bir üst düzey spesifikasyondan platforma özgü sorgular üretebilir. SynRAG olmadan, sorgu dilleri sistemler arasında önemli ölçüde farklılık gösterdiği için analistlerin her SIEM platformu için ayrı ayrı sorgular yazmaları gerekirdi. Bu çerçeve, heterojen SIEM ortamlarında kesintisiz tehdit algılama ve olay incelemesini mümkün kılarak, özel eğitim ve manuel sorgu çevirisi ihtiyacını azaltır. SynRAG'ı, temsili SIEM sistemleri olarak Qradar ve SecOps'u kullanarak, GPT, Llama, DeepSeek, Gemma ve Claude dahil olmak üzere en gelişmiş dil modellerine karşı değerlendiriyoruz. Sonuçlarımız, SynRAG'ın çapraz-SIEM tehdit algılama ve olay inceleme için en gelişmiş temel modellere kıyasla önemli ölçüde daha iyi sorgular ürettiğini göstermektedir."
    }
  },
  {
    "id": "2512.24452v1",
    "title": "Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations",
    "authors": [
      "Yalin E. Sagduyu",
      "Tugba Erpek",
      "Aylin Yener",
      "Sennur Ulukus"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.NI",
      "cs.AI",
      "cs.CR",
      "cs.IT",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2512.24452v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24452v1",
    "content": {
      "en": "Semantic communications conveys task-relevant meaning rather than focusing solely on message reconstruction, improving bandwidth efficiency and robustness for next-generation wireless systems. However, learned semantic representations can still leak sensitive information to unintended receivers (eavesdroppers). This paper presents a deep learning-based semantic communication framework that jointly supports multiple receiver tasks while explicitly limiting semantic leakage to an eavesdropper. The legitimate link employs a learned encoder at the transmitter, while the receiver trains decoders for semantic inference and data reconstruction. The security problem is formulated via an iterative min-max optimization in which an eavesdropper is trained to improve its semantic inference, while the legitimate transmitter-receiver pair is trained to preserve task performance while reducing the eavesdropper's success. We also introduce an auxiliary layer that superimposes a cooperative, adversarially crafted perturbation on the transmitted waveform to degrade semantic leakage to an eavesdropper. Performance is evaluated over Rayleigh fading channels with additive white Gaussian noise using MNIST and CIFAR-10 datasets. Semantic accuracy and reconstruction quality improve with increasing latent dimension, while the min-max mechanism reduces the eavesdropper's inference performance significantly without degrading the legitimate receiver. The perturbation layer is successful in reducing semantic leakage even when the legitimate link is trained only for its own task. This comprehensive framework motivates semantic communication designs with tunable, end-to-end privacy against adaptive adversaries in realistic wireless settings.",
      "tr": "**Makale Başlığı:** Çok Görevli Öğrenme ve Adversarial Perturbations Yoluyla Gizlilik Korumalı Anlamsal İletişim\n\n**Özet:**\n\nAnlamsal iletişim, bir sonraki nesil kablosuz sistemler için bant genişliği verimliliğini ve sağlamlığını artırarak yalnızca mesaj yeniden yapılandırmasına odaklanmak yerine görevle ilgili anlamı iletir. Ancak, öğrenilmiş anlamsal temsiller hala istenmeyen alıcılara (dinleyicilere) hassas bilgiler sızdırabilir. Bu makale, birden çok alıcı görevini ortaklaşa destekleyen ve bir dinleyiciye anlamsal sızmayı açıkça sınırlayan derin öğrenme tabanlı bir anlamsal iletişim çerçevesi sunmaktadır. Yasal bağlantı, verici tarafında öğrenilmiş bir kodlayıcı kullanırken, alıcı anlamsal çıkarım ve veri yeniden yapılandırması için kodlayıcılar eğitir. Güvenlik problemi, bir dinleyicinin anlamsal çıkarımını iyileştirmek için eğitildiği, yasal verici-alıcı çiftinin görev performansını korurken dinleyicinin başarısını azaltmak için eğitildiği iteratif bir min-max optimizasyonu yoluyla formüle edilmektedir. Ayrıca, iletilen dalga biçimine işbirlikçi, adversarial olarak hazırlanmış bir perturbation ekleyerek dinleyiciye anlamsal sızmayı azaltan yardımcı bir katman sunuyoruz. Performans, MNIST ve CIFAR-10 veri kümeleri kullanılarak Rayleigh solma kanallarında eklemeli beyaz Gauss gürültüsü üzerinde değerlendirilmektedir. Anlamsal doğruluk ve yeniden yapılandırma kalitesi, artan latent boyut ile iyileşirken, min-max mekanizması yasal alıcıyı bozmadan dinleyicinin çıkarım performansını önemli ölçüde azaltır. Perturbation katmanı, yasal bağlantı yalnızca kendi görevi için eğitilmiş olsa bile anlamsal sızmayı azaltmada başarılıdır. Bu kapsamlı çerçeve, gerçekçi kablosuz ortamlarda uyarlanabilir düşmanlara karşı ayarlanabilir, uçtan uca gizlilik sağlayan anlamsal iletişim tasarımlarını teşvik etmektedir."
    }
  },
  {
    "id": "2512.24391v1",
    "title": "FAST-IDS: A Fast Two-Stage Intrusion Detection System with Hybrid Compression for Real-Time Threat Detection in Connected and Autonomous Vehicles",
    "authors": [
      "Devika S",
      "Vishnu Hari",
      "Pratik Narang",
      "Tejasvi Alladi",
      "Vinay Chamola"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24391v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24391v1",
    "content": {
      "en": "We have implemented a multi-stage IDS for CAVs that can be deployed to resourec-constrained environments after hybrid model compression.",
      "tr": "İşte başlığın ve özetin çevirisi:\n\n**Makale Başlığı:** FAST-IDS: Bağlı ve Otonom Araçlarda Gerçek Zamanlı Tehdit Tespiti İçin Hibrit Sıkıştırmalı Hızlı İki Aşamalı Bir Saldırı Tespit Sistemi\n\n**Özet:**\nSumber-kısıtlı ortamlarda dağıtılabilecek, hibrit model compression sonrasında işlevsel hale getirilebilen, çok aşamalı bir IDS'yi Bağlı ve Otonom Araçlar (CAVs) için uygulamış bulunmaktayız."
    }
  },
  {
    "id": "2512.24345v1",
    "title": "FedSecureFormer: A Fast, Federated and Secure Transformer Framework for Lightweight Intrusion Detection in Connected and Autonomous Vehicles",
    "authors": [
      "Devika S",
      "Vishnu Hari",
      "Pratik Narang",
      "Tejasvi Alladi",
      "F. Richard Yu"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24345v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24345v1",
    "content": {
      "en": "This works presents an encoder-only transformer built with minimum layers for intrusion detection in the domain of Connected and Autonomous Vehicles using Federated Learning.",
      "tr": "**Makale Başlığı:** FedSecureFormer: Bağlantılı ve Otonom Araçlarda Hafif İzinsiz Giriş Tespiti İçin Hızlı, Federasyonlu ve Güvenli Bir Transformer Çerçevesi\n\n**Özet:**\nBu çalışma, Bağlantılı ve Otonom Araçlar alanında izinsiz giriş tespiti için minimum katmanla oluşturulmuş, encoder-only bir transformer'ı Federated Learning kullanarak sunmaktadır. Bu yaklaşım, hassas verileri merkezi bir sunucuya göndermeden, cihaz üzerinde dağıtık bir eğitim süreci sağlayarak gizliliği ve güvenliği artırmayı amaçlamaktadır. FedSecureFormer, özellikle kaynak kısıtlı ortamlarda etkili ve verimli bir izinsiz giriş tespiti çözümü sunarken, 'knowledge graph' ve 'reasoning' gibi gelişmiş yetenekleri ile sistemin çevikliğini ve adaptasyon kabiliyetini yükseltmeyi hedeflemektedir. Ayrıca, 'recall' ve 'exact retrieval' gibi performans metrikleri ile doğruluğu garanti altına alınırken, 'relation-first' ve 'persistent belief system' gibi prensiplerle derinlemesine analiz yetenekleri güçlendirilmektedir."
    }
  },
  {
    "id": "2512.24088v1",
    "title": "FedLiTeCAN : A Federated Lightweight Transformer for Fast and Robust CAN Bus Intrusion Detection",
    "authors": [
      "Devika S",
      "Pratik Narang",
      "Tejasvi Alladi"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI"
    ],
    "link": "http://arxiv.org/abs/2512.24088v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24088v1",
    "content": {
      "en": "This work implements a lightweight Transformer model for IDS in the domain of Connected and Autonomous Vehicles",
      "tr": "Elbette, istenen çeviriyi aşağıda bulabilirsiniz:\n\n**Makale Başlığı:** FedLiTeCAN: Bağlantılı ve Otonom Araçlar İçin Hızlı ve Sağlam CAN Bus Saldırı Tespiti Amaçlı Federasyonlu Hafif Transformer Modeli\n\n**Özet:**\n\nBu çalışma, Bağlantılı ve Otonom Araçlar (Connected and Autonomous Vehicles) alanındaki Saldırı Tespit Sistemleri (IDS) için hafif bir Transformer modeli uygulamaktadır."
    }
  },
  {
    "id": "2512.24044v1",
    "title": "Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?",
    "authors": [
      "Yuan Xin",
      "Dingfan Chen",
      "Linyi Yang",
      "Michael Backes",
      "Xiao Zhang"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "link": "http://arxiv.org/abs/2512.24044v1",
    "pdf_link": "https://arxiv.org/pdf/2512.24044v1",
    "content": {
      "en": "As large language models (LLMs) are increasingly deployed, ensuring their safe use is paramount. Jailbreaking, adversarial prompts that bypass model alignment to trigger harmful outputs, present significant risks, with existing studies reporting high success rates in evading common LLMs. However, previous evaluations have focused solely on the models, neglecting the full deployment pipeline, which typically incorporates additional safety mechanisms like content moderation filters. To address this gap, we present the first systematic evaluation of jailbreak attacks targeting LLM safety alignment, assessing their success across the full inference pipeline, including both input and output filtering stages. Our findings yield two key insights: first, nearly all evaluated jailbreak techniques can be detected by at least one safety filter, suggesting that prior assessments may have overestimated the practical success of these attacks; second, while safety filters are effective in detection, there remains room to better balance recall and precision to further optimize protection and user experience. We highlight critical gaps and call for further refinement of detection accuracy and usability in LLM safety systems.",
      "tr": "İşte istenen çeviri:\n\n**Makale Başlığı:** Jailbreaking Saldırıları ve İçerik Güvenliği Filtreleri: LLM Güvenliği Yarışında Ne Kadar İlerdeyiz?\n\n**Özet:**\n\nBüyük dil modellerinin (LLM'ler) yaygın olarak kullanılmaya başlanmasıyla, bunların güvenli kullanımını sağlamak büyük önem taşımaktadır. Jailbreaking, model hizalamasını atlatarak zararlı çıktılara yol açan adversarial prompt'lar, önemli riskler oluşturmakta ve mevcut çalışmalar yaygın LLM'leri atlatmada yüksek başarı oranları bildirmektedir. Ancak, önceki değerlendirmeler yalnızca modellere odaklanmış, tipik olarak içerik moderasyon filtreleri gibi ek güvenlik mekanizmalarını içeren tam deployment pipeline'ı göz ardı etmiştir. Bu boşluğu gidermek için, LLM güvenlik hizalamasını hedef alan jailbreak saldırılarının ilk sistematik değerlendirmesini sunuyoruz; bu değerlendirme, girdi ve çıktı filtreleme aşamalarını içeren tam inference pipeline'ı boyunca başarılarını ölçmektedir. Bulgularımız iki temel içgörü sağlamaktadır: ilk olarak, değerlendirilen jailbreak tekniklerinin neredeyse tamamı en az bir güvenlik filtresi tarafından tespit edilebilir, bu da önceki değerlendirmelerin bu saldırıların pratik başarısını abartmış olabileceğini düşündürmektedir; ikinci olarak, güvenlik filtreleri tespit etmede etkili olsa da, korumayı ve kullanıcı deneyimini daha da optimize etmek için recall ve precision'ı daha iyi dengelemek için alan kalmaktadır. LLM güvenlik sistemlerinde tespit doğruluğu ve kullanılabilirliğin daha da iyileştirilmesi gerektiğini vurguluyor ve bu alanda kritik boşlukların giderilmesi çağrısında bulunuyoruz."
    }
  },
  {
    "id": "2512.23995v1",
    "title": "RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress",
    "authors": [
      "Ruixuan Huang",
      "Qingyue Wang",
      "Hantao Huang",
      "Yudong Gao",
      "Dong Chen"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2512.23995v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23995v1",
    "content": {
      "en": "Mixture-of-Experts architectures have become the standard for scaling large language models due to their superior parameter efficiency. To accommodate the growing number of experts in practice, modern inference systems commonly adopt expert parallelism to distribute experts across devices. However, the absence of explicit load balancing constraints during inference allows adversarial inputs to trigger severe routing concentration. We demonstrate that out-of-distribution prompts can manipulate the routing strategy such that all tokens are consistently routed to the same set of top-$k$ experts, which creates computational bottlenecks on certain devices while forcing others to idle. This converts an efficiency mechanism into a denial-of-service attack vector, leading to violations of service-level agreements for time to first token. We propose RepetitionCurse, a low-cost black-box strategy to exploit this vulnerability. By identifying a universal flaw in MoE router behavior, RepetitionCurse constructs adversarial prompts using simple repetitive token patterns in a model-agnostic manner. On widely deployed MoE models like Mixtral-8x7B, our method increases end-to-end inference latency by 3.063x, degrading service availability significantly.",
      "tr": "**Makale Başlığı:** RepetitionCurse: Mixture-of-Experts LLM'lerde DoS Stresi Altında Router Dengesizliğinin Ölçülmesi ve Anlaşılması\n\n**Özet:**\n\nMixture-of-Experts mimarileri, üstün parametre verimlilikleri sayesinde büyük dil modellerini ölçeklendirmek için standart haline gelmiştir. Günümüzde yaygın olan pratik uygulamalarda artan expert sayısını karşılamak amacıyla, modern çıkarım (inference) sistemleri genellikle expert paralelliğini benimseyerek expert'leri cihazlar arasında dağıtır. Ancak, çıkarım sırasında açık yük dengeleme (load balancing) kısıtlarının olmaması, kötü niyetli (adversarial) girdilerin ciddi yönlendirme (routing) konsantrasyonunu tetiklemesine izin vermektedir. Dağılım dışı (out-of-distribution) prompt'ların, yönlendirme stratejisini tüm token'ların tutarlı bir şekilde aynı üst-$k$ expert kümesine yönlendirilecek şekilde manipüle edebildiğini gösteriyoruz; bu durum belirli cihazlarda hesaplama darboğazları yaratırken diğerlerini atıl bırakır. Bu, bir verimlilik mekanizmasını hizmet reddi (denial-of-service - DoS) saldırı vektörüne dönüştürerek, ilk token'a kadar geçen süre (time to first token) için hizmet seviyesi anlaşmalarının (service-level agreements - SLA) ihlaline yol açar. Bu zafiyeti sömürmek için düşük maliyetli bir black-box stratejisi olan RepetitionCurse'ü öneriyoruz. MoE router davranışındaki evrensel bir kusuru belirleyerek, RepetitionCurse modelden bağımsız (model-agnostic) bir şekilde basit tekrarlayan token örüntüleri kullanarak adversarial prompt'lar oluşturur. Mixtral-8x7B gibi yaygın olarak kullanılan MoE modellerinde, yöntemimiz uçtan uca çıkarım gecikmesini (end-to-end inference latency) 3.063 kat artırarak hizmet kullanılabilirliğini (service availability) önemli ölçüde düşürmektedir."
    }
  },
  {
    "id": "2512.23987v1",
    "title": "MeLeMaD: Adaptive Malware Detection via Chunk-wise Feature Selection and Meta-Learning",
    "authors": [
      "Ajvad Haneef K",
      "Karan Kuwar Singh",
      "Madhu Kumar S D"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "link": "http://arxiv.org/abs/2512.23987v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23987v1",
    "content": {
      "en": "Confronting the substantial challenges of malware detection in cybersecurity necessitates solutions that are both robust and adaptable to the ever-evolving threat environment. The paper introduces Meta Learning Malware Detection (MeLeMaD), a novel framework leveraging the adaptability and generalization capabilities of Model-Agnostic Meta-Learning (MAML) for malware detection. MeLeMaD incorporates a novel feature selection technique, Chunk-wise Feature Selection based on Gradient Boosting (CFSGB), tailored for handling large-scale, high-dimensional malware datasets, significantly enhancing the detection efficiency. Two benchmark malware datasets (CIC-AndMal2020 and BODMAS) and a custom dataset (EMBOD) were used for rigorously validating the MeLeMaD, achieving a remarkable performance in terms of key evaluation measures, including accuracy, precision, recall, F1-score, MCC, and AUC. With accuracies of 98.04\\% on CIC-AndMal2020 and 99.97\\% on BODMAS, MeLeMaD outperforms the state-of-the-art approaches. The custom dataset, EMBOD, also achieves a commendable accuracy of 97.85\\%. The results underscore the MeLeMaD's potential to address the challenges of robustness, adaptability, and large-scale, high-dimensional datasets in malware detection, paving the way for more effective and efficient cybersecurity solutions.",
      "tr": "**Makale Başlığı:** MeLeMaD: Chunk-wise Feature Selection ve Meta-Learning ile Adaptif Kötü Amaçlı Yazılım Tespiti\n\n**Özet:**\n\nSiber güvenlik alanında kötü amaçlı yazılım tespitindeki önemli zorluklarla yüzleşmek, sürekli gelişen tehdit ortamına hem dayanıklı hem de uyarlanabilir çözümler gerektirmektedir. Bu makale, kötü amaçlı yazılım tespitinde Model-Agnostic Meta-Learning (MAML)'in adaptasyon ve genelleme yeteneklerinden yararlanan yeni bir çerçeve olan Meta Learning Malware Detection (MeLeMaD)'ı sunmaktadır. MeLeMaD, büyük ölçekli, yüksek boyutlu kötü amaçlı yazılım veri kümelerini işlemeye yönelik özel olarak tasarlanmış, Gradient Boosting'e dayalı yeni bir özellik seçme tekniği olan Chunk-wise Feature Selection based on Gradient Boosting (CFSGB)'yi bünyesine katarak tespit verimliliğini önemli ölçüde artırmaktadır. MeLeMaD'ın titizlikle doğrulanması için iki kıyaslama kötü amaçlı yazılım veri kümesi (CIC-AndMal2020 ve BODMAS) ve özel bir veri kümesi (EMBOD) kullanılmış, doğruluk, hassasiyet, recall, F1-score, MCC ve AUC gibi temel değerlendirme ölçütleri açısından dikkat çekici bir performans elde edilmiştir. CIC-AndMal2020 üzerinde %98.04, BODMAS üzerinde ise %99.97 doğruluk oranları ile MeLeMaD, mevcut en gelişmiş yaklaşımları geride bırakmaktadır. Özel veri kümesi EMBOD de %97.85 gibi dikkate değer bir doğruluk oranına ulaşmıştır. Elde edilen sonuçlar, MeLeMaD'ın kötü amaçlı yazılım tespitinde dayanıklılık, adaptasyon ve büyük ölçekli, yüksek boyutlu veri kümeleriyle ilgili zorlukların üstesindeki potansiyelini vurgulamakta ve daha etkili ve verimli siber güvenlik çözümlerinin önünü açmaktadır."
    }
  },
  {
    "id": "2512.23948v1",
    "title": "DivQAT: Enhancing Robustness of Quantized Convolutional Neural Networks against Model Extraction Attacks",
    "authors": [
      "Kacem Khaled",
      "Felipe Gohring de Magalhães",
      "Gabriela Nicolescu"
    ],
    "published_date": "2025-12-30",
    "tags": [
      "cs.LG",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2512.23948v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23948v1",
    "content": {
      "en": "Convolutional Neural Networks (CNNs) and their quantized counterparts are vulnerable to extraction attacks, posing a significant threat of IP theft. Yet, the robustness of quantized models against these attacks is little studied compared to large models. Previous defenses propose to inject calculated noise into the prediction probabilities. However, these defenses are limited since they are not incorporated during the model design and are only added as an afterthought after training. Additionally, most defense techniques are computationally expensive and often have unrealistic assumptions about the victim model that are not feasible in edge device implementations and do not apply to quantized models. In this paper, we propose DivQAT, a novel algorithm to train quantized CNNs based on Quantization Aware Training (QAT) aiming to enhance their robustness against extraction attacks. To the best of our knowledge, our technique is the first to modify the quantization process to integrate a model extraction defense into the training process. Through empirical validation on benchmark vision datasets, we demonstrate the efficacy of our technique in defending against model extraction attacks without compromising model accuracy. Furthermore, combining our quantization technique with other defense mechanisms improves their effectiveness compared to traditional QAT.",
      "tr": "**Makale Başlığı:** DivQAT: Model Extraction Saldırılarına Karşı Nicelenmiş Evrişimli Sinir Ağlarının Dayanıklılığının Artırılması\n\n**Özet:**\n\nEvrişimli Sinir Ağları (CNN) ve bunların nicelenmiş karşılıkları, fikri mülkiyet hırsızlığı tehdidi oluşturan extraction saldırılarına karşı savunmasızdır. Ancak, büyük modellere kıyasla nicelenmiş modellerin bu saldırılara karşı dayanıklılığı az çalışılmıştır. Önceki savunma yöntemleri, tahmin olasılıklarına hesaplanmış gürültü enjekte etmeyi önermektedir. Bununla birlikte, bu savunmalar model tasarımı sırasında entegre edilmedikleri ve yalnızca eğitimden sonra bir sonradan düşünülmüş olarak eklendikleri için sınırlıdır. Ek olarak, çoğu savunma tekniği hesaplama açısından maliyetlidir ve genellikle kenar cihaz uygulamalarında mümkün olmayan ve nicelenmiş modellere uygulanmayan kurban model hakkında gerçekçi olmayan varsayımlara sahiptir. Bu makalede, nicelenmiş CNN'leri, extraction saldırılarına karşı dayanıklılıklarını artırmayı hedefleyen Quantization Aware Training (QAT) temelinde eğiten yeni bir algoritma olan DivQAT'ı öneriyoruz. Bilgimiz dahilinde, tekniğimiz, model extraction savunmasını eğitim sürecine entegre etmek için nicelleştirme sürecini değiştiren ilk çalışmadır. Kıyaslama görüş veri kümeleri üzerindeki ampirik doğrulama yoluyla, model doğruluğundan ödün vermeden model extraction saldırılarına karşı tekniğimizin etkinliğini gösteriyoruz. Dahası, nicelleştirme tekniğimizi diğer savunma mekanizmalarıyla birleştirmek, geleneksel QAT'ye kıyasla etkinliklerini artırmaktadır."
    }
  },
  {
    "id": "2512.23881v1",
    "title": "Breaking Audio Large Language Models by Attacking Only the Encoder: A Universal Targeted Latent-Space Audio Attack",
    "authors": [
      "Roee Ziv",
      "Raz Lapid",
      "Moshe Sipper"
    ],
    "published_date": "2025-12-29",
    "tags": [
      "cs.SD",
      "cs.AI",
      "cs.CR"
    ],
    "link": "http://arxiv.org/abs/2512.23881v1",
    "pdf_link": "https://arxiv.org/pdf/2512.23881v1",
    "content": {
      "en": "Audio-language models combine audio encoders with large language models to enable multimodal reasoning, but they also introduce new security vulnerabilities. We propose a universal targeted latent space attack, an encoder-level adversarial attack that manipulates audio latent representations to induce attacker-specified outputs in downstream language generation. Unlike prior waveform-level or input-specific attacks, our approach learns a universal perturbation that generalizes across inputs and speakers and does not require access to the language model. Experiments on Qwen2-Audio-7B-Instruct demonstrate consistently high attack success rates with minimal perceptual distortion, revealing a critical and previously underexplored attack surface at the encoder level of multimodal systems.",
      "tr": "Makale Başlığı: Sadece Kodlayıcıya Saldırarak Sesli Büyük Dil Modellerini Kırmak: Evrensel Hedefli Gizli Alan Ses Saldırısı\n\nÖzet:\nSesli-dil modelleri, multimodal reasoning yeteneği kazandırmak için ses kodlayıcılarını büyük dil modelleriyle birleştirir, ancak aynı zamanda yeni güvenlik açıkları da ortaya çıkarır. Biz, saldırgan tarafından belirtilen çıktıları sonraki dil üretiminde tetiklemek amacıyla sesli gizli temsilleri manipüle eden bir kodlayıcı seviyesi düşmanca saldırı olan evrensel hedefli gizli alan saldırısı (universal targeted latent space attack) öneriyoruz. Dalga formu seviyesindeki veya girdi-spesifik saldırılardan farklı olarak, yaklaşımımız girdiler ve konuşmacılar arasında genelleme yapan ve dil modeline erişim gerektirmeyen evrensel bir pertürbasyon (universal perturbation) öğrenir. Qwen2-Audio-7B-Instruct üzerindeki deneyler, minimum algısal bozulma ile tutarlı olarak yüksek saldırı başarı oranları göstermiştir. Bu durum, multimodal sistemlerin kodlayıcı seviyesinde kritik ve daha önce yeterince araştırılmamış bir saldırı yüzeyini ortaya koymaktadır."
    }
  }
]